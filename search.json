[{"title":"android command line 安装时的坑","url":"/2020/03/24/android-command-line-%E5%AE%89%E8%A3%85%E6%97%B6%E7%9A%84%E5%9D%91/","content":"很久没有搞过 Android 开发了，Android 的命令行安装方式相比之前发生了一些变化，这里针对安装最新的 Android 命令行时遇到的一些问题，记录一下解决方法。\n问题：下载最新的 commandlinetools 在自己指定的目录安装之后，无法使用\n原因：最新版本的 commandlinetools 对安装的目录是有要求的\n\nDownload latest Command line tools from android i.e. commandlinetools-win-6200805_latest.zip\nUnzip the downloaded file\nCreate directory for storing commandline tools somewhere on your disk, with following path included: android&#x2F;cmdline-tools&#x2F;latest Basically when You unzip this Cmd line tools, just rename tools directory to latest and make sure You put this latest folder in android&#x2F;cmdline-tools directory somewhere on your disk\nCreate ANDROID_HOME environment variable for directory that stores the cmdline tools directory location like: C:\\YourLocationWhereYouStoreTheDirectory\\android\\cmdline-tools\\latest\nCreate new entry in Path environment variable as %ANDROID_HOME%\\bin\n\n"},{"title":"JaCoCo手册","url":"/2022/01/26/JaCoCo%E6%89%8B%E5%86%8C/","content":"JaCoCo 简介\nJaCoCo should provide the standard technology for code coverage analysis in Java VM based environments. The focus is providing a lightweight, flexible and well documented library for integration with various build and development tools.\n\nJaCoCo 要为基于 Java VM 的环境中的代码提供覆盖率分析标准技术，重点是提供一个轻量、灵活且文档齐全的库，以便与各种构建和开发工具集成。\n功能特性\n指令（C0）、分支（C1）、行、方法、类型、圈复杂度的覆盖率分析；\n基于 Java 字节码，即使没有源码依然可以运行；\n支持 on-the-fly 模式，可以通过 javaagent 便捷地集成，也可以通过 API 来自定义类装载器进行集成；\n与框架无关，可以对基于 Java VM 的应用程序顺利的集成；\n与已所有已发布的 Java 版本兼容；\n支持不同的 JVM 语言；\n可以生成多种格式的报告（HTML、XML、CSV）；\n支持远程协议和 JMX 控制，可以在任何时间点来进行覆盖率数据的存储；\n\n使用下载完 JaCoCo 之后会得到几个 jar 包，其中 jacocoagent.jar 和 jacococli.jar 是我们比较关注的。\n\njacocoagent.jar 是 JVM 应用程序启动时的代理\njacococli.jar 是生成覆盖率报告、合并 dump 文件的命令行工具\n\njacocoagentJava Agent 的原理可以阅读 java.lang.instrument.Instrumentation 这个类，这里先介绍 jacocoagent 的使用方法。\n在 Java 应用的启动命令上加入如下的参数：\n-javaagent:[yourpath/]jacocoagent.jar=[option1]=[value1],[option2]=[value2]\n即可对启动的 Java 应用程序中指定的类进行代码覆盖率的采集，其中 option 的选项有：\n\n\n\noption\n缺省值\n描述\n\n\n\ndestfile\njacoco.exec\n保存 jacoco 采集的数据文件的路径\n\n\nappend\ntrue\n数据文件保存路径的文件存在的情况下，是否追加覆盖率数据\n\n\nincludes\n*\n采集哪些类（采集类过多会导致新能下降严重）\n\n\nexcludes\n*\n排除哪些类\n\n\ninclbootstrapclasses\nfalse\n是否需要采集 bootstrap classLoader 加载的类\n\n\ninclnolocationclasses\nfalse\n是否需要采集没有原位置的类（即程序运行时生成的类）\n\n\nsessionid\nauto-generated\n会话标识符，如果没有配置该参数，jacocoagent 会自动生成\n\n\ndumponexit\ntrue\n是否在 VM 关闭时写入数据\n\n\noutput\nfile\n存储数据的方式，有效的选项：file、tcpserver、tcpclient、none\n\n\naddress\nloopback interface\n当 output 为 tcpserver 时启用，缺省值为 127.0.0.1\n\n\nport\n6300\n当 output 为 tcpserver 时启用\n\n\nclassdumpdir\nno dumps\n保存插桩之后的 class 的路径\n\n\njmx\nfalse\n是否开启 JMX 功能\n\n\njacococlijacoco 的命令行工具，可以用于链接 jacocoagent 用于采集回文件的存储、对指定的类进行插桩、合并 dump 文件、生成报告等功能，具体使用方法不再一一列举，可以查看官方文档\n"},{"title":"数据库死锁","url":"/2019/11/15/database-deadlock/","content":"\n死锁是指两个或多个事务在同一个资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象\n\n示例先用一个示例来演示一下数据库死锁的情况。本示例基于 MySQL 的 InnoDB 存储引擎。\n表结构我们先建一个 wallet 表，表结构如下\nmysql&gt; DESC wallet;+---------+---------------------+------+-----+---------+-------+| Field   | Type                | Null | Key | Default | Extra |+---------+---------------------+------+-----+---------+-------+| id      | bigint(20) unsigned | NO   | PRI | NULL    |       || user_id | bigint(20) unsigned | NO   | UNI | 0       |       || balance | bigint(20)          | NO   |     | 0       |       |+---------+---------------------+------+-----+---------+-------+\n\n开启事务 A，并修改 id 为 1 的记录mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE wallet SET balance = balance + 100 WHERE id = 1;Query OK, 1 row affected (0.00 sec)\n\n开启事务 B，并修改 id 为 2 的记录mysql&gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&gt; UPDATE wallet SET balance = balance + 100 WHERE id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0\n\n事务 A 修改 id 为 2 的记录mysql&gt; UPDATE wallet SET balance = balance + 100 WHERE id = 2;\n\n此时发现该修改并未马上成功，而是陷入等待状态，原因是事务 A 此时要锁定 id 为 2 的记录，但该记录已经被事务 B 锁定了。\n事务 B 修改 id 为 1 的记录mysql&gt; UPDATE wallet SET balance = balance + 100 WHERE id = 1;ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction\n\n此时事务 B 报错，错误原因很明确是发生了死锁问题，通过查询操作也可以发现事务 B 的操作已经回滚，与此同时事务 A 对 id 为 2 的记录的修改已经成功，后续的 COMMIT 操作就不展示了。\n如何解决死锁问题死锁产生的原因锁的行为和顺序是和存储引擎相关的，同样的顺序执行语句，有些存储引擎会产生死锁，有的则不会。因此死锁的产生有两种原因：有些是因为真正的数据冲突，有些则完全是由于存储引擎的实现方式导致的。\n死锁发生以后，只有部分或者完全回滚其中一个事务，才能打破死锁。对于事务性系统，死锁问题是无法完全避免的，在设计应用程序时必须考虑如何处理死锁。大部分情况下只需要重新执行因死锁回滚的事务即可。\n解决死锁问题常见的数据库都实现了各种死锁检测和死锁超时机制。\n\n死锁检测：比如上述例子中，检测到死锁问题，数据库立马报错，这种解决方式非常有效，否则死锁会导致非常慢的查询。\n\n超时机制：超时机制就是当查询时间达到锁等待超时的设定后放弃锁的请求。\n\n\nInnoDB 目前处理死锁的方式是选择代价较小的事务进行回滚，这个代价基于多种因素计算，包括事务已经锁定了多少行数据、事务的权重等因素。\nInnoDB 显式和隐式锁定InnoDB 采用的是两阶段锁定协议（two-phase locking protocol）。在事务执行过程中，随时都可以执行锁定，锁只有在执行 COMMIT 或者 ROLLBACK 的时候才会被释放，并且所有的锁是在同一时刻被释放。InnoDB 会根据隔离级别在需要的时候自动加锁。\nInnoDB 也支持通过特定的语句进行显式的锁定，这些语句不属于标准 SQL 规范。\n\nSELECT ... LOCK IN SHARE MODE\nSELECT ... FOR UPDATE\n\nMySQL 也支持 LOCK TABLES 和 UNLOCK TABLES 语句，这是在服务器层面实现的，跟存储引擎无关，不能用于代替事务处理。\n","tags":["数据库","MySQL"]},{"title":"Arthas 非常实用的几个命令","url":"/2020/01/18/arthas-useful-command/","content":"本文介绍几个非常有用的 Arthas 命令，熟练使用这几个命令，可以让我们在排查线上问题的时候更加轻松。\n关于 Arthas 的设计思想，美团技术团队的文章Java 动态追踪技术探究一文中做了详细的说明，有兴趣可以去阅读一下。\ntracetrace 命令见名知意，可以用于跟踪方法内部的调用路径，渲染整个调用链路上所有的性能开销和跟踪调用链路。\n例如，我们提供了一个 controller，用来保存一笔订单数据，如下：\npackage com.goku.order.rest;import com.goku.order.entity.Order;import lombok.extern.slf4j.Slf4j;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.*;/** * @author fuyongde * @date 2020/1/18 15:36 */@RestController@RequestMapping(&quot;/api/orders&quot;)@Slf4jpublic class OrderRestController &#123;    private static Random random = new Random();    @PostMapping    public Map&lt;String, Object&gt; save(@RequestBody Order order) &#123;        long id = random.nextLong();        order.setId(id);        Date now = new Date();        if (Objects.nonNull(order.getFlag()) &amp;&amp; order.getFlag()) &#123;            log.info(&quot;调用路径1&quot;);        &#125; else &#123;            log.warn(&quot;调用路径2&quot;);        &#125;        order.setCreateTime(now);        order.setUpdateTime(now);        log.info(&quot;request body : &#123;&#125;&quot;, order);        Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(16);        map.put(&quot;order&quot;, order);        return map;    &#125;&#125;\n\n现在项目在运行中，我们要查看 save 方法的链路，打开 arthas 并选择我们的工程，使用 trace com.goku.order.rest.OrderRestController save 命令并触发一次调用\nAffect(class-cnt:1 , method-cnt:1) cost in 69 ms.`---ts=2020-01-18 22:40:56;thread_name=http-nio-8081-exec-1;id=14;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@4f824872    `---[3.6313ms] com.goku.order.rest.OrderRestController:save()        +---[0.0164ms] com.goku.order.entity.Order:setId() #26        +---[0.0047ms] com.goku.order.entity.Order:getFlag() #28        +---[0.1695ms] org.slf4j.Logger:warn() #31        +---[0.0103ms] com.goku.order.entity.Order:setCreateTime() #33        +---[0.0062ms] com.goku.order.entity.Order:setUpdateTime() #34        `---[2.6388ms] org.slf4j.Logger:info() #35\n\n从输出上来看，我们可以很清楚地看到代码的 26、28、31、33、34、35 行被执行了，同样的，如果 order 对象的 flag 属性如果为 true，则第 31 行的调用会变成第 29 行，如下：\n`---ts=2020-01-18 22:56:00;thread_name=http-nio-8081-exec-4;id=17;is_daemon=true;priority=5;TCCL=org.springframework.boot.web.embedded.tomcat.TomcatEmbeddedWebappClassLoader@4f824872    `---[2.1072ms] com.goku.order.rest.OrderRestController:save()        +---[0.0051ms] com.goku.order.entity.Order:setId() #26        +---[min=0.0023ms,max=0.0023ms,total=0.0046ms,count=2] com.goku.order.entity.Order:getFlag() #28        +---[0.6911ms] org.slf4j.Logger:info() #29        +---[0.0186ms] com.goku.order.entity.Order:setCreateTime() #33        +---[0.0032ms] com.goku.order.entity.Order:setUpdateTime() #34        `---[0.312ms] org.slf4j.Logger:info() #35\n\n从输出结果也可以清楚地看到代码在执行过程中，哪一行的代码调用耗时最长，这对我们排查线上对应的问题是非常有帮助的。\n包含 jdk 的函数如果需要将 JDK 的方法执行链路也输出，则使用 --skipJDKMethod false 参数，例如： trace com.goku.order.rest.OrderRestController save --skipJDKMethod false。\n根据调用耗时过滤如果需要只需要查看调用耗时比较长的，则添加对应的过滤条件，可以更快地帮助我们定位异常问题。比如只查询调用耗时超过 10ms 的方法：trace com.goku.order.rest.OrderRestController save &#39;#cost &gt; 10&#39;\n","categories":["手册"],"tags":["Arthas"]},{"title":"curl-command 手册","url":"/2019/10/24/curl-command-%E6%89%8B%E5%86%8C/","content":"curl 是十分常用的命令，通常我们用这个命令来请求 Web 服务器。一些常见的构造 HTTP 请求的客户端（如 Postman）关于项目协作的功能都是商业化版本才有的，团队开发过程中通过维护接口的 curl 命令脚本可以低成本的代替一些商业化软件的功能。\n下面介绍一下 curl 命令的常见用法。\n基础用法请求一个 URLcurl http://www.baidu.com/\n\n-X使用 -X 参数可以指定 HTTP Method\ncurl -X POST http://www.baidu.com/\n\n-H, –header使用 -H 或者 –header 参数可以添加 HTTP 的请求头\ncurl -H &quot;Content-Type:application/json&quot; http://www.baidu.com/\n\n-d, –data使用 -d 或 –data 可以发送 HTTP 的请求参数，可以是 form 表单，也可以是二进制的 request body\n# 发送 form 表单curl -X POST -d &quot;name=jasonfu&amp;age=20&amp;birthday=1990/06/01&quot; &quot;http://localhost:8080/http/post?type=form&quot;# 也可以使用多个 -d 参数curl -X POST -d &quot;name=jasonfu&quot; -d &quot;age=20&quot; -d &quot;birthday=1990/06/01&quot; &quot;http://localhost:8080/http/post?type=form&quot;### 发送 request bodycurl -X POST -H &quot;Content-Type:application/json&quot; -d &quot;&#123;\\&quot;name\\&quot;:\\&quot;jasonfu\\&quot;,\\&quot;age\\&quot;:19,\\&quot;birthday\\&quot;:12345678911&#125;&quot; &quot;http://localhost:8080/http/post?type=body&quot;\n\n-F, –form使用 -F 或 –form 参数可以上传文件\n### 上传文件curl -F &quot;file=@alias.bat&quot; -X POST &quot;http://localhost:8080/http/post?type=upload&quot;### 上传文件 带参数curl --form &quot;file=@alias.bat&quot; --form &quot;id=1&quot; -X POST &quot;http://localhost:8080/http/post?type=upload&quot;\n\n进阶用法-i, -I使用 -i 参数可以输出 HTTP 的响应头\ncurl -i http://www.baidu.com/\n\n使用 -I 参数只输出 HTTP 的响应头\ncurl -I http://www.baidu.com/\n\n-e, –referer使用 -e 或者 –referer 参数可以在 HTTP 请求头中添加 referer 字段，标识从哪里跳转过来的\ncurl --referer http://www.baidu.com/ http://www.qq.com/\n\n-A, –user-agent使用 -A 或者 –user-agent 参数可以指定 HTTP 请求头中的 User-Agent 字段\ncurl --user-agent curl-client http://www.baidu.com/\n\ncookie使用 -b 或者 –cookie 可以发送 cookie 给 Web 服务器。\ncurl --cookie &quot;user=fuyongde&quot; http://www.baidu.com/\n\n使用 -c 参数可以保存服务端返回的 cookie 到指定的文件\ncurl -c baidu-cookie.txt http://www.baidu.com/\n\n显示通信过程使用 -v 或者 –verbose 参数可以展示完整的 HTTP 通信过程\ncurl -v http://www.baidu.com/\n\n使用 –trace 或者 –trace-ascii 参数可以展示更详细的通信过程\ncurl --trace trace.txt http://www.baidu.com/\n\n保存响应使用 -o 或者 -O 参数可以将 http 响应保存为文件，区别在于 -o 可以指定文件名，-O 则是使用 URL 中最后一段 path 作为文件名来进行保存，其下载文件的效果等同于 wget 命令。\n# 将 http://www.baidu.com/ 响应保存至文件 baidu.html 中curl -o baidu.html http://www.baidu.com/# 将 http://localhost:8080/ping 响应保存至文件 ping 中curl -O http://localhost:8080/ping\n\n使用代理一些 Web 服务器是仅支持某些特定的 ip 来访问的，这种情况下，我们就需要使用代理来发送我们的 HTTP 请求，使用 -x 参数可以指定代理服务器来发送我们的请求。\n# 使用 socks5 协议的代理服务器来发送请求curl -x socks5://username:password@proxyhost:8080 http://www.baidu.com/# 默认情况下使用 http 协议的代理服务器来发送请求curl -x username:password@proxyhost:8080 http://www.baidu.com/\n\n-L, –location对于一些 HTTP 响应码为 302 的情况，可以使用 -L 或者 –location 参数来实现自动跳转的效果\ncurl -L -i http://localhost:8080/http/redirect\n\n其输出如下：\nHTTP/1.1 302Location: http://localhost:8080/http/get/jasonfuContent-Length: 0Date: Tue, 24 Aug 2021 10:22:10 GMTHTTP/1.1 200Content-Type: application/jsonTransfer-Encoding: chunkedDate: Tue, 24 Aug 2021 10:22:10 GMT&#123;&quot;name&quot;:&quot;jasonfu&quot;,&quot;age&quot;:18,&quot;birthday&quot;:&quot;2021-08-24T10:22:10.713+00:00&quot;&#125;\n\n可以看到已经实现了自动跳转的效果\n–limit-rate使用 –limit-rate 参数可以限制访问 HTTP 请求和响应的带宽。\n# 将带宽限制为每秒 1k 字节curl --limit-rate 1k http://www.baidu.com/\n","categories":["手册"],"tags":["curl","command","未完待续"]},{"title":"夏令时问题","url":"/2019/10/01/daylight-saving-time/","content":"在工作中，遇到一个很有意思的关于时间的问题，这里跟大家分享一下。\n现象从数据库里取出用户的生日1990-05-22，接口返回时发现返回值变成了1990-05-21，而对于1992-05-22这样的日期却能正确返回。\n网上很多对于相关问题的分析都是简单粗暴的认为是时区的问题，却没有讲明白问题出现的根本原因。\n排查过程问题复现为了复现问题现象，我们先快速搭建一个 Spring Boot Application。\n先将配置文件中对日期类型的格式化配置为 yyyy-MM-dd，如下所示：\nspring.jackson.time-zone=GMT+8spring.jackson.date-format=yyyy-MM-dd\n\n写一个接口，直接将有问题的日期输出，代码如下：\n@RestControllerpublic class IndexController &#123;    @GetMapping(&quot;/dst&quot;)    public Map&lt;String, Object&gt; dst(@RequestParam(&quot;date&quot;) Date date) &#123;        Map&lt;String, Object&gt; map = Maps.newHashMap();        System.out.println(&quot;birthday : &quot; + DateFormatUtils.format(date, &quot;yyyy-MM-dd&quot;));        map.put(&quot;birthday&quot;, date);        return map;    &#125;&#125;\n\n构造如下请求：\nGET http://localhost:8081/dst?date=1990/05/22\n\n发现服务端日志正确输出1990-05-22，而接口返回值却输出：\n&#123; &quot;birthday&quot;: &quot;1990-05-21&quot; &#125;\n\n构造如下请求：\nGET http://localhost:8081/dst?date=1992/05/22\n\n发现服务端日志正确输出1992-05-22，此时接口的输出与服务端日志一致：\n&#123; &quot;birthday&quot;: &quot;1992-05-22&quot; &#125;\n\n至此，我们复现了本文要讲解的问题。\n输出对应的时间为了更精确的知道这两个日期究竟有什么不同，我们更详细的输出这两个 Date 所对应的具体时间。\n修改配置文件为：\nspring.jackson.date-format=yyyy-MM-dd HH:mm:ss\n\n重复以上请求，发现对于1990-05-22，服务端日志输出1990-05-22 00:00:00，而接口返回值则为1990-05-21 23:00:00，两者相差了一个小时。而对于1992-05-22，服务端日志与接口返回值完全一致。\n输出系统的时区通过上述的现象基本上可以定位问题出现在 Jackson 对日期的序列化上。\n为了排查这个问题，我们在启动 Spring Boot Application 时，先输出当前系统的时区，发现系统时区为 Asia/Shanghai，而我们配置的 Jackson 时区为 GMT+8。\n难道 Asia/Shanghai 与 GMT+8 不是同一个时区？\n求证为了证明我们的猜想是正确的，在启动 Spring Boot Application 时，将系统时区设置为 GMT+8。\n@SpringBootApplicationpublic class DSTApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(DSTApplication.class, args);        TimeZone.setDefault(TimeZone.getTimeZone(&quot;GMT+8&quot;));    &#125;&#125;\n\n重复以上请求，发现对于1990-05-22，服务端日志和接口均正确输出 1990-05-22 00:00:00。\n若不设置默认时区为 GMT+8，而是将 Jackson 序列化的时区配置修改为 Asia/Shanghai，接口也能正确输出。\n那么 Asia/Shanghai 与 GMT+8 在什么情况下会导致相差一个小时的问题呢？\n夏令时\n夏令时，表示为了节约能源，人为规定时间的意思。也叫夏时制，夏时令（Daylight Saving Time：DST），又称”日光节约时制”和”夏令时间”，在这一制度实行期间所采用的统一时间称为”夏令时间”。一般在天亮早的夏季人为将时间调快一小时，可以使人早起早睡，减少照明量，以充分利用光照资源，从而节约照明用电。各个采纳夏时制的国家具体规定不同。目前全世界有近 110 个国家每年要实行夏令时。1986 年 4 月，中国中央有关部门发出”在全国范围内实行夏时制的通知”，具体作法是：每年从四月中旬第一个星期日的凌晨 2 时整（北京时间），将时钟拨快一小时，即将表针由 2 时拨至 3 时，夏令时开始；到九月中旬第一个星期日的凌晨 2 时整（北京夏令时），再将时钟拨回一小时，即将表针由 2 时拨至 1 时，夏令时结束。从 1986 年到 1991 年的六个年度，除 1986 年因是实行夏时制的第一年，从 5 月 4 日开始到 9 月 14 日结束外，其它年份均按规定的时段施行。在夏令时开始和结束前几天，新闻媒体均刊登有关部门的通告。1992 年起，夏令时暂停实行。\n\n以上内容摘抄自百度百科，这也就是为什么在上述例子中为什么1992-05-22即使在系统时区与 Jackson 序列化时区不一致的情况下，仍然能够正确返回，而1990-05-22就会出错。\n问题本质分析实际上，这个问题的根本原因并不是简单的夏令时问题，而是不同时间 zone 表示方式的差异：\n\nAsia/Shanghai 是一个完整的时区 ID，它包含了完整的时区历史信息，包括中国实行夏令时的历史记录\nGMT+8 只是一个固定的 UTC 偏移量，不包含任何历史时区变化信息\n\n当处理 1990 年这样的历史日期时，这两种时区表示方式在夏令时处理上会产生差异，导致序列化结果不一致。\n更好的解决方案除了文中提到的两种解决方案外，还有其他更好的处理方式：\n\n使用 LocalDate 处理纯日期：对于生日这类不含时区信息的日期，应使用 LocalDate 而不是 Date\n统一使用 UTC：在系统内部统一使用 UTC 时间存储和传输，在展示给用户时再转换为本地时区\n明确时区处理策略：在序列化配置中明确指定时区处理策略，避免依赖系统默认设置\n\n","categories":["问题排查"],"tags":["夏令时"]},{"title":"Docker 手册","url":"/2019/11/14/docker-%E6%89%8B%E5%86%8C/","content":"镜像管理查询所需的镜像\nUsage：\ndocker search [OPTIONS] TERM\n\nOptions：\n-f --filter ：根据提供的条件过滤输出\n--format ：使用 Go 模板进行漂亮的打印搜索\n--limit ：最大搜索结果数（默认为 25）\n--no-trunc：不要截断输出\n\nExample：\n\n\ndocker search mysql\n\n安装镜像\nUsage：\ndocker pull [OPTIONS] NAME[:TAG|@DIGEST]\n\nOptions：\n-a --all-tags：下载存储库中的所有标记镜像\n--disable-content-trust：跳过图像验证（默认为 true）\n\nExample：\n# 安装MySQL的5.7.24版本docker pull mysql:5.7.24# 缺省TAG时默认安装最新版本docker pull mysql# 安装所有版本docker pull -a mysql# 安装zookeeperdocker pull zookeeper\n\n查看镜像信息Usage：\ndocker images [OPTIONS] [REPOSITORY[:TAG]]\nOptions：\n-a, --all：展示全部镜像--digests：展示镜像的哈希值-f, --filter filter：根据提供的条件过滤输出--format string：使用 Go 模板的漂亮打印图像--no-trunc：不要截断输出-q, --quiet：仅显示数字 ID\nExample：\n# 查看所有的镜像信息docker images -a\n\n删除镜像Usage：\ndocker rmi [OPTIONS] IMAGE [IMAGE...]\nOptions：-f, --force：强制删除某个镜像--no-prune ：不删除未标记的父类\nExample：\n# 删除id为cd14cecfdb3a的镜像docker rmi cd14cecfdb3a# 删除jenkins镜像docker rmi jenkins\n\n容器管理查看容器# 查看所有正在运行的容器docker ps# 查看所有容器docker ps -a# 查看所有容器IDdocker ps -a -q\n\n启动容器docker run IMG\nExample：\n# 启动MySQLdocker run -p 3306:3306 --name MySQL -e MYSQL_ROOT_PASSWORD=fuyongde mysql:5.7.24# 启动zookeeperdocker run -p 2181:2181 --name zookeeper zookeeper\n\n停止容器docker stop [containerId]：停止容器\nExample：\n# 停止id为8fcc3dad236a的容器docker stop 8fcc3dad236a\n\n重启容器# 重启id为1e4b2a31028d的容器docker restart 1e4b2a31028d\n\n删除容器docker rm [containerId]\n# 删除id为1e4b2a31028d的容器docker rm 1e4b2a31028d\n\n重命名容器# 将docker-mysql重命名为mysqldocker rename docker-mysql mysql\n\n其他命令进入到一个容器通常我们使用的 docker 镜像一般是基于 Linux，则可以通过下面的方式进入到 docker 容器内：\ndocker exec -it 063caee1d235 /bin/bash\n但是对于基于Alpine Linux的镜像，则需要使用：\ndocker exec -it 063caee1d235 sh\n对于部分镜像默认用户不是 root 的（比如 Jenkins 官方提供的 docker 镜像），但我们又需要使用 root 账户的，可以通过添加 -u root 参数来使用 root 账户登录 docker 容器：\ndocker exec -it -u root a07fe9b55ade bash\n拷贝文件到一个容器docker cp C:\\Users\\fuyongde\\Documents\\repo\\github\\goku\\atomikos-demo\\zhifubao-server\\src\\main\\resources\\sql\\zhifubao.sql 1e4b2a31028d:/tmp\n从容器拷贝文件到主机docker cp 1e4b2a31028d:/tmp/zhifubao.sql C:\\Users\\fuyongde\\Documents\n","categories":["手册"],"tags":["Docker"]},{"title":"使用 Docker 构建 Spring Boot Application","url":"/2019/06/25/dockerizing-spring-boot-application/","content":"Docker &amp; Spring BootDocker 是一种 Linux 容器的实现，具有进程的轻量级资源隔离的特点，每一个容器对应操作系统中的一个进程，但是它又会有自己的网络空间、文件系统、PID 等。Docker 除了实现 Linux 容器，还使得容器具有“社会化”的属性，用户可以将容器镜像发布在 Docker Hub 与其他开发者共享、协作，类似于 Maven。\nSpring Boot 简化了 Spring 应用程序的开发过程，遵循约定优先配置的原则提供了各类 开箱即用（out-of-the-box） 的框架配置。另一方面，Spring Boot 还具备将代码直接构建为可执行 jar 包的能力，这个 jar 包是一个可以独立运行的部署单元。基于以上特性，现在普遍认为 Spring Boot 提供了一种快速构造微服务（Micro-Service）的能力。\nSpring Boot 的运行环境非常简单，将 Spring Boot Application 打包为 Docker 镜像，对于自动化部署、运维都非常方便。\nDockerizing Spring Boot Application使用 Docker 发布 Spring Boot Application，需要经历简单的几步，即可实现。\n如有需要，可参考本文所涉及 Demo。\n常规操作编写 Spring Boot Application本文不是为了讲解如何编写 Spring Boot Application，故建议读者直接采用脚手架快速构建出一个 Spring Boot Application。\n编写 DockerfileDockerfile 对于 Docker 的意义如同 POM 之于 Maven。\n在 pom.xml 同级目录新建文件 Dockerfile。\n# 基础运行环境，建议采用 openjdk alpine 作为基础的镜像FROM openjdk:8-jdk-alpine# 标记作者LABEL maintainer=&quot;fuyongde@foxmail.com&quot;# 挂载 /tmp 目录，因为 Spring Boot 内嵌的 Tomcat 默认使用 /tmp 作为工作目录VOLUME [ &quot;/tmp&quot; ]# 容器对外映射 8080 端口EXPOSE 8080# 定义要打包的 jarARG JAR_FILE=target/thanos-0.0.1-SNAPSHOT.jar# 将指定的 jar 添加到目标镜像并重命名ADD $&#123;JAR_FILE&#125; thanos-0.0.1.jar# 使用 java -jar 命令运行目标程序ENTRYPOINT [ &quot;java&quot;, &quot;-jar&quot;, &quot;/thanos-0.0.1.jar&quot; ]\n\n\nFROM：指定一个构建镜像的基础源镜像，如果本地没有就会从公共库中拉取，没有指定镜像的标签会使用默认的 latest 标签，如果需要在一个 Dockerfile 中构建多个镜像，该选项可以出现多次。\nLABEL：为镜像指定标签\nVOLUME：可实现挂载功能，可以将内地文件夹或者其他容器种得文件夹挂在到这个容器种\nEXPOSE：暴漏容器运行时的监听端口给外部，但是 EXPOSE 并不会使容器访问主机的端口，如果想使得容器与主机的端口有映射关系，必须在容器启动的时候加上 -p 参数\nARG：设置变量\nADD：将文件添加到目标镜像中\nENTRYPOINT：启动时的默认命令\n\n构建 Docker 镜像由于 Docker 依赖我们程序编译的结果，故在构建 Docker 镜像之前，需要先构建我们的工程。\n如本文所讲例子，需要依次执行\n# 采用 Maven 构建 Spring Boot Applicationmvnw install# 构建 Docker Imagedocker build -t thanos .\n\n构建完成之后，可以通过 docker image ls 查看。\nREPOSITORY    TAG       IMAGE ID        CREATED              SIZEthanos        latest    5f30b11b5088    About an hour ago    122MB\n\n运行 Docker 镜像和正常的运行 Docker 镜像的命令一致。\ndocker run -p 8080:8080 thanos# 也可以采用后台运行的方式运行容器docker run -d -p 8080:8080 thanos\n\n运行之后，通过 docker ps 命令来查看当前运行的容器。\nCONTAINER ID   IMAGE    COMMAND                  CREATED             STATUS             PORTS                    NAMES9f20a76e22fa   thanos   &quot;java -jar /thanos-0…&quot;   About an hour ago   Up About an hour   0.0.0.0:8080-&gt;8080/tcp   xenodochial_noyce\n\n将 Docker 镜像推送到镜像仓库由于众所周知的原因，我们访问 docker hub 并不稳定，而且速度比较慢，本文采用阿里云的容器镜像服务。\n\n登录到阿里云容器镜像服务\n\n# 登录docker login --username=fuyongde@foxmail.com registry.cn-hangzhou.aliyuncs.com# 输入密码，当看到 Login Succeeded 表示登录成功\n\n\n为当前镜像打 tag\n\ndocker tag thanos registry.cn-hangzhou.aliyuncs.com/fuyongde/thanos:v1\n\n\n推送到容器镜像服务\n\ndocker push registry.cn-hangzhou.aliyuncs.com/fuyongde/thanos:v1\n\n按照上述步骤操作完成之后，登录到阿里云的控制台 &gt; 容器镜像服务 &gt; 镜像仓库 即可查看已经推送好的镜像。\ndockerfile-maven-plugin经过上述的操作我们发现，要将我们的 Spring Boot Application 打包为 Docker 镜像，必须先将我们的工程构建，然后才能执行 Docker 的 build、push。那么能否将工程的构建与 Docker 的操作合二为一呢？\n答案是肯定的，这就需要用到 dockerfile-maven-plugin。\n引入 dockerfile-maven-plugin基于上述工程，在 pom.xml 中添加插件：\n&lt;plugin&gt;    &lt;groupId&gt;com.spotify&lt;/groupId&gt;    &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;1.4.10&lt;/version&gt;    &lt;configuration&gt;        &lt;repository&gt;registry.cn-hangzhou.aliyuncs.com/fuyongde/thanos&lt;/repository&gt;        &lt;tag&gt;$&#123;project.version&#125;&lt;/tag&gt;        &lt;useMavenSettingsForAuth&gt;true&lt;/useMavenSettingsForAuth&gt;    &lt;/configuration&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;default&lt;/id&gt;            &lt;phase&gt;install&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;build&lt;/goal&gt;                &lt;goal&gt;push&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n其中：\n\nrepository：表示要上传的容器镜像服务，可以是阿里云、Docker Hub 等\ntag：镜像打包的 tag\nexecution：这个标签下的配置表示，在 Maven 的 install 阶段，进行 Docker 的 build、push 操作\nuseMavenSettingsForAuth：表示使用 Maven 的配置的账号密码来认证 Docker 容器镜像服务，需要在 Maven 的 settings.xml 文件中加入以下配置：\n\n&lt;servers&gt;    &lt;server&gt;        &lt;id&gt;registry.cn-hangzhou.aliyuncs.com&lt;/id&gt;        &lt;username&gt;username&lt;/username&gt;        &lt;password&gt;password&lt;/password&gt;    &lt;/server&gt;&lt;/servers&gt;\n\n构建执行 mvn install 命令，Docker 镜像就打包并上传好了 ✌。\nOne more thing你以为上述构建 Docker 镜像方法就非常方便了吗？\nToo young!\n下一篇，带你了解 Jib，Make docker simple again✨!\n","tags":["Docker","Spring Boot"]},{"title":"Dubbo 中的负载均衡策略","url":"/2019/11/16/dubbo-loadbalance/","content":"Dubbo 内置了 4 种负载均衡策略\n\nRandomLoadBalance：随机负载均衡，随机选择一个服务结点，跟权重相关。该策略是 Dubbo 的默认负载均衡策略。\nRoundRobinLoadBalance：轮询负载均衡，轮询选择一个服务结点，跟权重相关。\nLeastActiveLoadBalance：最少活跃调用数，相同的活跃数随机选择一个结点，跟权重相关。实现方式是对活跃数值前后计数差。使得慢的结点收到更少的请求，因为越慢的结点前后计数差越大。\nConsistentHashLoadBalance：一致性哈希负载均衡，即相同的参数的请求总是落在同一个服务结点上。\n\n通过观察类之间依赖图，可以快速帮我们梳理其之间的关系，如下图所示：\n\n\n实践\n纸上得来终觉浅，觉知此时要躬行。\n\nDubbo 中负载均衡的源码可自行通过源码来学习，为了加深印象，这里我以 Dubbo 源码中的思路来实现这四个负载均衡策略。\n准备工作定义结点接口这里我们不实现 Dubbo 中的 Invoker，以一个结点类 Endpoint 代替。\nEndpoint.java\npublic interface Endpoint &#123;    /**     * hello方法     *     * @param param 参数     */    void hello(String param);    /**     * 获取结点名称     *     * @return 结点名称     */    String name();    /**     * 获取结点权重     *     * @return 结点权重     */    int weight();&#125;\n\n实现多个结点这里我们分别实现 S0, S1, S2 三个结点，代码如下：\nS0Endpoint.java\npublic class S0Endpoint implements Endpoint &#123;    @Override    public void hello(String param) &#123;        System.out.println(&quot;S0 -&gt; &quot; + param);    &#125;    @Override    public String name() &#123;        return &quot;S0&quot;;    &#125;    @Override    public int weight() &#123;        return 3;    &#125;&#125;\n\nS1Endpoint.java\npublic class S1Endpoint implements Endpoint &#123;    @Override    public void hello(String param) &#123;        System.out.println(&quot;S1 -&gt; &quot; + param);    &#125;    @Override    public String name() &#123;        return &quot;S1&quot;;    &#125;    @Override    public int weight() &#123;        return 2;    &#125;&#125;\n\nS2Endpoint.java\npublic class S2Endpoint implements Endpoint &#123;    @Override    public void hello(String param) &#123;        System.out.println(&quot;S2 -&gt; &quot; + param);    &#125;    @Override    public String name() &#123;        return &quot;S2&quot;;    &#125;    @Override    public int weight() &#123;        return 1;    &#125;&#125;\n\n定义负载均衡的接口以及抽象类LoadBalance.java\npublic interface LoadBalance &#123;    Endpoint select(List&lt;Endpoint&gt; endpoints, String param);&#125;\n\nAbstractLoadBalance.java\npublic abstract class AbstractLoadBalance implements LoadBalance &#123;    @Override    public Endpoint select(List&lt;Endpoint&gt; endpoints, String param) &#123;        if (Objects.isNull(endpoints) || endpoints.size() == 0) &#123;            throw new RuntimeException(&quot;没有可用的结点&quot;);        &#125;        if (endpoints.size() == 1) &#123;            return endpoints.get(0);        &#125;        return doSelect(endpoints, param);    &#125;    protected abstract Endpoint doSelect(List&lt;Endpoint&gt; endpoints, String param);    int getWeight(Endpoint endpoint) &#123;        return endpoint.weight();    &#125;&#125;\n\n程序入口public class App &#123;    public static void main(String[] args) &#123;        List&lt;Endpoint&gt; endpoints = Lists.newArrayList(new S0Endpoint(), new S1Endpoint(), new S2Endpoint());        // 需要演示哪种负载均衡策略，替换为对应的实现类即可        LoadBalance loadBalance = new RoundRobinLoadBalance();        for (int i = 0; i &lt; 18; i++) &#123;            Endpoint endpoint = loadBalance.select(endpoints, &quot;LoanBance&quot;);            endpoint.hello(&quot;LoadBance&quot;);        &#125;    &#125;&#125;\n\n随机负载均衡Dubbo 中随机负载均衡策略，会受每个服务结点权重的影响。由于随机负载均衡策略的实现比较简单，每一步的作用，可查看注释，这里就不详细讲解。代码如下：\nRandomLoadBalance.java\npublic class RandomLoadBalance extends AbstractLoadBalance &#123;    @Override    protected Endpoint doSelect(List&lt;Endpoint&gt; endpoints, String param) &#123;        // 先获取结点总数        int length = endpoints.size();        // 每个结点权重是否相等        boolean sameWeight = true;        // 每个计算器的权重        int[] weights = new int[length];        // 获取第一个计算器的权重，Dubbo 中权重会从 Invoker 中取        int firstWeight = getWeight(endpoints.get(0));        weights[0] = firstWeight;        int totalWeight = firstWeight;        for (int i = 1; i &lt; length; i++) &#123;            // 获取后续每一个结点的权重，用于判断所有结点权重是否相等            int weight = getWeight(endpoints.get(i));            weights[i] = weight;            totalWeight += weight;            if (sameWeight &amp;&amp; weight != firstWeight) &#123;                sameWeight = false;            &#125;        &#125;        if (totalWeight &gt; 0 &amp;&amp; !sameWeight) &#123;            // 若各个结点权重不相等，则随机一个[0~总权重数]之间的数值            int offset = ThreadLocalRandom.current().nextInt(totalWeight);            for (int i = 0; i &lt; length; i++) &#123;                offset -= weights[i];                if (offset &lt; 0) &#123;                    return endpoints.get(i);                &#125;            &#125;        &#125;        return endpoints.get(ThreadLocalRandom.current().nextInt(length));    &#125;&#125;\n\n将程序入口中的负载均衡替换为随机负载均衡的实现类，其输出如下：\nS0 -&gt; LoadBanceS0 -&gt; LoadBanceS2 -&gt; LoadBanceS0 -&gt; LoadBanceS0 -&gt; LoadBanceS0 -&gt; LoadBanceS2 -&gt; LoadBanceS0 -&gt; LoadBanceS0 -&gt; LoadBanceS1 -&gt; LoadBanceS1 -&gt; LoadBanceS0 -&gt; LoadBanceS1 -&gt; LoadBanceS0 -&gt; LoadBanceS1 -&gt; LoadBanceS0 -&gt; LoadBanceS0 -&gt; LoadBanceS1 -&gt; LoadBance\n\n可发现其调用每个结点的规律大致与所占权重的比例相同。\n轮询负载均衡轮询负载均衡就是依次调用所有的服务结点，和随机负载均衡一样轮询负载均衡也有权重的概念。轮询负载均衡算法可以让服务调用严格的按照我们设置的权重比例来分配，并且跟调用的次数无关。缺点是慢的结点会累计请求，从而导致整个系统变慢。\npublic class RoundRobinLoadBalance extends AbstractLoadBalance &#123;    /** 在内存中存储所有的 服务名+方法 **/    private ConcurrentMap&lt;String, ConcurrentMap&lt;String, WeightedRoundRobin&gt;&gt; methodWeightMap = new ConcurrentHashMap&lt;&gt;();    /** 保证原子性 **/    private AtomicBoolean updateLock = new AtomicBoolean();    /** 默认的回收期，设置为1分钟 **/    private static final int RECYCLE_PERIOD = 60000;    @Override    protected Endpoint doSelect(List&lt;Endpoint&gt; endpoints, String param) &#123;        System.out.println(&quot;-----------------------------------------------------------------&quot;);        // Dubbo 中这个 Key 值是通过解析 Invoker 被调用的服务URL+方法名以及对应的参数而拼装的字符串，这里为了演示，直接写死        String key = &quot;com.exp.Endpoint.add&quot;;        ConcurrentMap&lt;String, WeightedRoundRobin&gt; map = methodWeightMap.get(key);        if (Objects.isNull(map)) &#123;            // 若没有该 key 值的权重信息，则说明是第一次调用，创建新的放入methodWeightMap即可            methodWeightMap.putIfAbsent(key, new ConcurrentHashMap&lt;&gt;());            map = methodWeightMap.get(key);        &#125;        // 总权重        int totalWeight = 0;        // 当前最大权重，初始值设为 Long 类型最小值        long maxCurrent = Long.MIN_VALUE;        // 记录当前时间        long now = System.currentTimeMillis();        // 被选择的结点        Endpoint selectedEndpoint = null;        // 被选择的结点的权重轮询信息        WeightedRoundRobin selectedWRR = null;        for (Endpoint endpoint : endpoints) &#123;            String name = endpoint.name();            WeightedRoundRobin weightedRoundRobin = map.get(name);            int weight = getWeight(endpoint);            if (Objects.isNull(weightedRoundRobin)) &#123;                weightedRoundRobin = new WeightedRoundRobin();                weightedRoundRobin.setWeight(weight);                map.putIfAbsent(name, weightedRoundRobin);            &#125;            if (weight != weightedRoundRobin.getWeight()) &#123;                weightedRoundRobin.setWeight(weight);            &#125;            // 对权重进行加权操作（其实就上次内存中该节点的权重 + 该节点的真实权重），计算出该次调用该节点的权重            long cur = weightedRoundRobin.increaseCurrent();            System.out.println(String.format(&quot;节点%s -&gt; 内存中权重：%s，真实权重：%s，该次调用权重：%s，当前最大权重：%s&quot;, name, weightedRoundRobin.current, weight, cur, maxCurrent));            weightedRoundRobin.setLastUpdate(now);            if (cur &gt; maxCurrent) &#123;                maxCurrent = cur;                selectedEndpoint = endpoint;                selectedWRR = weightedRoundRobin;            &#125;            totalWeight += weight;        &#125;        if (!updateLock.get() &amp;&amp; endpoints.size() != map.size()) &#123;            // 若 methodWeightMap 中该该服务+方法的节点数据量与内存中的不一致            if (updateLock.compareAndSet(false, true)) &#123;                try &#123;                    ConcurrentMap&lt;String, WeightedRoundRobin&gt; newMap = new ConcurrentHashMap&lt;&gt;();                    newMap.entrySet().removeIf(item -&gt; now - item.getValue().getLastUpdate() &gt; RECYCLE_PERIOD);                    methodWeightMap.put(key, newMap);                &#125; finally &#123;                    updateLock.set(false);                &#125;            &#125;        &#125;        if (Objects.nonNull(selectedEndpoint)) &#123;            long tmpWeight = selectedWRR.current.get();            selectedWRR.sel(totalWeight);            System.out.println(String.format(&quot;本地调用选择 %s，同时调整 %s 节点在内存中的权重为 %s - %s = %s&quot;, selectedEndpoint.name(), selectedEndpoint.name(), tmpWeight, totalWeight, selectedWRR.current));            System.out.println(&quot;此时内存中各节点权重：&quot;);            map.entrySet().forEach(item-&gt; System.out.println(String.format(&quot;  %s -&gt; 权重：%s&quot;, item.getKey(), item.getValue().current)));            System.out.println(&quot;-----------------------------------------------------------------&quot;);            return selectedEndpoint;        &#125;        System.out.println(&quot;-----------------------------------------------------------------&quot;);        return endpoints.get(0);    &#125;    /**     * 该对象用于计算每次调用各个结点的权重信息     */    protected static class WeightedRoundRobin &#123;        /** 每次调用时结点当次的权重值 **/        private AtomicLong current = new AtomicLong(0);        /** 各个结点的真实权重 **/        private int weight;        /** 最后一次更新的时间 **/        private long lastUpdate;        public int getWeight() &#123;            return weight;        &#125;        public void setWeight(int weight) &#123;            this.weight = weight;        &#125;        public long getLastUpdate() &#123;            return lastUpdate;        &#125;        public void setLastUpdate(long lastUpdate) &#123;            this.lastUpdate = lastUpdate;        &#125;        public long increaseCurrent() &#123;            return current.addAndGet(weight);        &#125;        public void sel(int total) &#123;            current.addAndGet(-1 * total);        &#125;        public AtomicLong getCurrent() &#123;            return current;        &#125;    &#125;&#125;\n\n为了方便的观察每次调用各个结点的是如何选择的，程序中打印了对应的日志。修改程序入口中的负载均衡策略为轮询负载均衡，观察其输出：\n-----------------------------------------------------------------节点S0 -&gt; 内存中权重：3，真实权重：3，该次调用权重：3，当前最大权重：-9223372036854775808节点S1 -&gt; 内存中权重：2，真实权重：2，该次调用权重：2，当前最大权重：3节点S2 -&gt; 内存中权重：1，真实权重：1，该次调用权重：1，当前最大权重：3本地调用选择 S0，同时调整 S0 节点在内存中的权重为 3 - 6 = -3此时内存中各节点权重：  S0 -&gt; 权重：-3  S1 -&gt; 权重：2  S2 -&gt; 权重：1-----------------------------------------------------------------S0 -&gt; LoadBance-----------------------------------------------------------------节点S0 -&gt; 内存中权重：0，真实权重：3，该次调用权重：0，当前最大权重：-9223372036854775808节点S1 -&gt; 内存中权重：4，真实权重：2，该次调用权重：4，当前最大权重：0节点S2 -&gt; 内存中权重：2，真实权重：1，该次调用权重：2，当前最大权重：4本地调用选择 S1，同时调整 S1 节点在内存中的权重为 4 - 6 = -2此时内存中各节点权重：  S0 -&gt; 权重：0  S1 -&gt; 权重：-2  S2 -&gt; 权重：2-----------------------------------------------------------------S1 -&gt; LoadBance-----------------------------------------------------------------节点S0 -&gt; 内存中权重：3，真实权重：3，该次调用权重：3，当前最大权重：-9223372036854775808节点S1 -&gt; 内存中权重：0，真实权重：2，该次调用权重：0，当前最大权重：3节点S2 -&gt; 内存中权重：3，真实权重：1，该次调用权重：3，当前最大权重：3本地调用选择 S0，同时调整 S0 节点在内存中的权重为 3 - 6 = -3此时内存中各节点权重：  S0 -&gt; 权重：-3  S1 -&gt; 权重：0  S2 -&gt; 权重：3-----------------------------------------------------------------S0 -&gt; LoadBance-----------------------------------------------------------------节点S0 -&gt; 内存中权重：0，真实权重：3，该次调用权重：0，当前最大权重：-9223372036854775808节点S1 -&gt; 内存中权重：2，真实权重：2，该次调用权重：2，当前最大权重：0节点S2 -&gt; 内存中权重：4，真实权重：1，该次调用权重：4，当前最大权重：2本地调用选择 S2，同时调整 S2 节点在内存中的权重为 4 - 6 = -2此时内存中各节点权重：  S0 -&gt; 权重：0  S1 -&gt; 权重：2  S2 -&gt; 权重：-2-----------------------------------------------------------------S2 -&gt; LoadBance-----------------------------------------------------------------节点S0 -&gt; 内存中权重：3，真实权重：3，该次调用权重：3，当前最大权重：-9223372036854775808节点S1 -&gt; 内存中权重：4，真实权重：2，该次调用权重：4，当前最大权重：3节点S2 -&gt; 内存中权重：-1，真实权重：1，该次调用权重：-1，当前最大权重：4本地调用选择 S1，同时调整 S1 节点在内存中的权重为 4 - 6 = -2此时内存中各节点权重：  S0 -&gt; 权重：3  S1 -&gt; 权重：-2  S2 -&gt; 权重：-1-----------------------------------------------------------------S1 -&gt; LoadBance-----------------------------------------------------------------节点S0 -&gt; 内存中权重：6，真实权重：3，该次调用权重：6，当前最大权重：-9223372036854775808节点S1 -&gt; 内存中权重：0，真实权重：2，该次调用权重：0，当前最大权重：6节点S2 -&gt; 内存中权重：0，真实权重：1，该次调用权重：0，当前最大权重：6本地调用选择 S0，同时调整 S0 节点在内存中的权重为 6 - 6 = 0此时内存中各节点权重：  S0 -&gt; 权重：0  S1 -&gt; 权重：0  S2 -&gt; 权重：0-----------------------------------------------------------------S0 -&gt; LoadBance...\n\n通过观察可发现，S0、S1、S2结点的选择确实是严格按照其对应的权重比例来进行分配的。\n最少活跃调用数负载均衡最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差，使慢的机器收到更少。\nDubbo 中计算活跃调用数是通过 Dubbo 的 Filter 机制来实现的。具体可以参考 ActiveLimitFilter 类的源码。本文示例直接采用简单的调用前后的耗时进行累加来表示每个结点的活跃值。\n改造 Endpoint 接口由于最少活跃调用数需要获取活跃调用数，故 Endpoint 接口新增返回调用活跃数的方法。如下：\npublic interface Endpoint &#123;    /**     * hello方法     *     * @param param 参数     */    void hello(String param);    /**     * 获取节点名称     *     * @return 节点名称     */    String name();    /**     * 获取节点权重     *     * @return 节点权重     */    int weight();    /**     * 获取调用活跃数     *     * @return 调用活跃数     */    int active();&#125;\n\n各个结点实现类实现对活跃调用数的累加S0Endpoint.java\npublic class S0Endpoint implements Endpoint &#123;    private int activeValue = 0;    @Override    public void hello(String param) &#123;        long start = System.currentTimeMillis();        try &#123;            Thread.sleep(1);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;S0 -&gt; &quot; + param);        long remain = (System.currentTimeMillis() - start);        activeValue += remain;    &#125;    @Override    public String name() &#123;        return &quot;S0&quot;;    &#125;    @Override    public int weight() &#123;        return 3;    &#125;    @Override    public int active() &#123;        return activeValue;    &#125;&#125;\n\nS1Endpoint.java\npublic class S1Endpoint implements Endpoint &#123;    private int activeValue = 0;    @Override    public void hello(String param) &#123;        long start = System.currentTimeMillis();        try &#123;            Thread.sleep(1);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;S1 -&gt; &quot; + param);        long remain = (System.currentTimeMillis() - start);        activeValue += remain;    &#125;    @Override    public String name() &#123;        return &quot;S1&quot;;    &#125;    @Override    public int weight() &#123;        return 2;    &#125;    @Override    public int active() &#123;        return activeValue;    &#125;&#125;\n\nS2Endpoint.java\npublic class S2Endpoint implements Endpoint &#123;    private int activeValue = 0;    @Override    public void hello(String param) &#123;        long start = System.currentTimeMillis();        try &#123;            Thread.sleep(2);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        System.out.println(&quot;S2 -&gt; &quot; + param);        long remain = (System.currentTimeMillis() - start);        activeValue += remain;    &#125;    @Override    public String name() &#123;        return &quot;S2&quot;;    &#125;    @Override    public int weight() &#123;        return 1;    &#125;    @Override    public int active() &#123;        return activeValue;    &#125;&#125;\n\n实现最小活跃调用数的负载均衡类LeastActiveLoadBalance.java\npublic class LeastActiveLoadBalance extends AbstractLoadBalance &#123;    @Override    protected Endpoint doSelect(List&lt;Endpoint&gt; endpoints, String param) &#123;        System.out.println(&quot;-----------------------------------------------------------------&quot;);        // 总结点数        int length = endpoints.size();        // 所有结点的最小活动值        int leastActive = -1;        // 具有最小有效值的结点的数量        int leastCount = 0;        // 定义一个数组来存储每个结点的最小活跃数        int[] leastIndexes = new int[length];        // 权重数组        int[] weights = new int[length];        // 总权重        int totalWeight = 0;        // 最不活跃的结点的权重        int firstWeight = 0;        // 每个最不活跃的结点是否都具有相同的权重        boolean sameWeight = true;        // 过滤掉最不活跃的结点        for (int i = 0; i &lt; length; i++) &#123;            Endpoint endpoint = endpoints.get(i);            // 获取结点的活跃值，            int active = endpoint.active();            // Dubbo 中的结点活跃值是在ActiveLimitFilter这个类中计算的，            // 而本示例由于没有实现Filter机制与Listener机制，直接同步累加对应结点的调用耗时来实现            // 由于本示例的原因，i=0表示S0结点，i=1表示S1结点，i=2表示S2结点            System.out.println(String.format(&quot;i = %s, 活跃值：%s&quot;, i, active));            // 获取结点的权重            int weight = getWeight(endpoint);            weights[i] = weight;            // 从下面的逻辑可以看出若一个结点的活跃值越大，则不会添加到备选项中            // 如果它是第一个，或者结点的活动编号小于当前的最小活跃值            if (leastActive == -1 || active &lt; leastActive) &#123;                // 将最小活跃值赋值给 leastActive                leastActive = active;                leastCount = 1;                leastIndexes[0] = i;                System.out.println(String.format(&quot;i = %s，此时由于当前结点活跃值最小或该结点为第一遍历的结点&quot;, i));                totalWeight = weight;                firstWeight = weight;                sameWeight = true;            &#125; else if (active == leastActive) &#123;                System.out.println(String.format(&quot;i = %s，此时由于当前结点的活跃值等于最小活跃值&quot;, i));                // 若当前结点的活跃值与最小活跃值相同                leastIndexes[leastCount++] = i;                totalWeight += weight;                if (sameWeight &amp;&amp; i &gt; 0 &amp;&amp; weight != firstWeight) &#123;                    sameWeight = false;                &#125;            &#125;        &#125;        if (leastCount == 1) &#123;            return endpoints.get(leastIndexes[0]);        &#125;        if (!sameWeight &amp;&amp; totalWeight &gt; 0) &#123;            // 这里与随机负载均衡策略相同            int offsetWeight = ThreadLocalRandom.current().nextInt(totalWeight);            for (int i = 0; i &lt; leastCount; i++) &#123;                int leastIndex = leastIndexes[i];                offsetWeight -= weights[leastIndex];                if (offsetWeight &lt; 0) &#123;                    System.out.println(&quot;-----------------------------------------------------------------&quot;);                    return endpoints.get(leastIndex);                &#125;            &#125;        &#125;        System.out.println(&quot;-----------------------------------------------------------------&quot;);        return endpoints.get(leastIndexes[ThreadLocalRandom.current().nextInt(leastCount)]);    &#125;&#125;\n\n将程序入口中的负载均衡替换为随机负载均衡的实现类，其输出如下：\n-----------------------------------------------------------------i = 0, 活跃值：0i = 0，此时由于当前结点活跃值最小或该结点为第一遍历的结点i = 1, 活跃值：0i = 1，此时由于当前结点的活跃值等于最小活跃值i = 2, 活跃值：0i = 2，此时由于当前结点的活跃值等于最小活跃值-----------------------------------------------------------------S1 -&gt; LoadBance-----------------------------------------------------------------i = 0, 活跃值：0i = 0，此时由于当前结点活跃值最小或该结点为第一遍历的结点i = 1, 活跃值：1i = 2, 活跃值：0i = 2，此时由于当前结点的活跃值等于最小活跃值-----------------------------------------------------------------S0 -&gt; LoadBance-----------------------------------------------------------------i = 0, 活跃值：2i = 0，此时由于当前结点活跃值最小或该结点为第一遍历的结点i = 1, 活跃值：1i = 1，此时由于当前结点活跃值最小或该结点为第一遍历的结点i = 2, 活跃值：0i = 2，此时由于当前结点活跃值最小或该结点为第一遍历的结点-----------------------------------------------------------------S2 -&gt; LoadBance...\n\n通过观察日志可发现，确实实现了最少活跃调用数有限，相同最小活跃数的则随机\n一致性哈希负载均衡Dubbo 中的一致性哈希负载均衡是唯一一个与权重无关的负载均衡算法。使用一致性 Hash 算法，让相同参数的请求总是发到同一结点，当某一结点崩溃时，原本发往该结点的请求，基于虚拟节点，平摊到其它结点，不会引起剧烈变动。\npublic class ConsistentHashLoadBalance extends AbstractLoadBalance &#123;    private final ConcurrentMap&lt;String, ConsistentHashSelector&gt; selectors = new ConcurrentHashMap&lt;&gt;();    @Override    protected Endpoint doSelect(List&lt;Endpoint&gt; endpoints, String param) &#123;        // Dubbo中这个Key值的含义是被调用的服务名+方法名组成的字符串，与轮询随机算法一致        String key = &quot;com.exp.Endpoint.add&quot;;        // identityHashCode 是为了防止新增结点或部分结点失效的问题        int identityHashCode = System.identityHashCode(endpoints);        System.out.println(String.format(&quot;identityHashCode : %s&quot;, identityHashCode));        ConsistentHashSelector selector = selectors.get(key);        if (selector == null || selector.identityHashCode != identityHashCode) &#123;            selectors.put(key, new ConsistentHashSelector(endpoints, identityHashCode));            selector = selectors.get(key);        &#125;        return selector.select(param);    &#125;    private static final class ConsistentHashSelector &#123;        /** 存放结点信息的Map **/        private final TreeMap&lt;Long, Endpoint&gt; virtualEndpoints;        /** 对结点列表取的hashCode **/        private final int identityHashCode;        /** 虚拟结点个数 **/        private final int replicaNumber;        public ConsistentHashSelector(List&lt;Endpoint&gt; endpoints, int identityHashCode) &#123;            this.virtualEndpoints = new TreeMap&lt;&gt;();            this.identityHashCode = identityHashCode;            // Dubbo 默认的虚拟结点个数是160，也可以通过配置文件修改            this.replicaNumber = 4;            // 注意：Dubbo在构建 ConsistentHashSelector 对象时会获取对参数的下标值，用于后续对参数做哈希，            // 这里我们示例比较简单，直接对所有参数做哈希            for (Endpoint endpoint : endpoints) &#123;                for (int i = 0; i &lt; replicaNumber / 4; i++) &#123;                    byte[] digest = md5(endpoint.name() + i);                    for (int j = 0; j &lt; 4; j++) &#123;                        long m = hash(digest, j);                        virtualEndpoints.put(m, endpoint);                    &#125;                &#125;            &#125;        &#125;        public Endpoint select(String param) &#123;            byte[] digest = md5(param);            // 这里的哈希算法不要采用 java.util.Objects.hash的哈希算法            long key = hash(digest, 0);            System.out.println(String.format(&quot;param key : %s&quot;, key));            return selectForKey(key);        &#125;        private Endpoint selectForKey(long hash) &#123;            Map.Entry&lt;Long, Endpoint&gt; entry = virtualEndpoints.ceilingEntry(hash);            if (entry == null) &#123;                entry = virtualEndpoints.firstEntry();            &#125;            return entry.getValue();        &#125;        private long hash(byte[] digest, int number) &#123;            return (((long) (digest[3 + number * 4] &amp; 0xFF) &lt;&lt; 24)                    | ((long) (digest[2 + number * 4] &amp; 0xFF) &lt;&lt; 16)                    | ((long) (digest[1 + number * 4] &amp; 0xFF) &lt;&lt; 8)                    | (digest[number * 4] &amp; 0xFF))                    &amp; 0xFFFFFFFFL;        &#125;        private byte[] md5(String value) &#123;            MessageDigest md5;            try &#123;                md5 = MessageDigest.getInstance(&quot;MD5&quot;);            &#125; catch (NoSuchAlgorithmException e) &#123;                throw new IllegalStateException(e.getMessage(), e);            &#125;            md5.reset();            byte[] bytes = value.getBytes(StandardCharsets.UTF_8);            md5.update(bytes);            return md5.digest();        &#125;    &#125;&#125;\n\n替换程序入口中的负载均衡算法为一致性哈希负载均衡的实现类，观察输出\nidentityHashCode : 1018547642param key : 119807787S1 -&gt; LoadBanceidentityHashCode : 1018547642param key : 119807787S1 -&gt; LoadBanceidentityHashCode : 1018547642param key : 119807787S1 -&gt; LoadBance...\n\n通过观察发现对于相同的参数，程序永远调用了 S1 结点。\n","tags":["Dubbo","负载均衡","微服务"]},{"title":"RPC 进阶 - 线程池","url":"/2019/07/16/edith-with-thread-pool/","content":"在 Rpc Introduction 中简单写了一个 RPC Framework。在本节中，对 Edith 新增采用线程池支持多线程的特性。\n背景实际开发中，我们的应用程序是不能盲目的开辟线程的，这样会造成资源的极大浪费。若采用线程池，可以减少创建和销毁线程的次数，让每个线程可以多次使用，并且可以根据系统的承受能力，调整线程池中工作线程的数量，方式消耗过多的内存。\n如有需要可以阅读 Dubbo 中关于线程池的设计（位于 org.apache.dubbo.common.threadpool 包）。\n开发依赖&lt;dependency&gt;    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;    &lt;artifactId&gt;guava&lt;/artifactId&gt;&lt;/dependency&gt;\n\nCode本文代码可以从这里获取。\n新增 ThreadUtils.java用于创建 ExecutorService\npublic class ThreadUtils &#123;    /**     * 用于对线程分配一个名字，方便排查问题     * @param format format     * @return Edith-1     */    private static ThreadFactory buildThreadFactory(String format) &#123;        return new ThreadFactoryBuilder().setNameFormat(format).build();    &#125;    public static ExecutorService newCachedThreadPool(int maximumPoolSize) &#123;        return new ThreadPoolExecutor(THREAD_CORE_POOL_SIZE, maximumPoolSize &gt; 0 ? maximumPoolSize : THREAD_MAXIMUM_POOL_SIZE,                Long.MAX_VALUE, TimeUnit.MICROSECONDS, new SynchronousQueue&lt;&gt;(), buildThreadFactory(THREAD_NAME), new ThreadPoolExecutor.AbortPolicy());    &#125;&#125;\n\n修改 RpcFramework.java将原代码中 new Thread() 部分替换为线程池。\nprivate static final ExecutorService executorService = ThreadUtils.newCachedThreadPool(0);public static void export(final Object service, int port) throws Exception &#123;    Objects.requireNonNull(service, &quot;Service instance is null!&quot;);    if (port &lt;= PORT_MIN || port &gt; PORT_MAX) &#123;        throw new IllegalArgumentException(&quot;Invalid port &quot; + port);    &#125;    System.out.println(&quot;Export service &quot; + service.getClass().getName() + &quot; on port &quot; + port);    ServerSocket server = new ServerSocket(port);    for (; ; ) &#123;        System.out.println(&quot;application is running&quot;);        Socket socket = server.accept();        executorService.execute(() -&gt; &#123;            // do something ...        &#125;);    &#125;&#125;\n\n经过以上修改，我们在例子中的 HelloServiceImpl 打印一下线程名称\n@Overridepublic String hello(String name) &#123;    String result = &quot;Hello &quot; + name;    System.out.println(Thread.currentThread().getName() + &quot; &quot; + result);    return result;&#125;\n\n启动 provider，然后用 consumer 调用一次，观察 provider 的控制台输出\nEdith-0 Hello Peter Parker\n\nDone.\n","tags":["rpc"]},{"title":"git 恢复已删除的分支","url":"/2020/03/26/git-%E6%81%A2%E5%A4%8D%E5%B7%B2%E5%88%A0%E9%99%A4%E7%9A%84%E5%88%86%E6%94%AF/","content":"在日常开发中，如果我们一不小心删除了某个分支，又想重新使用这个分支，该怎么找回该分支上的代码呢？\n场景还原\n有一个 git 仓库，从 master 分支新建 feature/delete_branch 分支，并进行一次提交，如下：\n\n# 新建一个 feature/delete_branch 分支git branch feature/delete_branch# 切换到 feature/delete_branch 分支git checkout feature/delete_branch# 新建一个文件，进行一次提交并推送至远程分支git add delete-file.mdgit commit -m &#x27;:sparkles: add a delete-file.md file&#x27;git push origin feature/delete_branch:feature/delete_branch# 查看当前分支图git log --all --decorate --oneline --graph* 88ac246 (HEAD -&gt; feature/delete_branch, origin/feature/delete_branch) :sparkles: add a delete-file.md file* 8693480 (origin/master, master) :sparkles: add a hello-git.md file\n\n\n切换到 master 分支，并删除 feature/delete_branch 分支\n\n# 切换到 master 分支git checkout master# 删除 feature/delete_branch 分支git branch -d feature/delete_branch# 将删除操作同步至远程git push origin --delete feature/delete_branch# 此时无论是本地还是远程都已经删除了 feature/delete_branchgit log --all --decorate --oneline --graph* 8693480 (HEAD -&gt; master, origin/master) :sparkles: add a hello-git.md file\n\n还原删除的分支\n通过 git reflog 或 git log -g 命令找到我们需要恢复的 commit id\n\n# 这里演示 git reflog 命令展示出来的提交git reflog8693480 (HEAD -&gt; master, origin/master) HEAD@&#123;0&#125;: checkout: moving from feature/delete_branch to master88ac246 (feature/delete_branch) HEAD@&#123;1&#125;: commit: :sparkles: add a delete-file.md file8693480 (HEAD -&gt; master, origin/master) HEAD@&#123;2&#125;: checkout: moving from master to feature/delete_branch8693480 (HEAD -&gt; master, origin/master) HEAD@&#123;3&#125;: commit (initial): :sparkles: add a hello-git.md file# 这里演示 git log -g 命令展示出来的提交git log -gcommit 86934803092ae7ae7266f9ebff3429437e423b80 (HEAD -&gt; master, origin/master)Reflog: HEAD@&#123;0&#125; (fuyongde &lt;fuyongde@foxmail.com&gt;)Reflog message: checkout: moving from feature/delete_branch to masterAuthor: fuyongde &lt;fuyongde@foxmail.com&gt;Date:   Thu Mar 26 18:36:35 2020 +0800    :sparkles: add a hello-git.md filecommit 88ac246020a0cc25071fb7fd3ac88363f4bf2beb (feature/delete_branch)Reflog: HEAD@&#123;1&#125; (fuyongde &lt;fuyongde@foxmail.com&gt;)Reflog message: commit: :sparkles: add a delete-file.md fileAuthor: fuyongde &lt;fuyongde@foxmail.com&gt;Date:   Thu Mar 26 18:44:01 2020 +0800    :sparkles: add a delete-file.md filecommit 86934803092ae7ae7266f9ebff3429437e423b80 (HEAD -&gt; master, origin/master)Reflog: HEAD@&#123;2&#125; (fuyongde &lt;fuyongde@foxmail.com&gt;)Reflog message: checkout: moving from master to feature/delete_branchAuthor: fuyongde &lt;fuyongde@foxmail.com&gt;Date:   Thu Mar 26 18:36:35 2020 +0800    :sparkles: add a hello-git.md filecommit 86934803092ae7ae7266f9ebff3429437e423b80 (HEAD -&gt; master, origin/master)Reflog: HEAD@&#123;3&#125; (fuyongde &lt;fuyongde@foxmail.com&gt;)Reflog message: commit (initial): :sparkles: add a hello-git.md fileAuthor: fuyongde &lt;fuyongde@foxmail.com&gt;Date:   Thu Mar 26 18:36:35 2020 +0800    :sparkles: add a hello-git.md file\n\n\n通过 git branch [branch name] [commit id] 命令来恢复删除的分支\n\n# 恢复 feature/delete_branch 分支到 88ac246 版本git branch feature/delete_branch 88ac246# 检出 feature/delete_branch 分支git checkout feature/delete_branch# 此时可以看到已经删除的分支都找回来了，将分支推送到远程git push origin feature/delete_branch:feature/delete_branch\n\n原因当我们删除一个分支时，git 只是删除了指向相关提交的指针，但该提交对象依然会留在版本库中，因此，如果我们知道删除分支时的 commit id，就可以将某个删除的分支恢复过来。\n注意事项\n通过这种方式恢复分支有时间限制，Git会定期清理无法访问的对象\n无论是使用 git branch -d 还是 git branch -D 删除的分支，都可以通过这种方式恢复\n如果远程分支被删除，需要有相应的权限才能重新推送分支到远程仓库\n\n","tags":["git","骚操作"]},{"title":"Gradle 手册","url":"/2020/03/08/gradle-%E6%89%8B%E5%86%8C/","content":"Gradle 是什么\nGradle is an open-source build automation tool focused on flexibility and performance. Gradle build scripts are written using a Groovy or Kotlin DSL. Read about Gradle features to learn what is possible with Gradle.\n\nGradle 是一个专注于灵活性和性能的开源自动化构建工具，其脚本由 Groovy 或 Kotlin DSL 编写。Gradle 有以下特性：\n\n高度可定制：Gradle 采用可以高度自定义的方式进行建模。\n快速：Gradle 通过重用旧的输出、仅变更的输入以及并行的方式来快速完成任务。\n功能强大：Gradle 是 Android 的官方构建工具，并附带对许多流行语言和技术的支持。\n\n安装安装之前，请确保已经正确安装 JDK8 或更高版本\n使用包管理器安装针对类 Unix 系统（macOS、Linux、Cygwin、Solaris 和 FreeBSD）可以采用以下两种包管理的方式安装。\n\nSDKMAN 包管理器\n\nsdk install gradle\n\n\nHomebrew 包管理器\n\nbrew install gradle\n\n手动安装\n下载指定的 Gradle 发行版，下载地址可参考发布页\n解压缩到指定的目录，如 Windows 系统中的 C:\\gradle 或 Linux 系统中的 /opt/gradle 等\n配置环境变量\n\n\n针对 Windows 系统，打开 控制面板 &gt; 系统和安全 &gt; 系统 &gt; 高级系统设置 &gt; 环境变量 &gt; 系统变量，新增 GRADLE_HOME 变量，该变量指向 Gradle 的安装路径，然后选中系统变量中的 Path，并新增 %GRADLE_HOME%\\bin\\\n针对 Linux 系统，在 ~/.bashrc 或 ~/.profile 文件中添加以下内容：export GRADLE_HOME=/opt/gradle/gradle-[version]export PATH=$PATH:$GRADLE_HOME/bin\n\n除了配置环境变量之外，还可以配置 GRADLE_USER_HOME 变量来指定 Gradle 的库文件的目录，该变量缺省值为当前系统用户目录下的 .gradle 目录。\n验证在命令行中执行 gradle -v 命令，若输出为你安装的版本信息，则说明安装成功了。\n使用 Gradle 构建一个项目\n新建一个目录 mkdir hello-world\n进入该目录 cd hello-world\n使用 Gradle 初始化该目录 gradle init。执行完该命令之后按照指引选择要初始化工程的类型等。之后可以得到一个至少包含以下路径的目录结构。\n\n├── build.gradle├── gradle│   └── wrapper│       ├── gradle-wrapper.jar│       └── gradle-wrapper.properties├── gradlew├── gradlew.bat└── settings.gradle\n\n看到 gradlew、gradlew.bat 以及 wrapper 目录是不是有点熟悉？没错，这个和 Maven Wrapper 的思想是一样的，可参考 Maven Wrapper 手册这篇文章。\nGradle WrapperGradle Wrapper 的作用是让团队成员无需预先安装 Gradle 环统即可构建项目，保证所有成员使用相同版本的 Gradle。其核心是以下文件：\n\ngradlew：Unix 系统的 shell 脚本\ngradlew.bat：Windows 系统的批处理脚本\ngradle/wrapper/gradle-wrapper.jar：Wrapper 的可执行 JAR 文件\ngradle/wrapper/gradle-wrapper.properties：配置文件，指定使用的 Gradle 版本\n\n使用 Gradle Wrapper 运行构建时，使用 ./gradlew（Unix）或 gradlew.bat（Windows）代替直接使用 gradle 命令。\n未完待续…\n","categories":["手册"],"tags":["未完待续","Gradle","构建工具"]},{"title":"如何使用 Java 的 HttpClient 请求 Https 服务","url":"/2020/12/10/how-use-httpclient-over-https/","content":"近期收到一些小伙伴问 Java 中如何调用 https 中双向认证的接口的问题，本文采用 okhttp 以及 Java11 中的 httpclient 来介绍如何使用 Java 代码调用 https 双向认证的接口。\n前置工作\n生成服务端、客户端证书，并将各自的公钥加入到对方的信任链中以供后续的使用；\n搭建一个 https 协议的服务以供客户端调用。\n\n制作证书这里我们采用 jdk 提供的 keytool 命令来生成我们所需要的服务端、客户端证书，并且可以使用 keytool 命令来将各自的公钥加入到对方的信任连中。\n生成服务端、客户端密钥库以及证书# 生成服务端keystore，这里加拓展项的目的是为了说明域名验证的问题keytool -genkey -validity 3650 -alias server -keyalg RSA -keystore server.keystore -ext san=dns:www.goku.edu,ip:127.0.0.1# 生成客户端keystore，这里针对客户端的密钥库我们采用 PKCS12 的格式keytool -genkey -validity 3650 -alias client -keyalg RSA -storetype PKCS12 -keystore client.p12\n\n导出服务端、客户端证书中的公钥# 导出服务端证书的公钥keytool -export -keystore server.keystore -alias server -file server.cer -rfc# 导出客户端证书的公钥keytool -export -keystore client.p12 -storetype PKCS12 -alias client -file client.cer\n\n将各自的公钥加入到对方的密钥库中# 将服务端证书导入到客户端的信任库中keytool -import -alias server -file server.cer -keystore client.p12# 将客户端证书导入到服务端的信任库中keytool -import -alias client -file client.cer -keystore server.keystore\n\n查看密钥库可以通过如下命令，来查看公钥是否加入到各自的密钥库中\nkeytool -list -v -keystore server.keystorekeytool -list -rfc -keystore client.p12\n\n搭建 HTTPS 服务由于搭建服务不是本文的重点，建议使用 SpringBoot 脚手架快速搭建一个服务，下面只列关键点。\n编写一个简单的 HTTP 接口代码如下：\n@RestController@RequestMapping(&quot;/index&quot;)public class IndexRestController &#123;    @GetMapping(&quot;/hello&quot;)    public String hello() &#123;        return &quot;Hello World!&quot;;    &#125;&#125;\n\n完成之后，启动服务，使用浏览器打开对应的接口地址，如果正确输出Hello World!则说明接口正常。\n开启 SpringBoot 的 SSL 双向认证在 application.properties 中新增如下配置，即可开启 SSL 的双向认证\nserver.ssl.enabled=trueserver.ssl.protocol=TLSserver.ssl.key-store=classpath:certs/server.keystoreserver.ssl.key-store-password=111111server.ssl.key-password=111111server.ssl.key-alias=serverserver.ssl.trust-store=classpath:certs/server.keystoreserver.ssl.trust-store-password=111111server.ssl.client-auth=NEED\n\n配完之后，启动服务，再次使用浏览器打开上一步的接口地址，发现接口并不能正常使用，并且浏览器会提示”此站点的连接不安全”，如下图所示\n\n\n使用 OkHttp构建 OkHttpClient构建 SSL 的双向认证，有两个要点\n\n创建 SSLSocket\n创建 HostnameVerifier\n\n创建 SSLSocketFactory在进行 HTTPS 的请求时，最重要的就是创建 SSLSocket ，在 Java 中可以通过 SSLSocketFactory 来创建 SSLSocket，故在构建 OkHttpClient 时成员变量 SSLSocketFactory 的创建就显得非常关键。\n代码如下：\nprivate static SSLSocketFactory sslSocketFactory() &#123;    try (InputStream inputStream = HttpsUtils.class.getResourceAsStream(&quot;/certs/client.p12&quot;)) &#123;        // 加载 keyStore        KeyStore keyStore = KeyStore.getInstance(&quot;PKCS12&quot;);        keyStore.load(inputStream, &quot;111111&quot;.toCharArray());        // 创建密钥管理器        KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());        kmf.init(keyStore, &quot;111111&quot;.toCharArray());        // 创建信任链管理器        String defaultAlgorithm = TrustManagerFactory.getDefaultAlgorithm();        TrustManagerFactory tmf = TrustManagerFactory.getInstance(defaultAlgorithm);        tmf.init(keyStore);        // 初始化 SSLContext        SSLContext sslContext = SSLContext.getInstance(&quot;TLS&quot;);        sslContext.init(kmf.getKeyManagers(), tmf.getTrustManagers(), new SecureRandom());        return sslContext.getSocketFactory();    &#125; catch (NoSuchAlgorithmException | KeyManagementException | KeyStoreException | UnrecoverableKeyException | IOException | CertificateException e) &#123;        throw new RuntimeException(e);    &#125;&#125;\n\n对于第二个参数所需的 X509TrustManager，我们采用 OkHttp 提供的默认实现okhttp3.internal.Util#platformTrustManager即可。\n创建 HostnameVerifierHostnameVerifier 是为了帮助我们验证我们请求的域名以及对应的 IP 是否一致。这里可以回顾一下创建证书时我们添加的拓展项-ext san=dns:www.goku.edu,ip:127.0.0.1。由于我们在本机测试，可以信任对应的域名，也可以通过修改 hosts 文件的方式来指定域名，也可以自定义 HostnameVerifier 的实现。这里以不对域名做校验为例子，代码如下：\nprivate static HostnameVerifier hostnameVerifier() &#123;    return (hostname, session) -&gt; true;&#125;\n\n在完成以上所有步骤之后，就可以构建我们的 OkHttpClient，并发送我们的 https 请求。\npublic static void main(String[] args) throws IOException &#123;    // 创建 OkHttpClient    OkHttpClient httpClient = new OkHttpClient.Builder()        .hostnameVerifier(hostnameVerifier())        .sslSocketFactory(sslSocketFactory(), Util.platformTrustManager())        .build();    // 构造请求    Request request = new Request.Builder()            .url(&quot;https://www.goku.edu:8443/index/hello&quot;)            .build();    // 发送请求    Response response = httpClient.newCall(request).execute();    System.out.println(response.body().string());&#125;\n\n执行代码，发现控制台正确打印Hello World!，说明我们对于 SSL 双向认证的 Https 请求已经发送成功，并成功的接收到响应了。\n使用 Java11 的 HttpClient熟悉 Java11 HttpClient 的开发者都知道 Java11 中的 HttpClient 跟 OkHttpClient 中的用法几乎一致。回归到 SSL 的双向认证，有以下两个不同点\n\nJava11 的 HttpClient 所需传的参数为 SSLContext，这个跟我们在使用 OkHttp 时创建 SSLSocketFactory 时初始化的 SSLContext 完全一致；\nJava11 的 HttpClient 并不支持自定义的 hostnameVerifier，只能通过配置项来关闭或打开域名验证。\n\n其代码如下：\npublic static void main(String[] args) throws IOException, InterruptedException, KeyStoreException,        CertificateException, NoSuchAlgorithmException, UnrecoverableKeyException, KeyManagementException &#123;    // 如需禁用 HostnameVerification    // System.setProperty(&quot;jdk.internal.httpclient.disableHostnameVerification&quot;, &quot;true&quot;);    InputStream inputStream = HttpsUtils.class.getResourceAsStream(&quot;/certs/client.p12&quot;);    // 创建KeyStore，用来存储信任证书    KeyStore keyStore = KeyStore.getInstance(&quot;PKCS12&quot;);    keyStore.load(inputStream, &quot;111111&quot;.toCharArray());    // 创建密钥管理器    KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());    kmf.init(keyStore, &quot;111111&quot;.toCharArray());    // 创建信任链管理器    String defaultAlgorithm = TrustManagerFactory.getDefaultAlgorithm();    TrustManagerFactory tmf = TrustManagerFactory.getInstance(defaultAlgorithm);    tmf.init(keyStore);    // 初始化 SSLContext    SSLContext sslContext = SSLContext.getInstance(&quot;TLS&quot;);    sslContext.init(kmf.getKeyManagers(), tmf.getTrustManagers(), new SecureRandom());    // 创建 HttpClient    HttpClient httpClient = HttpClient.newBuilder()            .sslContext(sslContext)            .build();    // 创建一个自定义的HTTP请求对象    HttpRequest request = HttpRequest.newBuilder()            .GET()            .uri(URI.create(&quot;https://www.goku.edu:8443/index/hello&quot;))            .header(&quot;Accept-Language&quot;, &quot;zh-CN&quot;)            .timeout(Duration.ofMillis(5000))            .build();    // 客户端传递请求信息，且返回字符串形式的应答报文    HttpResponse&lt;String&gt; response = httpClient.send(request, HttpResponse.BodyHandlers.ofString());    System.out.println(response.body());&#125;","tags":["https","okhttp"]},{"title":"如何使用Hexo？","url":"/2010/05/24/hexo/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new posthexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun serverhexo server\n\nMore info: Server\nGenerate static fileshexo generate\n\nMore info: Generating\nDeploy to remote siteshexo deploy\n\nMore info: Deployment\n"},{"title":"Jenkins 手册","url":"/2020/02/18/jenkins-%E6%89%8B%E5%86%8C/","content":"Jenkins 是常见的 CI 平台\n安装Windows 平台略\nCentOS 平台更为详细的步骤及说明可查看官网\n添加 jenkins 源命令如下：\nsudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.key\n\nyum 安装命令如下：\n# 在线安装的方式yum install jenkins# 离线安装的方式，由于国内连接 jenkins 网站较慢，可先行下载 rpm 文件格式的离线安装包，采用离线的方式安装yum install jenkins-2.204.2-1.1.noarch.rpm\n\n启动命令如下：\nsystemctl start jenkins\n\n解决插件中心安装慢的问题第一次登录 Jenkins 会出现初始化缓慢的问题，产生这个问题的原因有两个，一个是因为首次打开 Jenkins 会尝试连接 Google，另外一个原因是因为连接插件中心缓慢。\n将插件中心修改为清华的源修改文件 $JENKINS_HOME/hudson.model.UpdateCenter.xml，将 url 从 https://updates.jenkins.io/update-center.json 修改为 https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json\n将 Google 的地址修改为 Baidu修改文件 $JENKINS_HOME/updates/default.json\n\n将 connectionCheckUrl 的值修改为 http://www.baidu.com/\n替换文件中 updates.jenkins-ci.org/download 为 mirrors.tuna.tsinghua.edu.cn/jenkins\n\n未完待续…\n","categories":["手册"],"tags":["未完待续","Jenkins","CI","持续集成"]},{"title":"javaagent 使用指南","url":"/2022/01/08/javaagent-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","content":"最近在做基于 JaCoCo 的代码覆盖率工具，了解到了一下 javaagent 相关的一些知识点。\njavaagent 是什么？javaagent 是 java 命令的一个参数选项，可以用于加载 Java 语言的代理。\n那么这个参数加载的 Java 语言的代理需要满足什么样的规范呢？\n\n代理 jar 包中的 MANIFEST.MF 文件需指定 Premain-Class；\nPremain-Class 指定的类中必须实现 premain 方法。\n\n","tags":["Java"]},{"title":"Java 多线程死锁问题","url":"/2019/11/19/java-deadlock/","content":"本文描述一个 Java 多线程死锁问题，并演示使用 jstack、arthas 工具来发现应用程序中的线程死锁。\n先编写一段死锁的代码public class App &#123;    public static void main(String[] args) &#123;        String x = &quot;x&quot;;        String y = &quot;y&quot;;        Thread a = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                String threadName = Thread.currentThread().getName();                synchronized (x) &#123;                    System.out.println(String.format(&quot;Thread %s Start %s&quot;, threadName, &quot;------&quot;));                    System.out.println(String.format(&quot;Thread %s, x = %s&quot;, threadName, x));                    synchronized (y) &#123;                        System.out.println(String.format(&quot;Thread %s, y = %s&quot;, threadName, y));                    &#125;                    System.out.println(String.format(&quot;Thread %s End %s&quot;, threadName, &quot;------&quot;));                &#125;            &#125;        &#125;);        Thread b = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                String threadName = Thread.currentThread().getName();                synchronized (y) &#123;                    System.out.println(String.format(&quot;Thread %s Start %s&quot;, threadName, &quot;------&quot;));                    System.out.println(String.format(&quot;Thread %s, y = %s&quot;, threadName, y));                    synchronized (x) &#123;                        System.out.println(String.format(&quot;Thread %s, x = %s&quot;, threadName, x));                    &#125;                    System.out.println(String.format(&quot;Thread %s End %s&quot;, threadName, &quot;------&quot;));                &#125;            &#125;        &#125;);        a.start();        b.start();    &#125;&#125;\n\n运行以上代码，发现如下输出：\nThread Thread-0 Start ------Thread Thread-0, x = xThread Thread-1 Start ------Thread Thread-1, y = y\n\n由于 Thread-0 和 Thread-1 均没有输出 End 信息，可知线程陷入了死锁。\njstack 分析jstack 是 jdk 自带的线程堆栈分析工具，使用该命令可以查看或导出 Java 应用程序中线程堆栈信息。\nUseage:\nUsage:    jstack [-l] &lt;pid&gt;        (to connect to running process)    jstack -F [-m] [-l] &lt;pid&gt;        (to connect to a hung process)    jstack [-m] [-l] &lt;executable&gt; &lt;core&gt;        (to connect to a core file)    jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt;        (to connect to a remote debug server)Options:    -F  强制转储线程信息，当 jstack 不响应时使用    -m  打印Java和本机框架的所有栈信息（混合模式）    -l  长列表，答应更多关于锁的附加信息    -h or -help 打印帮住信息\n\n通过 jps 命令查询到程序的 pid，使用 jstack -l 来查看线程堆栈信息\nPS C:\\Users\\fuyongde&gt; jstack -l 1517922019-11-19 16:20:14Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.162-b12 mixed mode):&quot;DestroyJavaVM&quot; #15 prio=5 os_prio=0 tid=0x0000000003103800 nid=0x240b8 waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;Thread-1&quot; #14 prio=5 os_prio=0 tid=0x00000000227d2000 nid=0x21898 waiting for monitor entry [0x00000000235df000]   java.lang.Thread.State: BLOCKED (on object monitor)        at com.exp.App$2.run(App.java:34)        - waiting to lock &lt;0x0000000740da48c0&gt; (a java.lang.String)        - locked &lt;0x0000000740da48f0&gt; (a java.lang.String)        at java.lang.Thread.run(Thread.java:748)   Locked ownable synchronizers:        - None&quot;Thread-0&quot; #13 prio=5 os_prio=0 tid=0x00000000227d1000 nid=0x23f90 waiting for monitor entry [0x00000000234df000]   java.lang.Thread.State: BLOCKED (on object monitor)        at com.exp.App$1.run(App.java:19)        - waiting to lock &lt;0x0000000740da48f0&gt; (a java.lang.String)        - locked &lt;0x0000000740da48c0&gt; (a java.lang.String)        at java.lang.Thread.run(Thread.java:748)   Locked ownable synchronizers:        - None&quot;Service Thread&quot; #12 daemon prio=9 os_prio=0 tid=0x000000002271c000 nid=0x21868 runnable [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;C1 CompilerThread2&quot; #11 daemon prio=9 os_prio=2 tid=0x0000000022681800 nid=0x21874 waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;C2 CompilerThread1&quot; #10 daemon prio=9 os_prio=2 tid=0x0000000022678800 nid=0x24288 waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;C2 CompilerThread0&quot; #9 daemon prio=9 os_prio=2 tid=0x0000000022661000 nid=0x21870 waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;JDWP Command Reader&quot; #8 daemon prio=10 os_prio=0 tid=0x00000000225fe000 nid=0x21864 runnable [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;JDWP Event Helper Thread&quot; #7 daemon prio=10 os_prio=0 tid=0x00000000225fa800 nid=0x21834 runnable [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;JDWP Transport Listener: dt_socket&quot; #6 daemon prio=10 os_prio=0 tid=0x0000000021291800 nid=0x21854 runnable [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;Attach Listener&quot; #5 daemon prio=5 os_prio=2 tid=0x00000000212dc800 nid=0x21860 waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;Signal Dispatcher&quot; #4 daemon prio=9 os_prio=2 tid=0x00000000225f0800 nid=0x2184c runnable [0x0000000000000000]   java.lang.Thread.State: RUNNABLE   Locked ownable synchronizers:        - None&quot;Finalizer&quot; #3 daemon prio=8 os_prio=1 tid=0x000000002126a000 nid=0x240c4 in Object.wait() [0x00000000225df000]   java.lang.Thread.State: WAITING (on object monitor)        at java.lang.Object.wait(Native Method)        - waiting on &lt;0x0000000740988ec0&gt; (a java.lang.ref.ReferenceQueue$Lock)        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143)        - locked &lt;0x0000000740988ec0&gt; (a java.lang.ref.ReferenceQueue$Lock)        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164)        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:212)   Locked ownable synchronizers:        - None&quot;Reference Handler&quot; #2 daemon prio=10 os_prio=2 tid=0x0000000021249800 nid=0x24090 in Object.wait() [0x00000000224de000]   java.lang.Thread.State: WAITING (on object monitor)        at java.lang.Object.wait(Native Method)        - waiting on &lt;0x0000000740986b68&gt; (a java.lang.ref.Reference$Lock)        at java.lang.Object.wait(Object.java:502)        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)        - locked &lt;0x0000000740986b68&gt; (a java.lang.ref.Reference$Lock)        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)   Locked ownable synchronizers:        - None&quot;VM Thread&quot; os_prio=2 tid=0x0000000021246800 nid=0x218a0 runnable&quot;GC task thread#0 (ParallelGC)&quot; os_prio=0 tid=0x0000000003119000 nid=0x240ac runnable&quot;GC task thread#1 (ParallelGC)&quot; os_prio=0 tid=0x000000000311a800 nid=0x2188c runnable&quot;GC task thread#2 (ParallelGC)&quot; os_prio=0 tid=0x000000000311c000 nid=0x2189c runnable&quot;GC task thread#3 (ParallelGC)&quot; os_prio=0 tid=0x000000000311e000 nid=0x2409c runnable&quot;VM Periodic Task Thread&quot; os_prio=2 tid=0x00000000227c9000 nid=0x240f8 waiting on conditionJNI global references: 1880Found one Java-level deadlock:=============================&quot;Thread-1&quot;:  waiting to lock monitor 0x00000000031fdbd8 (object 0x0000000740da48c0, a java.lang.String),  which is held by &quot;Thread-0&quot;&quot;Thread-0&quot;:  waiting to lock monitor 0x00000000031fc5d8 (object 0x0000000740da48f0, a java.lang.String),  which is held by &quot;Thread-1&quot;Java stack information for the threads listed above:===================================================&quot;Thread-1&quot;:        at com.exp.App$2.run(App.java:34)        - waiting to lock &lt;0x0000000740da48c0&gt; (a java.lang.String)        - locked &lt;0x0000000740da48f0&gt; (a java.lang.String)        at java.lang.Thread.run(Thread.java:748)&quot;Thread-0&quot;:        at com.exp.App$1.run(App.java:19)        - waiting to lock &lt;0x0000000740da48f0&gt; (a java.lang.String)        - locked &lt;0x0000000740da48c0&gt; (a java.lang.String)        at java.lang.Thread.run(Thread.java:748)Found 1 deadlock.\n\n通过观察可以发现 Thread-0、Thread-1 两个线程均处于 BLOCKED 状态，而且堆栈信息的最后明确提示了 Found 1 deadlock.，相关锁定的代码行也都有非常明确的提示，相关提示如下：\nFound one Java-level deadlock:=============================&quot;Thread-1&quot;:  waiting to lock monitor 0x00000000031fdbd8 (object 0x0000000740da48c0, a java.lang.String),  which is held by &quot;Thread-0&quot;&quot;Thread-0&quot;:  waiting to lock monitor 0x00000000031fc5d8 (object 0x0000000740da48f0, a java.lang.String),  which is held by &quot;Thread-1&quot;Java stack information for the threads listed above:===================================================&quot;Thread-1&quot;:        at com.exp.App$2.run(App.java:34)        - waiting to lock &lt;0x0000000740da48c0&gt; (a java.lang.String)        - locked &lt;0x0000000740da48f0&gt; (a java.lang.String)        at java.lang.Thread.run(Thread.java:748)&quot;Thread-0&quot;:        at com.exp.App$1.run(App.java:19)        - waiting to lock &lt;0x0000000740da48f0&gt; (a java.lang.String)        - locked &lt;0x0000000740da48c0&gt; (a java.lang.String)        at java.lang.Thread.run(Thread.java:748)Found 1 deadlock.\n\narthas 分析Arthas 是 Alibaba 开源的 Java 诊断工具，深受开发者喜爱。在线排查问题，无需重启；动态跟踪 Java 代码；实时监控 JVM 状态。详情可参考官网\n启动 arthas 并选择我们的程序。\n由于我们是要查询线程死锁问题，故需要用到 thread 命令。\nUseage：\nUSAGE:   thread [-h] [-b] [-i &lt;value&gt;] [-n &lt;value&gt;] [id] SUMMARY:   Display thread info, thread stack EXAMPLES:   thread   thread 51   thread -n -1   thread -n 5   thread -b   thread -i 2000 WIKI:   https://alibaba.github.io/arthas/thread OPTIONS: -h, --help                                                                     this help -b, --include-blocking-thread                                                  Find the thread who is holding a lock that blocks the most number of threads. -i, --sample-interval &lt;value&gt;                                                  Specify the sampling interval (in ms) when calculating cpu usage. -n, --top-n-threads &lt;value&gt;                                                    The number of thread(s) to show, ordered by cpu utilization, -1 to show all. &lt;id&gt;                                                                           Show thread stack\n\n从帮助信息中可知 thread -b 可以帮我们查询阻塞时间最长的线程。\n[arthas@664776]$ thread -b&quot;Thread-0&quot; Id=13 BLOCKED on java.lang.String@45db1404 owned by &quot;Thread-1&quot; Id=14    at com.exp.App$1.run(App.java:19)    -  blocked on java.lang.String@45db1404    -  locked java.lang.String@2fa93a25 &lt;---- but blocks 1 other threads!    at java.lang.Thread.run(Thread.java:748)Affect(row-cnt:0) cost in 22 ms.\n\n通过观察输出可以发现，相比 jstack，arthas 可以更加快速的定位到阻塞线程。\n","tags":["Java","jstack","死锁"]},{"title":"Java8 Stream","url":"/2019/06/15/java8-stream/","content":"\nA sequence of elements supporting sequential and parallel aggregate operations.\n\n从 Stream 的定义可以看出\n\nStream 是一组元素的集合\nStream 支持顺序和并行地对元素进行操作\n\nHow it work先看示例：\npublic void method1() &#123;    List&lt;String&gt; list = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, 1, 2, 3)            .peek(System.out::print)            .map(String::valueOf)            .sorted()            .collect(Collectors.toList());    System.out.println(&quot;\\n&quot; + JSON.toJSONString(list));&#125;\n\n上述程序输出结果：\nabc123[&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;a&quot;,&quot;b&quot;,&quot;c&quot;]\n\n通过上述例子：\n\nStream.of() 产生一个流；\npeek 将所有元素进行打印；\nmap 将所有元素转化为 String；\nsorted 将所有元素进行排序；\ncollect 将所有元素聚合为一个 List。\n\n由此总结对流的操作可分为 3 个阶段\n\n创建流\n转化流（每次转化，原有的 Stream 不变，产生一个新的 Stream 对象，可以对流进行多次转化）\n消耗流（获取最终的结果）\n\n+--------------------+   +------+   +-----+   +--------+   +-------+| stream of elements |-&gt; | peek |-&gt; | map |-&gt; | sorted |-&gt; |collect|+--------------------+   +------+   +-----+   +--------+   +-------+\n\nStream 的操作就像一条流水线。我们可以对流进行不同地操作（如 peek 、 map 等），最终得到前面处理的结果。\n操作类型Stream 的操作分为两大类 中间操作（intermediate） 和 _结束操作（terminal）_。\n中间操作中间操作可进一步区分为 无状态（stateless） 和 _有状态（stateful）_。\n\n\n\n\n方法\n\n\n\n无状态\npeek、filter、map、mapToInt、mapToLong、mapToDouble、flatMap、flatMapToInt、flatMapToLong、flatMapToDouble\n\n\n有状态\nsorted、distinct、limit、skip\n\n\n结束操作结束操作中有一部分操作可以视为 _短路操作（short-circuiting）_。\n\n\n\n\n方法\n\n\n\n非短路\nforEach、forEachOrdered、toArray、collect、min、max、reduce、count\n\n\n短路\nanyMatch、noneMatch、findFirst、findAny\n\n\n有什么优点一般来说，Java8 之前的编程方式，对数组、集合中元素遍历是显示的在外部进行，我们称之为 _外部迭代_，而 Stream 的方式叫做内部迭代，采用了 访问者模式（Visitor） 实现。外部迭代我们的关注点是怎么做，内部迭代我们的关注点是做什么。通过 Stream 对元素的 内部迭代 我们更容易清晰的看到一个方法对元素做了什么操作。\n元素执行顺序在 Stream 编程中，元素的执行顺序非常重要。\n还是先看例子\npublic void method3() &#123;    Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)            .peek(s -&gt; System.out.println(&quot;peek -&gt; &quot; + s))            .map(s -&gt; &#123;                System.out.println(&quot;map -&gt; &quot; + s);                return s.toUpperCase();            &#125;)            .forEach(s -&gt; System.out.println(&quot;forEach -&gt; &quot; + s));&#125;\n\n直接看这段程序的输出\npeek -&gt; amap -&gt; aforEach -&gt; Apeek -&gt; bmap -&gt; bforEach -&gt; Bpeek -&gt; cmap -&gt; cforEach -&gt; C\n\n是不是与想象中的不一样？\nStream 对元素的操作是一个元素执行完所有的操作在执行下一个元素，而不是一个操作执行完所有的元素再进行下一个操作。这就更加证明了 Stream 对元素的操作是像流水线那样。\n为什么执行顺序如此重要通过上文，还不足以说明执行顺序为什么非常重要。\n再看一个例子\npublic void method4() &#123;    Stream.of(2, 4, 5, 3, 1)            .sorted((i1, i2)-&gt;&#123;                System.out.format(&quot;sorted -&gt; %d %d \\n&quot;, i1, i2);                return i1.compareTo(i2);            &#125;)            .map(i -&gt; &#123;                System.out.println(&quot;map -&gt; &quot; + i);                return i * 2;            &#125;)            .filter(i -&gt; &#123;                System.out.println(&quot;filter -&gt; &quot; + i);                return i &gt; 8;            &#125;)            .forEach(i -&gt; System.out.println(&quot;forEach -&gt; &quot; + i));&#125;\n\n输出如下：\nsorted -&gt; 4 2sorted -&gt; 5 4sorted -&gt; 3 5sorted -&gt; 3 4sorted -&gt; 3 2sorted -&gt; 1 4sorted -&gt; 1 3sorted -&gt; 1 2map -&gt; 1filter -&gt; 2map -&gt; 2filter -&gt; 4map -&gt; 3filter -&gt; 6map -&gt; 4filter -&gt; 8map -&gt; 5filter -&gt; 10forEach -&gt; 10\n\n从上述输出可以看出，每个元素都进行了 sorted、map 操作，那么我们对上述程序做一个变形，如下\npublic void method4() &#123;    Stream.of(2, 4, 5, 3, 1)            .filter(i -&gt; &#123;                System.out.println(&quot;filter -&gt; &quot; + i);                return i * 2 &gt; 8;            &#125;)            .map(i -&gt; &#123;                System.out.println(&quot;map -&gt; &quot; + i);                return i * 2;            &#125;)            .sorted((i1, i2)-&gt;&#123;                System.out.format(&quot;sorted -&gt; %d %d \\n&quot;, i1, i2);                return i1.compareTo(i2);            &#125;)            .forEach(i -&gt; System.out.println(&quot;forEach -&gt; &quot; + i));&#125;\n\n变形之后该段程序输出为：\nfilter -&gt; 2filter -&gt; 4filter -&gt; 5map -&gt; 5filter -&gt; 3filter -&gt; 1forEach -&gt; 10\n\n可以看出，元素[1, 2, 3, 4]并未进行 map 操作，所有的元素都未进行 sorted 操作，因为 filter 操作将不满足条件的元素都过滤掉了，只剩下一个元素，故不会进行 sorted 操作。\n所以在使用Stream对元素进行操作时，合理的调整操作顺序，可以提升性能。\n延时性Stream 对元素的操作有一个非常重要的特性：延时性。为了更加直观的看到这个特性，我们先看一个例子\npublic void method5() &#123;    Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;).peek(System.out::print);&#125;\n\n按照我们的预期，上述程序应该输出\nabc\n\n可是在实际执行过程中却发现并没有任何输出，这是为什么？\n这是因为在对 stream 操作过程中，没有调用结束操作的时候，所有的中间操作都不会执行。\n高阶操作短路操作在遇到 短路操作 时，一旦满足 短路操作 的条件时，Stream 会马上终止。例如：\npublic void method6() &#123;    Stream.of(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;)        .map(s -&gt; &#123;            System.out.println(&quot;map -&gt; &quot; + s);            return s.toUpperCase();        &#125;)        .anyMatch(s -&gt; &#123;            System.out.println(&quot;anyMatch -&gt; &quot; + s);            return s.startsWith(&quot;X&quot;);        &#125;);&#125;\n\n输出：\nmap -&gt; xanyMatch -&gt; X\n\n上述例子中，第一个元素即满足了 anyMatch 的条件，后续的元素便不再进行 Stream 上的各种操作，其余 短路操作 不再一一举例。\ncollectcollect操作是十分常用的 _终止操作_，可以将流中的元素聚合成我们想要的集合类（如 List、Set、Map 等），也可以对元素做一些拼接、汇总等。下面的例子演示了 collect 一些常用的场景。\npublic void method7() &#123;    System.out.println(&quot;---聚合为List---&quot;);    List&lt;String&gt; list = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;).collect(Collectors.toList());    list.forEach(System.out::print);    System.out.println(&quot;---拼接为字符串---&quot;);    String str = Stream.of(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;).collect(Collectors.joining(&quot;,&quot;));    System.out.println(str);    System.out.println(&quot;---聚合为汇总信息---&quot;);    IntSummaryStatistics intSummaryStatistics = Stream.of(1, 2, 3).collect(Collectors.summarizingInt(value -&gt; value));    System.out.println(intSummaryStatistics);    System.out.println(&quot;---求平均值---&quot;);    Double average = Stream.of(1, 2, 3).collect(Collectors.averagingInt(value -&gt; value));    System.out.println(average);    System.out.println(&quot;---分组---&quot;);    Map&lt;Integer, List&lt;Integer&gt;&gt; map1 = Stream.of(1, 2, 3).collect(Collectors.groupingBy(value -&gt; value));    System.out.println(JSON.toJSONString(map1));    System.out.println(&quot;---将元素聚合为Map--&quot;);    Map&lt;Integer, String&gt; map2 = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;).collect(Collectors.toMap(String::hashCode, Function.identity()));    System.out.println(JSON.toJSONString(map2));&#125;\n\nflatMap通过上文，我们已经知道如何使用 map，但是有的时候 map 使用起来十分受限，因为 map 只能将一个对象映射为另一个对象，但是当我们希望将一个对象转化对多个或零个对象的时候，就需要用到 flatMap 。\n看例子：\npublic void method8() &#123;    List&lt;Foo&gt; foos = new ArrayList&lt;&gt;();    IntStream.range(1, 4).forEach(i -&gt; foos.add(new Foo(&quot;Foo&quot; + &quot; -&gt; &quot; + i)));    foos.forEach(foo -&gt; IntStream.range(1, 4).forEach(i -&gt; foo.bars.add(new Bar(foo.name + &quot; -&gt; &quot; + &quot;Bar&quot; + &quot; -&gt; &quot; + i))));    List&lt;Bar&gt; bars = foos.stream()            .flatMap(foo -&gt; foo.bars.stream())            .collect(Collectors.toList());    bars.forEach(bar -&gt; System.out.println(bar.name));&#125;@Dataclass Foo &#123;    String name;    List&lt;Bar&gt; bars = new ArrayList&lt;&gt;();    public Foo(String name) &#123;        this.name = name;    &#125;&#125;@Dataclass Bar &#123;    String name;    public Bar(String name) &#123;        this.name = name;    &#125;&#125;\n\n输出：\nFoo -&gt; 1 -&gt; Bar -&gt; 1Foo -&gt; 1 -&gt; Bar -&gt; 2Foo -&gt; 1 -&gt; Bar -&gt; 3Foo -&gt; 2 -&gt; Bar -&gt; 1Foo -&gt; 2 -&gt; Bar -&gt; 2Foo -&gt; 2 -&gt; Bar -&gt; 3Foo -&gt; 3 -&gt; Bar -&gt; 1Foo -&gt; 3 -&gt; Bar -&gt; 2Foo -&gt; 3 -&gt; Bar -&gt; 3\n\n可以看出，上述例子通过 flatMap 操作，我们成功地将一个含有 3 个 foo 元素的流转化为了含有 9 个 bar 元素的流。\nreducereduce 操作是将所有流中的元素组合为单一结果。\n下面例子演示了两种常见的规约操作。\npublic void method9() &#123;    List&lt;Foo&gt; foos = new ArrayList&lt;&gt;();    IntStream.range(1, 4).forEach(i -&gt; foos.add(new Foo(&quot;Foo&quot; + &quot; -&gt; &quot; + i)));    foos.forEach(foo -&gt; IntStream.range(1, 4).forEach(i -&gt; foo.bars.add(new Bar(foo.name + &quot; -&gt; &quot; + &quot;Bar&quot; + &quot; -&gt; &quot; + i))));    System.out.println(&quot;---foos中的元素---&quot;);    foos.forEach(o -&gt; System.out.println(JSON.toJSONString(o)));    System.out.println(&quot;---foos进行规约之后---&quot;);    foos.stream()            .reduce((foo1, foo2) -&gt; foo1.name.hashCode() &gt; foo2.name.hashCode() ? foo1 : foo2)            .ifPresent(foo -&gt; System.out.println(JSON.toJSONString(foo)));    System.out.println(&quot;---foos将元素规约成一个新的对象---&quot;);    Foo foo = foos.stream()            .reduce(new Foo(&quot;&quot;), (foo1, foo2) -&gt; &#123;                foo1.name += foo2.name;                return foo1;            &#125;);    System.out.println(JSON.toJSONString(foo));&#125;\n\n并行流从流的定义中我们得知流是支持并行地对元素进行操作地。在流中存在大量元素地情况下，使用并行流可以极大的提升运行时的性能。\n并行流使用公共的ForkJoinPool，由ForkJoinPool.commonPool()方法提供。\nForkJoinPool commonPool = ForkJoinPool.commonPool();System.out.println(commonPool.getParallelism());\n\n通过上述方法可以查看公共池的默认线程数，也可以通过 JVM 参数-Djava.util.concurrent.ForkJoinPool.common.parallelism=5来调整。\n看下面的例子：\npublic void method10() &#123;    List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)            .parallelStream()            .filter(s -&gt; &#123;                System.out.format(&quot;filter: %s [%s]\\n&quot;, s, Thread.currentThread().getName());                try &#123;                    Thread.sleep(10);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                return true;            &#125;)            .map(s -&gt; &#123;                System.out.format(&quot;map: %s [%s]\\n&quot;, s, Thread.currentThread().getName());                return s.toUpperCase();            &#125;)            .collect(Collectors.toList());    list.forEach(System.out::print);&#125;\n\n输出：\nfilter: c [main]filter: b [ForkJoinPool.commonPool-worker-2]filter: a [ForkJoinPool.commonPool-worker-3]filter: d [ForkJoinPool.commonPool-worker-1]map: c [main]map: d [ForkJoinPool.commonPool-worker-1]map: b [ForkJoinPool.commonPool-worker-2]map: a [ForkJoinPool.commonPool-worker-3]ABCD\n\n上述例子中，为了使对元素的操作能在 ForkJoinPool.commonPool-worker-* 的线程上执行，我们针对 filter 操作进行了 _sleep_，通过观察发现并行流使用的线程确实是由 ForkJoinPool.commonPool() 提供。\n让我们对上述程序增加一个 sorted 操作，看会发生什么变化：\npublic void method11() &#123;    System.out.println(&quot;\\n-----&quot;);    Arrays.asList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)            .parallelStream()            .filter(s -&gt; &#123;                System.out.format(&quot;filter: %s [%s]\\n&quot;, s, Thread.currentThread().getName());                try &#123;                    Thread.sleep(10);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;                return true;            &#125;)            .map(s -&gt; &#123;                System.out.format(&quot;map: %s [%s]\\n&quot;, s, Thread.currentThread().getName());                return s.toUpperCase();            &#125;)            .sorted((s1, s2) -&gt; &#123;                System.out.format(&quot;sort: %s &lt;&gt; %s [%s]\\n&quot;, s1, s2, Thread.currentThread().getName());                return s1.compareTo(s2);            &#125;)            .collect(Collectors.toList()).forEach(System.out::print);    System.out.println(&quot;\\n&quot;);&#125;\n\n输出：\nfilter: d [ForkJoinPool.commonPool-worker-1]filter: c [main]filter: b [ForkJoinPool.commonPool-worker-3]filter: a [ForkJoinPool.commonPool-worker-2]map: c [main]map: d [ForkJoinPool.commonPool-worker-1]map: a [ForkJoinPool.commonPool-worker-2]map: b [ForkJoinPool.commonPool-worker-3]sort: B &lt;&gt; A [main]sort: C &lt;&gt; B [main]sort: D &lt;&gt; C [main]ABCD\n\n我们发现在经过 sorted 操作时，全部元素都在 main 线程中执行了。实际上，并行流上的 sorted 在背后使用了 Java8 中新的方法 Arrays.parallelSort()，这个方法会根据流中元素的长度来决定是以串行还是并行的方式来执行。\n","categories":["Java8"],"tags":["Java","Java8","Stream"]},{"title":"Jib - Make docker simple again","url":"/2019/06/26/jib-make-docker-simple-again/","content":"在 使用 Docker 构建 Spring Boot Application 中简单介绍了如何使用 Docker 构建 Spring Boot Application。本文探讨如何更简单的构建 Docker 镜像。\njib 简介\nMake America Great Again. – Donald Trump\n\n大概是受 Donald Trump 的启发 🙄，Google 发布的 jib 让原本已经很简单的 Docker 镜像构建过程变得更加简单。\n一图顶千言，先看 Docker 构建镜像流程\n\n\n再看 Jib 构建容器镜像流程\n\n\n使用下面来介绍以下如何使用 Jib\n编写 Spring Boot Application略\n配置 Jib 插件在项目的 pom.xml 文件中，新增如下配置\n&lt;plugin&gt;    &lt;groupId&gt;com.google.cloud.tools&lt;/groupId&gt;    &lt;artifactId&gt;jib-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;1.3.0&lt;/version&gt;    &lt;configuration&gt;        &lt;from&gt;            &lt;image&gt;openjdk:8u212-jdk-alpine&lt;/image&gt;        &lt;/from&gt;        &lt;to&gt;            &lt;image&gt;registry.cn-hangzhou.aliyuncs.com/fuyongde/ebony-maw:$&#123;project.version&#125;&lt;/image&gt;        &lt;/to&gt;        &lt;container&gt;            &lt;jvmFlags&gt;                &lt;jvmFlag&gt;-Xms128m&lt;/jvmFlag&gt;                &lt;jvmFlag&gt;-Xmx128m&lt;/jvmFlag&gt;            &lt;/jvmFlags&gt;        &lt;/container&gt;    &lt;/configuration&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;phase&gt;package&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;build&lt;/goal&gt;            &lt;/goals&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n其中\n\nfrom：等同于 Dockerfile 中的 FROM\nto：镜像容器服务的地址以及对应的 tag，这里我采用的是阿里云的地址\njvmFlag：容器启动时的 JVM 参数\n\n构建在终端执行 maven package 命令，Docker 镜像就打包并上传好了 ✌。\n至此，整个构建过程已经完成，我们甚至连 Dockerfile 都不用写，是不是超级简单 🤪。\n如有需要，可参考本文中的 Demo 。\n","tags":["Docker","Spring Boot","Jib"]},{"title":"JVM 手册","url":"/2019/11/10/jvm-%E6%89%8B%E5%86%8C/","content":"记录常用的 JVM 参数，持续更新 …\n堆内存设置-Xms128M : 设置 java 程序启动时堆内存 128M（默认为物理内存 1&#x2F;64,且小于 1G），阿里 p3c 文档中推荐 Xmx 与 Xms 配置同样的大小，避免 GC 后调整堆大小带来的压力\n-Xmx256M : 设置最大堆内存 256M，超出后会出现 OutOfMemoryError（默认为物理内存 1&#x2F;64，且小于 1G）\n-Xmn10M : 设置新生代区域大小为 10M\n-XX:NewSize=2M : 设置新生代初始大小为 2M\n-XX:MaxNewSize=2M : 设置新生代最大值为 2M\n-Xss1M : 设置线程栈的大小 1M（默认 1M）\n-XX:MinHeapFreeRatio=40 : 设置堆空间最小空闲比例（默认 40）（当 Xmx 与 Xms 相等时，该配置无效）\n-XX:MaxHeapFreeRatio=70 : 设置堆空间最大空闲比例（默认 70）（当 Xmx 与 Xms 相等时，该配置无效）\n-XX:NewRatio=2 : 设置年轻代与年老代的比例为 2:1\n-XX:SurvivorRatio=8 : 设置年轻代中 eden 区与 survivor 区的比例为 8:1\n-XX:MetaspaceSize=64M : 设置元数据空间初始大小（取代-XX:PermSize）\n-XX:MaxMetaspaceSize=128M : 设置元数据空间最大值（取代之前-XX:MaxPermSize）\n-XX:TargetSurvivorRatio=50 : 设置 survivor 区使用率。当 survivor 区达到 50%时，将对象送入老年代\n-XX:+UseTLAB : 在年轻代空间中使用本地线程分配缓冲区(TLAB)，默认开启\n-XX:TLABSize=512k : 设置 TLAB 大小为 512k\n-XX:+UseCompressedOops : 使用压缩指针，默认开启\n-XX:MaxTenuringThreshold=15 : 对象进入老年代的年龄（Parallel 是 15，CMS 是 6）\n垃圾收集器相关参数-XX:+UseSerialGC : 启用 Serial 收集器，开启之后会默认启用 Serial（年轻代）+ Serial Old（年老代）的收集器组合。\n-XX:+UseParNewGC : 启用 ParNew 收集器，开启之后会默认启用 ParNew（年轻代）+ Serial Old（老年代，该收集器已过时）的收集器组合，新生代使用复制算法，老年代采用标记-整理算法。推荐配合老年代使用 CMS 收集器。\n-XX:+UseParallelGC : 启用 Parallel 收集器，Java8 默认启用该收集器，俗称吞吐量优先的收集器。开启之后默认启用 Parallel Scavenge（年轻代）+ Parallel Old（老年代）。与 ParNew 的区别在于自适应调节策略，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整参数以提供最合适的停顿时间或最大吞吐量。新生代采用复制算法，老年代采用标记-整理算法。\n-XX:+UseParallelOldGC : 启用 Parallel 收集器，与 -XX:+UseParallelGC 可相互激活。\n-XX:+ParallelGCThreads : 限制垃圾收集的线程数量，默认开始和 CPU 数量相同的线程数。\n-XX:+UseConcMarkSweepGC : 启用 CMS 收集器，开启该参数之后，默认打开 -XX:+UseParNewGC，启用 ParNew（年轻代）+ CMS（老年代）+ Serial Old（老年代）收集器的组合，Serial Old 将作为 CMS 出错的后备收集器。\n-XX:+UseG1GC : 启用 G1 收集器，G1 收集器不同于以往的收集器，G1 收集器既可以回收年轻代的垃圾也可以回收年老代的垃圾。\nGC 相关的参数-XX:+PrintGC : 输出 GC 日志\n-XX:+PrintGCDetails : 输出 GC 的详细日志\n-XX:+PrintGCTimeStamps : 输出 GC 的时间戳（以基准时间的形式）\n-XX:+PrintGCDateStamps : 输出 GC 的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）\n-XX:+PrintHeapAtGC : 在进行 GC 的前后打印出堆的信息\n-XX:+PrintGCApplicationStoppedTime : 输出 GC 造成应用暂停的时间\n-Xloggc:../logs/gc.log : 日志文件的输出路径\n其他-XX:+HeapDumpOnOutOfMemoryError : 让 JVM 碰到 OOM 场景时输出 dump 信息。说明：OOM 的发生是有概率的，甚至有规律地相隔数月才出现一例，出现时的现场信息对查错非常有价值。\n-XX:MaxGCPauseMillis : 设置每次年轻代垃圾回收的最长时间，如果无法满足此时间，JVM 会自动调整年轻代大小，以满足此值。\n-XX:+TraceClassLoading : 跟踪类的加载信息\n-XX:+PrintCommandLineFlags : 打印启动命令参数\n","categories":["手册"],"tags":["未完待续","JVM"]},{"title":"Linux 手册","url":"/2019/09/24/linux-%E6%89%8B%E5%86%8C/","content":"记录一些常用的 Linux 操作，持续更新 …\n查看系统版本常用的查看系统版本有以下命令\n\ncat /etc/os-release\nuname -a\ncat /proc/version\ncat /etc/issue\n\n下面演示一下 cat /etc/os-release，其他不详细说明。\ncat /etc/os-release\n\n输出如下\nPRETTY_NAME=&quot;Debian GNU/Linux 9 (stretch)&quot;NAME=&quot;Debian GNU/Linux&quot;VERSION_ID=&quot;9&quot;VERSION=&quot;9 (stretch)&quot;ID=debianHOME_URL=&quot;https://www.debian.org/&quot;SUPPORT_URL=&quot;https://www.debian.org/support&quot;BUG_REPORT_URL=&quot;https://bugs.debian.org/&quot;\n\n替换源由于网络的原因，国内部分 Linux 在安装软件时非常缓慢，将源替换为国内的镜像可以方便很多。\n国内常见的镜像如清华大学、阿里云、163 等等，大家可自行选择。由于大部分网络上的博客，只写了具体源的地址，对很多没有基础的同学来说，由于系统版本的差异，反而会适得其反。\n替换源一定要遵循下面的步骤：\n\n确认操作系统版本。如何查看可参考上文。\n备份默认的源。不同的操作系统版本，源的文件位置各不一样，直接采用备份文件的方式备份即可。\n选择对应版本的源并替换。\n\n下面针对常见的 Debian、Ubuntu、CentOS，这里以说明一下如何正确的查找并替换源。\nDebianDebian 系统的源文件目录位于 /etc/apt/sources.list，这里我们以清华大学的镜像为例。清华大学开源镜像站 Debian 系统的帮助页面 详细列举了常用版本的源的信息。\n例如，我们系统的版本是 9 (stretch)，则选择 stretch，替换掉对应的源即可。\nstretch 版本的源信息如下：\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian-security stretch/updates main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security stretch/updates main contrib non-free\n\nbuster 版本的源信息如下\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-updates main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ buster-backports main contrib non-freedeb https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free# deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security buster/updates main contrib non-free\n\n其他版本不一一列举。\nUbuntuUbuntu 也是基于 Debian 的，故源的目录位置也是 /etc/apt/sources.list。清华大学开源镜像站 Ubuntu 系统的帮助页面 详细列举了常用版本的源的信息。\n例如，我们系统的版本是 18.04 LTS，则选择 18.04 LTS，替换掉对应的源即可。\n18.04 LTS 版本的源信息如下：\n# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse\n\nUbuntu 若安装了图形界面，也可以采用图形界面的方式。\n图形界面配置新手推荐使用图形界面配置： 系统设置 -&gt; 软件和更新 选择下载服务器 -&gt; “mirrors.aliyun.com”\nCentOSCentOS 的源文件位于 /etc/yum.repos.d/CentOS-Base.repo，清华大学开源镜像站 CentOS 系统的帮助页面 详细列举了常用版本的源的信息。\n与 Debian 的不同，CentOS 替换源之后，需要运行 yum makecache 生成缓存。\n此外阿里云提供了更为简单的方式，直接下载阿里云的 CentOS-Base.repo 文件到对应目录即可，命令如下：\n# CentOS 6wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo# 或者curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo# CentOS 7wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 或者curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo# 由于非阿里云 ECS 用户会出现 Couldn&#x27;t resolve host &#x27;mirrors.cloud.aliyuncs.com&#x27; 信息，不影响使用。用户也可自行修改相关配置: eg:sed -i -e &#x27;/mirrors.cloud.aliyuncs.com/d&#x27; -e &#x27;/mirrors.aliyuncs.com/d&#x27; /etc/yum.repos.d/CentOS-Base.repo\n\nCentOS 7 版本的清华大学源信息如下：\n# CentOS-Base.repo## The mirror system uses the connecting IP address of the client and the# update status of each mirror to pick mirrors that are updated to and# geographically close to the client.  You should use this for CentOS updates# unless you are manually picking other mirrors.## If the mirrorlist= does not work for you, as a fall back you can try the# remarked out baseurl= line instead.##[base]name=CentOS-$releasever - Basebaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#released updates[updates]name=CentOS-$releasever - Updatesbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/updates/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updatesgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that may be useful[extras]name=CentOS-$releasever - Extrasbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extrasgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plusbaseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/centosplus/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=centosplusgpgcheck=1enabled=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7\n\n配置免密登录场景：A 主机实现免密登录 B 主机\n\nA 主机生成公私钥对 ssh-keygen；\n将生成的公钥传输给 B 机器 scp /root/.ssh/id_rsa.pub remoteUser@remoteIp:remoteFolder；\n登录 B 机器，将 A 机器的公钥追加到 B 主机用户目录下的 .ssh/authorized_keys 文件，执行 cat id_rsa.pub &gt;&gt; .ssh/authorized_keys 命令即可。若没有authorized_keys文件，则需要创建，且其权限要为 600。\n\n查看系统负载top：重点关注 CPU、内存的使用率，以及 average（平均负载，三个值分别是 CPU 最近 1 分钟、5 分钟、15 分钟的平均负载）\nvmstat：\nLinux 子系统在 Windows 10 中使用 Linux 子系统时，经常会需要用到 root 账号，初始情况下，该账号是没有设定密码的，需要设定之后才能正常使用。\n# 设置 root 账户的密码sudo passwd# 切换 root 账户su\n\n软件管理Ubuntu 软件管理查看安装了哪些软件# 查看安装了哪些软件包apt list --installed# 也可以使用 dpkg 命令来查看安装了哪些软件包dpkg --list\n\n卸载已经安装的软件# 卸载某个软件包apt remove packagename# 也可以使用自动卸载apt autoremove packagename# 使用 dpkg 命令卸载dpkg --remove packagename","categories":["手册"],"tags":["未完待续","Linux"]},{"title":"Maven Wrapper 手册","url":"/2019/06/23/maven-wapper-%E6%89%8B%E5%86%8C/","content":"我们使用 Maven 时，基本上只会用到 mvn 这一个命令。有些开发者可能听说过 mvnw，这个是啥？\nmvnw 是 Maven Wrapper 的缩写，我们安装 Maven 时，默认情况下，系统所有项目都会使用全局安装的这个 Maven 版本。但是，对于某些项目来说，它可能必须使用某个特定的 Maven 版本，这个时候，就可以使用 Maven Wrapper，它可以负责给这个特定的项目安装指定版本的 Maven，而其他项目不受影响。\n简单地说，Maven Wrapper 就是给一个项目提供一个独立的，指定版本的 Maven 给它使用。\n安装 Maven Wrapper安装 Maven Wrapper 最简单的方式是在项目的根目录（即 pom.xml 所在的目录）下运行安装命令：\nmvn -N io.takari:maven:0.7.7:wrapper\n\n它会使用默认版本的 Maven。注意 0.7.7 是 Maven Wrapper 的版本。最新的 Maven Wrapper 版本可以去官方网站查看。\n如果要指定使用的 Maven 版本，使用下面的安装命令指定版本，例如 3.6.0：\nmvn -N io.takari:maven:0.7.7:wrapper -Dmaven=3.6.0\n\n安装后，查看项目结构：\nHello-World├── .mvn│   └── wrapper│       ├── MavenWrapperDownloader.java│       ├── maven-wrapper.jar│       └── maven-wrapper.properties├── mvnw├── mvnw.cmd├── pom.xml└── src    ├── main    │   ├── java    │   └── resources    └── test        ├── java        └── resources\n\n发现多了 mvnw、mvnw.cmd 和 .mvn 目录。\n使用 Maven Wrapper我们只需要把 mvn 命令改成 mvnw 就可以使用跟项目关联的 Maven。例如：\nmvnw clean package\n\nMaven Wrapper 的另一个作用是把项目的 mvnw、mvnw.cmd 和 .mvn 提交到版本库中，可以使所有开发人员使用统一的 Maven 版本。\n","categories":["手册"],"tags":["构建工具","Maven","Maven Wrapper"]},{"title":"Maven 手册","url":"/2019/06/22/maven-%E6%89%8B%E5%86%8C/","content":"什么是 Maven\nApache Maven is a software project management and comprehension tool. Based on the concept of a project object model (POM), Maven can manage a project’s build, reporting and documentation from a central piece of information.\n\nApache Maven 本质是一个软件项目管理和理解工具，它提供了一种项目管理的方法，涵盖了了项目管理中常见的阶段：\n\nBuilds\nDocumentation\nReporting\nDependencies\nSCMs\nReleases\nDistribution\n\n安装从官网下载安装包。\n基础环境Maven 依赖 Java 环境，所以要先确保已经正确安装 JDK。\n通过 java -version 命令来查看是否正确安装了 JDK\nPS C:\\Users\\fuyon&gt; java -versionjava version &quot;11.0.1&quot; 2018-10-16 LTSJava(TM) SE Runtime Environment 18.9 (build 11.0.1+13-LTS)Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.1+13-LTS, mixed mode)\n\nWindows解压将下载好的安装包 apache-maven-3.6.1-bin.zip 解压至 C:\\（或其他路径）。\n配置环境变量打开 控制面板 &gt; 系统和安全 &gt; 系统 &gt; 高级系统设置 &gt; 环境变量 &gt; 系统变量\n\n新建一个变量名为 M2_HOME，变量值为 C:\\apache-maven-3.6.1 (即 Maven 的安装路径)。\n选中系统变量中的 Path，并新增 %M2_HOME%\\bin\\\n\n验证打开终端，输入 mvn --version，输出\nPS C:\\Users\\fuyongde&gt; mvn --versionApache Maven 3.6.1 (d66c9c0b3152b2e69ee9bac180bb8fcc8d37e0fe; 2019-04-05T03:00:29+08:00)Maven home: C:\\apache-maven-3.6.1Java version: 1.8.0_162, vendor: Oracle CorporationJava home: C:\\Program Files\\Java\\jdk1.8.0_162\\jreDefault locale: zh_CN, platform encoding: GBKOS name: &quot;windows 10&quot;, version: &quot;10.0&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot;\n\n表示安装成功\nLinux &amp; Mac OS你都用这操作系统了，那肯定会安装吧 🤣。\n使用快速开始Maven 提供了丰富的模板，以供我们快速创建一个工程。其命令如下：\nmvn archetype:generate \\ -DgroupId=com.demo \\ -DartifactId=hello-maven \\ -DarchetypeArtifactId=maven-archetype-quickstart \\ -DinteractiveMode=false\n\n其中各个参数的含义：\n\n-DgroupId：组织的唯一标识符\n-DartifactId：项目的唯一标识符\n-DarchetypeArtifactId：指定 ArchetypeId，常见的选项 maven-archetype-quickstart (Java project)、maven-archetype-webapp (web project)\n-DinteractiveMode：是否使用交互模式\n\n目录结构不同的模板创建出来的项目目录可能会有差异，常见的 Maven 目录结构如下：\n├── src│   ├── main│   │   ├── java # 源码目录│   │   └── resources # 资源目录│   └── test│       ├── java # 单元测试源码目录│       └── resources # 单元测试资源目录├── target # 项目编译输出的目录├── pom.xml\n\nMaven 生命周期Maven 默认的生命周期包括：\n\nvalidate: 验证项目是否正确，并提供所有必要的信息\ncompile: 编译源码\ntest: 使用合适的单元测试框架测试编译的源代码，单元测试的代码并不会被打包。\npackage: 获取已编译的代码并将其打包为可分发的格式，例如 JAR。\nintegration-test: 如有必要，将程序包处理并部署到可以运行集成测试的环境中\nverify: 验证打包文件是否有效并符合质量标准\ninstall: 将项目打包安装到本地存储库中，以便在本地用作其他项目的依赖项\ndeploy: 将项目打包并推送到 Maven 私服或中央仓库\n\n此外还有两个生命周期的阶段\n\nclean: 清除之前构建\nsite: 为此项目生成站点文档\n\nPOMPOM stands for &quot;Project Object Model&quot;. It is an XML representation of a Maven project held in a file named pom.xml.\n\nPOM 表示”项目对象模型”，在 Maven 项目中以一个 pom.xml 文件的形式存在。\n最基本的构成一个 pom.xml 最基本的构成如下：\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;my-project&lt;/artifactId&gt;    &lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt;\n\n其中\n\nmodelVersion：Maven2 &amp; 3只支持 4.0.0\ngroupId：组织的唯一标识符\nartifactId：项目的唯一标识符\nversion：版本号\n\npackaging在 pom.xml 中可以添加 &lt;packaging&gt;war&lt;/packaging&gt; 来标识项目最终的打包格式，缺省值为：jar，可选值：pom, jar, maven-plugin, ejb, war, ear, rar。\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;!-- ... --&gt;    &lt;packaging&gt;war&lt;/packaging&gt;    &lt;!-- ... --&gt;&lt;/project&gt;\n\nPOM Relationships（重点）Maven 的一个强大的功能，就是它处理项目之间关系的能力，包括了：依赖项管理、继承和聚合。\n依赖依赖管理是 POM 的灵魂，大部分的项目都会依赖于其他项目来构建以及正确的运行。通过依赖管理，我们可以方便的下载、引入所需的其他依赖项。\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;  &lt;!-- ... --&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;junit&lt;/groupId&gt;        &lt;artifactId&gt;junit&lt;/artifactId&gt;        &lt;version&gt;4.12&lt;/version&gt;        &lt;type&gt;jar&lt;/type&gt;        &lt;scope&gt;test&lt;/scope&gt;        &lt;optional&gt;true&lt;/optional&gt;      &lt;/dependency&gt;      &lt;!-- ... --&gt;  &lt;/dependencies&gt;  &lt;!-- ... --&gt;&lt;/project&gt;\n\ngroupId、artifactId表示依赖项的坐标。由于依赖项都是由 Maven 坐标，意味着我们的项目只能依赖于同样是 Maven 管理的其他项目。但是很多时候，项目可能会依赖一些具有闭源许可的 jar，这些 jar 并不存在于中央仓库，有三种办法可以解决这个问题。\n\n使用 install 插件在本地安装依赖项，这是最简单也是最推荐的方式。例如：\n\nmvn install:install-file -Dfile=non-maven-proj.jar -DgroupId=some.group -DartifactId=non-maven-proj -Dversion=1 -Dpackaging=jar\n\n\n将依赖部署到私服\n\n将依赖的 scope 设置为 system 并且定义 systemPath，强烈不推荐这种方式。\n\n\nversion表示依赖的版本，关于 version 语法如下：\n\n1.0：若匹配到了 1.0 版本，则使用 1.0 版本\n[1.0]: 强制配依赖项的 1.0 版本\n(,1.0]: x &lt;&#x3D; 1.0\n[1.2,1.3]: 1.2 &lt;&#x3D; x &lt;&#x3D; 1.3\n[1.0,2.0): 1.0 &lt;&#x3D; x &lt; 2.0\n[1.5,): x &gt;&#x3D; 1.5\n(,1.0],[1.2,): x &lt;&#x3D; 1.0 or x &gt;&#x3D; 1.2，多个版本集合的情况以逗号分隔\n(,1.1),(1.1,): 排除 1.1 版本\n\n此外，version 的不同写法也存在优先级，详情可参考官网\ntype依赖项的类型，缺省值是 jar。除此之外还有ejb-client、test-jar，但都不常用\nscope依赖项作用的范围以及如何限制依赖项的传递性。共五个范围值可选：\n\ncompile：缺省值即为 compile，表示依赖项参与项目的编译、测试、运行阶段，项目打包时，也会打进去。\nprovided：依赖项参与项目的编译、测试阶段，与 compile 不同的是不会打包进项目中，但是期望 JDK、容器或使用者会提供该依赖项。\nruntime：编译时不需要该依赖项，但是执行时需要。\ntest：项目不需要该依赖项，并且仅适用于单元测试的编译和执行阶段，不具有传递性。\nsystem：使用上与 provided 相同，不同之处在于该依赖不从 Maven 仓库中提取，而是从本地文件系统中提取，其会参照 systemPath 的属性进行提取依赖。\n\nsystemPath仅在 scope 为 system 时使用，必须指定本地的绝对路径，且必须保证文件存在。例如：\n&lt;dependency&gt;  &lt;groupId&gt;org.hamcrest&lt;/groupId&gt;  &lt;artifactId&gt;hamcrest-core&lt;/artifactId&gt;  &lt;version&gt;1.5&lt;/version&gt;  &lt;scope&gt;system&lt;/scope&gt;  &lt;systemPath&gt;$&#123;basedir&#125;/WebContent/WEB-INF/lib/hamcrest-core-1.3.jar&lt;/systemPath&gt;&lt;/dependency&gt;\n\noptional标记依赖项是否可选，缺省值为 false。\n若项目 A 依赖项目 B，项目 B 依赖项目 C 且 optional 为 true，此时若 项目 A 没有显式的依赖 C，则项目 A 不依赖 C，且打包过程中，不会将 C 打包进来。例如 fastjson 依赖了 spring-webmvc，若使用者在开发的项目依赖了 fastjson并且没有依赖 spring-webmvc，则此项目是不依赖 spring-webmvc。\n排除依赖项由于依赖的传播的特性，我们可以排除一个依赖项中我们不需要的依赖。\n排除部分依赖项&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;  &lt;!-- ... --&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;      &lt;artifactId&gt;maven-embedder&lt;/artifactId&gt;      &lt;version&gt;2.0&lt;/version&gt;      &lt;exclusions&gt;        &lt;exclusion&gt;          &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;          &lt;artifactId&gt;maven-core&lt;/artifactId&gt;        &lt;/exclusion&gt;      &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;!-- ... --&gt;  &lt;/dependencies&gt;  &lt;!-- ... --&gt;&lt;/project&gt;\n\n排除所有依赖项&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;  &lt;!-- ... --&gt;  &lt;dependencies&gt;    &lt;dependency&gt;      &lt;groupId&gt;org.apache.maven&lt;/groupId&gt;      &lt;artifactId&gt;maven-embedder&lt;/artifactId&gt;      &lt;version&gt;3.1.0&lt;/version&gt;      &lt;exclusions&gt;        &lt;exclusion&gt;          &lt;groupId&gt;*&lt;/groupId&gt;          &lt;artifactId&gt;*&lt;/artifactId&gt;        &lt;/exclusion&gt;      &lt;/exclusions&gt;    &lt;/dependency&gt;    &lt;!-- ... --&gt;  &lt;/dependencies&gt;  &lt;!-- ... --&gt;&lt;/project&gt;\n\n继承在继承关系中，父工程的 packaging 类型必须为 pom，父工程的大多数属性会被子工程继承，包括\n\ngroupId\nversion\ndescription\nurl\ninceptionYear\norganization\nlicenses\ndevelopers\ncontributors\nmailingLists\nscm\nissueManagement\nciManagement\nproperties\ndependencyManagement\ndependencies\nrepositories\npluginRepositories\nbuild\nplugin executions with matching ids\nplugin configuration\netc.\n\n\nreporting\nprofiles\n\n不会被继承的属性包括：\n\nartifactId\nname\nprerequisites\n\n看一个例子\n父工程：\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;  &lt;artifactId&gt;my-parent&lt;/artifactId&gt;  &lt;version&gt;2.0&lt;/version&gt;  &lt;packaging&gt;pom&lt;/packaging&gt;&lt;/project&gt;\n\n子工程\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;parent&gt;    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;    &lt;artifactId&gt;my-parent&lt;/artifactId&gt;    &lt;version&gt;2.0&lt;/version&gt;    &lt;relativePath&gt;../my-parent&lt;/relativePath&gt;  &lt;/parent&gt;  &lt;artifactId&gt;my-project&lt;/artifactId&gt;&lt;/project&gt;\n\n其中 relativePath 不是必需的，但如果指定了，该路径则会作为搜索父工程的首选项。\nDependency Management在存在多个项目的情况下，在父项目中定义 dependencyManagement 来帮助管理所有子项目的依赖项。如果在父项目中的 dependencyManagement 标签下定义了某个依赖项的信息，则在子项目中只需要填写该依赖项的 groupId 和 artifactId 即可。好处是可以避免不同的子项目，引入不同版本的依赖项。\n聚合聚合可以将不同的模块，聚合在一起进行构建。\n&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0                      https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;  &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;  &lt;artifactId&gt;my-parent&lt;/artifactId&gt;  &lt;version&gt;2.0&lt;/version&gt;  &lt;packaging&gt;pom&lt;/packaging&gt;  &lt;modules&gt;    &lt;module&gt;my-project&lt;/module&gt;    &lt;module&gt;another-project&lt;/module&gt;    &lt;module&gt;third-project/pom-example.xml&lt;/module&gt;  &lt;/modules&gt;&lt;/project&gt;\n\n未完待续…\n","categories":["手册"],"tags":["未完待续","构建工具","Maven"]},{"title":"MySQL 优化器成本模型","url":"/2019/12/04/mysql-optimizer-cost-model/","content":"本文探讨一下 MySQL5.7 版本中 优化器的代价模型。相关内容也可查看官网\nMySQL 优化器成本模型由两个表组成，分别位于 mysql.server_cost 和 mysql.engine_cost 中。\n\nserver_cost: 针对服务器操作的优化器成本估算\nengine_cost: 针对特定存储引擎的特定操作的优化器成本估算\n\nserver_costserver_cost 包含以下值：\n\ndisk_temptable_create_cost：缺省值 40.0，该字段标识基于磁盘的存储引擎（InnoDB 和 MyISAM）中创建临时表的成本估算。从缺省值也可以看出，默认情况下创建临时表的代价是非常昂贵的。\ndisk_temptable_row_cost：缺省值 1.0，该字段标识基于磁盘的存储引擎（InnoDB 和 MyISAM）中创建临时行的成本估算。\nkey_compare_cost：缺省值 0.1，该字段表示比较记录的成本。\nmemory_temptable_create_cost：缺省值 2.0，MEMORY 存储引擎创建临时表的成本，从与 disk_temptable_create_cost 的对比中可以看出，默认情况下 MEMORY 存储引擎创建临时表的成本是远小于 InnoDB 和 MyISAM 存储引擎的。\nmemory_temptable_row_cost：缺省值 0.2，MEMORY 存储引擎创建临时行的成本。\nrow_evaluate_cost：缺省值 0.2，行评估成本，即扫描了多少行的成本。\n\nengine_cost\nio_block_read_cost：缺省值 1.0，从磁盘读取索引或数据块的成本。\nmemory_block_read_cost：缺省值 1.0，从内存数据库缓冲区读取索引或数据块的成本。\n\n查看当前成本配置-- 查看 server_cost 配置SELECT * FROM mysql.server_cost;-- 查看 engine_cost 配置SELECT * FROM mysql.engine_cost;\n\n修改成本模型-- 修改所有的 io_block_read_cost 成本UPDATE mysql.engine_cost  SET cost_value = 2.0  WHERE cost_name = &#x27;io_block_read_cost&#x27;;FLUSH OPTIMIZER_COSTS;-- 仅修改 InnoDB 存储引擎的成本INSERT INTO mysql.engine_cost  VALUES (&#x27;InnoDB&#x27;, 0, &#x27;io_block_read_cost&#x27;, 3.0,  CURRENT_TIMESTAMP, &#x27;Using a slower disk for InnoDB&#x27;);FLUSH OPTIMIZER_COSTS;-- 查看修改后的配置SELECT * FROM mysql.engine_cost WHERE cost_name = &#x27;io_block_read_cost&#x27;;\n\n实战打开优化器跟踪-- 查看优化器跟踪的开关SHOW VARIABLES LIKE &#x27;%optimizer_trace%&#x27;;-- 打开优化器跟踪SET GLOBAL optimizer_trace = &#x27;enabled=on,one_line=on&#x27;;\n\n未完待续 …\n"},{"title":"MySQL 索引","url":"/2019/11/23/mysql-index-categories/","content":"本文粗略说以下 MySQL 中常见的索引分类。\n物理存储角度\n聚簇索引\n非聚簇索引\n\n聚簇索引将数据存储与索引放到了一起，找到索引也就找到了数据。非聚簇索引将数据存储与索引分开，索引结构的叶子结点指向了数据对应的行。\n在 InnoDB 中，在聚簇索引之上创建的索引，称之为辅助索引，辅助索引叶子结点存储的不是行的物理位置，而是主键值，因此辅助索引访问数据总是需要二次查找的。\n一图顶千言，如下图所示：\n\n\n由于聚簇索引是将数据跟索引结构放在一起的，因此一个表仅有一个聚簇索引。\n聚簇索引默认是主键，如果表中没有定义主键，InnoDB 会选择一个唯一非空索引，如果没有这样的索引，InnoDB 会隐式定义一个主键来作为聚簇索引。\n数据结构角度\nB-Tree 索引（技术上来说是 B+树）\nhash 索引\nFULLTEXT 索引（全文索引）\nR-Tree 索引\n\n这里着重说以下 B-Tree 索引，B-Tree 索引之所以能加快访问数据的速度，是因为存储引擎不在需要进行全表扫描来获取数据，而是从索引的跟结点开始进行搜索，根节点的槽中存放了指向子节点的指针，存储引擎根据这些指针向下层查找，通过比较节点页的值和要查找的值找到合适的指针进入下层子节点，这些指针定义了子节点页中值的上限和下限。最终存储引擎要么找到对应的值，要么对应的记录不存在。\n叶子结点比较特别，它们的指针指向的是被索引的数据，而不是其他的结点页。同时所有的叶子结点到根节点的距离相同，所以 B-Tree 的查询效率非常的稳定。\n相较于二叉查找树，B-Tree 在比较次数上并不占优，但是把磁盘里数据加载到内存的时候，是以页为单位来加载的，节点与节点之间的数据是不连续的，所以不同的节点，有可能分布在不同的磁盘页中。B-Tree 的每一个节点可以存放多个元素，所以磁盘寻址加载次数会比较少。所以总体来说 B-Tree 还是比二叉查找树快。\nB-Tree 适用于全键值、键值范围或建前缀查找（只适用于最左前缀查找）。\n逻辑角度\n主键索引\n普通索引（单列索引）\n复合索引（多列索引）\n唯一索引\n\n","tags":["MySQL","索引"]},{"title":"MySQL 手册","url":"/2019/11/14/mysql-%E6%89%8B%E5%86%8C/","content":"参数配置查看所有参数mysql&gt; SHOW VARIABLES;\n\n慢查询、索引相关的参数查看慢查询日志是否打开Usage:\nmysql&gt; SHOW VARIABLES LIKE &#x27;%slow_query_log%&#x27;;\n\nResult:\n\n\n\nVariable_name\nValue\n\n\n\nslow_query_log\nOFF\n\n\nslow_query_log_file\n&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;17998065ff2d-slow.log\n\n\n打开慢查询日志Usage:\n-- 打开MySQL慢查询日志mysql&gt; SET GLOBAL slow_query_log = ON;-- 或者用这种方式mysql&gt; SET GLOBAL slow_query_log = 1;\n\n慢查询阈值查看慢查询阈值Usage:\nmysql&gt; SHOW VARIABLES LIKE &#x27;long_query_time&#x27;;\n\nResult:\n\n\n\nVariable_name\nValue\n\n\n\nlong_query_time\n10.000000\n\n\n设置慢查询阈值Usage:\n-- 设置慢查询阈值为0.1秒mysql&gt; SET GLOBAL long_query_time = 0.1;-- 注意：对于全局变量的修改，当前会话可能需要重新连接才能看到变化\n\n未使用索引的情况查看未使用索引的查询是否计入慢查询日志Usage:\nmysql&gt; SHOW VARIABLES LIKE &#x27;%log_queries_not_using_indexes%&#x27;;\n\nResult:\n\n\n\nVariable_name\nValue\n\n\n\nlog_queries_not_using_indexes\nOFF\n\n\n打开未使用索引记入慢查询日志Usage:\nmysql&gt; SET GLOBAL log_queries_not_using_indexes = ON;-- 或者mysql&gt; SET GLOBAL log_queries_not_using_indexes = 1;\n\n慢查询日志分析MySQL 自带了 mysqldumpslow 可以帮助我们快速地分析慢查询日志。pt-query-digest 是一个非常优秀的第三方工具来帮助我们分析 MySQL 的 binlog、generallog、slowlog。\nmysqldumpslowUsage：\nmysqldumpslow [ OPTS... ] [ LOGS... ]\n具体的参数，可自行查看其对应的含义\n示例：\n# 得到返回记录集最多的 10 个 SQL。mysqldumpslow -s r -t 10 /var/lib/mysql/izwz9ezwhlhq4hy1wzw9oqz-slow.log# 得到访问次数最多的 10 个 SQLmysqldumpslow -s c -t 10 /var/lib/mysql/izwz9ezwhlhq4hy1wzw9oqz-slow.log# 得到按照时间排序的前10条里面含有左连接的查询语句。mysqldumpslow -s t -t 10 -g &quot;left join&quot; /var/lib/mysql/izwz9ezwhlhq4hy1wzw9oqz-slow.log# 另外建议在使用这些命令时结合 | 和 more 使用 ，否则有可能出现刷屏的情况。mysqldumpslow -s r -t 20 /var/lib/mysql/izwz9ezwhlhq4hy1wzw9oqz-slow.log | more\n\n剖析 MySQL 查询在实际项目中，我们通过慢查询日志，只是找到对应的慢查询，那么如何对慢查询进行剖析呢？\nMySQL 在 5.1 版本之后引入了 SHOW PROFILE 命令，默认是禁用的，但可以在会话级别动态地修改。\n开启-- 设置为 ON 或 1 均可，启用查询性能分析功能mysql&gt; SET PROFILING = ON;\n\n剖析查询耗时开启之后执行任意一个查询，然后执行 SHOW PROFILING，观察对应的结果。\nmysql&gt; SHOW PROFILING;\n\n其结果如下\n\n\n\nQuery_ID\nDuration\nQuery\n\n\n\n1\n0.00060525\nSELECT * FROM actor\n\n\n如果需要看更为详细的信息\nmysql&gt; SHOW PROFILE FOR QUERY 1;\n\n其结果如下，可以看到详细地记录了该次查询各个阶段的耗时情况\n\n\n\nStatus\nDuration\n\n\n\nstarting\n0.000069\n\n\nchecking permissions\n0.000009\n\n\nOpening tables\n0.000021\n\n\ninit\n0.000022\n\n\nSystem lock\n0.000010\n\n\noptimizing\n0.000006\n\n\nstatistics\n0.000017\n\n\npreparing\n0.000015\n\n\nexecuting\n0.000004\n\n\nSending data\n0.000298\n\n\nend\n0.000006\n\n\nquery end\n0.000008\n\n\nclosing tables\n0.000009\n\n\nfreeing items\n0.000020\n\n\nlogging slow query\n0.000074\n\n\ncleaning up\n0.000019\n\n\n事务相关的参数事务隔离级别查看事务的隔离级别-- 查看当前数据库事务隔离级别mysql&gt; SHOW VARIABLES LIKE &#x27;%transaction_isolation%&#x27;;-- 或者mysql&gt; SELECT @@transaction_isolation;-- 低版本的MySQL属性是不一样的mysql&gt; SHOW VARIABLES LIKE &#x27;%tx_isolation%&#x27;;-- 或者mysql&gt; SELECT @@tx_isolation;\n\n设置事务的隔离级别-- 设置当前会话级别为`read-uncommitted`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;-- 设置当前会话级别为`read-committed`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;-- 设置当前会话级别为`repeatable-read`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;-- 设置当前会话级别为`serializable`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL SERIALIZABLE;\n\n事务自动提交MySQL 默认采用自动提交模式，也就是说如果不是显式地开始一个事务，则每个查询都被当做一个事务执行提交操作。另外还有一些命令，在执行之前会强制 COMMIT 提交当前活动的事务，典型的例子如 DDL 语言中会导致大量数据改变的操作，又比如 ALTER TABLE 等，此外还有 LOCK TABLES 等语句。\n查看事务自动提交状态Usage:\n-- 查看事务自动提交的参数mysql&gt; SHOW VARIABLES LIKE &#x27;AUTOCOMMIT&#x27;;\n\nResult:\n\n\n\nVariable_name\nValue\n\n\n\nautocommit\nON\n\n\n关闭事务自动提交Usage:\n-- 关闭事务自动提交mysql&gt; SET AUTOCOMMIT = OFF;","categories":["手册"],"tags":["MySQL","未完待续"]},{"title":"npm 手册","url":"/2020/07/19/npm-%E6%89%8B%E5%86%8C/","content":"配置 npmmirror 镜像1. 备份旧镜像在替换 npmmirror 镜像之前，我们先查看一下原有的镜像\nnpm get registry\n\n结果为 https://registry.npmjs.org/\nyarn get registry\n\n结果为 https://registry.yarnpkg.com\n2. 替换为 npmmirror 镜像# 设置 npm 的源为 npmmirrornpm config set registry https://registry.npmmirror.com# 设置 yarn 的源为 npmmirroryarn config set registry https://registry.npmmirror.com\n\n升级版本查看 npm 版本npm -v\n\n升级到最新的 npm 版本npm install -g npm\n\n安装指定版本的 npmnpm install -g npm@版本号\n\n例如安装 npm 6.x 的最新版本：\nnpm install -g npm@6\n\n或者安装特定版本：\nnpm install -g npm@6.14.6","categories":["手册"],"tags":["未完待续","npm"]},{"title":"pip 手册","url":"/2020/03/20/pip-%E6%89%8B%E5%86%8C/","content":"PyPI (Python Package Index) 是 Python 编程语言的软件存储库。开发者可以通过 PyPI 查找和安装由 Python 社区开发和共享的软件，也可以将自己开发的库上传至 PyPI 。\n由于国外访问比较慢，我们可以通过配置国内的镜像来进行加速访问。\n配置 Aliyun 的镜像Linux 平台\n找到下列文件\n\n~/.pip/pip.conf\n\n如果该文件不存在，需要创建相应的目录和文件：\nmkdir ~/.piptouch ~/.pip/pip.conf\n\n\n在上述文件中添加或修改:\n\n[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host = mirrors.aliyun.com\n\nWindows 平台在 explorer 地址栏输入 %AppData%，进入文件夹后，在 pip 文件夹下新建 pip.ini 文件并写入以下配置。\n如果 pip 文件夹不存在，需要先创建该文件夹。\n[global]index-url = https://mirrors.aliyun.com/pypi/simple/trusted-host = mirrors.aliyun.com","categories":["手册"],"tags":["pip","Python"]},{"title":"PowerShell 手册","url":"/2019/09/27/powershell-%E6%89%8B%E5%86%8C/","content":"记录一些常见的 PowerShell 的使用问题\n别名命令在使用 Linux 系统时，我喜欢使用 ll 命令来查看当前目录的文件，但是 Windows 系统的 PowerShell 没有这个命令，所以每次用的时候就很不习惯。我们可以通过对命令设置别名来让 PowerShell 支持我们的使用习惯。\n查看别名Get-Alias 或者 gal 命令来查看我们系统命令的别名，如下\nPS C:\\Users\\fuyongde&gt; get-aliasCommandType     Name                         Version    Source-----------     ----                         -------    ------Alias           % -&gt; ForEach-ObjectAlias           ? -&gt; Where-ObjectAlias           ac -&gt; Add-ContentAlias           cat -&gt; Get-Content\n\n\n查看某别名的原命令，如 ls 的原命令：Get-Alias ls\n查看某原命令的别名，如 Get-ChildItem 的别名：Get-Alias -Definition Get-ChildItem\n\n临时创建或更改别名使用 Set-Alias 命令来创建或更改别名，但是该命令只在当前的 PowerShell Session 中生效。另外还有一个 New-Alias 命令用法类似。\n创建不带参数的别名PS C:\\Users\\fuyongde&gt; Set-Alias -Name ll -Value get-childitem# 或者简单一些PS C:\\Users\\fuyongde&gt; Set-Alias ll get-childitem\n\n创建带参数的别名如果命令带参数如想为 Get-ChildItem -Name 设定别名为 ll 则我们需要两步，第一步为这个带参数原命令设定一个中间 function，第二步为这个 function 指定别名\nPS C:\\Users\\fuyongde&gt; function getlist &#123;Get-ChildItem -Name&#125;PS C:\\Users\\fuyongde&gt; Set-Alias ll getlist\n\n创建永久的别名在 PowerShell 中直接使用 Set-Alias 或 New-Alias 命令创建的别名在关闭此 Session 后即会失效，防止此现象的方法是将此命令写入 Windows PowerShell profile 文件。\n查看此文件在计算机中的位置：\nPS C:\\Users\\fuyongde&gt; $profile\n\n结果如下：\nC:\\Users\\fuyongde\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1\n但如果安装了 PowerShell 6 或更高版本的话，则结果是：\nC:\\Users\\fuyongde\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1\n打开对应文件，并写入要预设的别名\nSet-Alias ll get-childitem\n\n注意：该种方式有可能会遇到系统上禁止运行脚本的提示，这是因为 PowerShell 对安全做过充分考量，把脚本的执行分成了几个策略。以下是常用的执行策略：\n\nRestricted：禁止运行任何脚本和配置文件，默认情况下就是该策略。\nAllSigned：可以运行脚本，但要求所有脚本和配置文件由可信任的发布者签名，包括在本地计算机编写的脚本。\nRemoteSigned：可以运行脚本，但要求从网络上下载的脚本和配置由可信任的发布者签名，不要求对已经运行和在本地计算机编写的脚本进行签名。\nUnrestricted：可以运行未签名的脚本，这种策略也是最危险的。\n\n通过 Get-ExecutionPolicy 命令可查看当前配置的执行策略，通过管理员运行 PowerShell 并执行 Set-ExecutionPolicy RemoteSigned 可更改执行策略。\n删除别名使用 Remove-Item alias 命令删除已设定的别名。\n如删除别名 ll ：\nPS C:\\Users\\fuyongde&gt; Remove-Item alias:\\ll\n\n环境变量命令切换 PowerShell 的 page 为 UTF-8 代码页在最新版本的 Windows 操作系统中，PowerShell 默认的代码页已经是 UTF-8 字符集的代码页了。常见的代码页如下：\n\n65001：UTF-8 代码页\n\n950：繁体中文\n\n936：简体中文默认的 GBK\n\n437：MS-DOS 美国英语\n\n\n命令如下：\nchcp 65001\n\nModules 管理安装 Module使用 Install-Module 命令来安装 Module，其支持的参数有很多，具体可以查看官方文档，这里我们只列举最常用的参数的使用方法：\n# 为当前用户安装 posh-git 模块Install-Module -Name posh-git -Scope CurrentUser\n\n查找 Module使用 Find-Module 命令可以来查找 Module，其支持的参数有很多，具体可以查看官方文档，这里我们只列举最常用的参数的使用方法：\n# 查找名称为 PowerShellGet 的 ModuleFind-Module -Name PowerShellGet\n\n查看已经安装的 Modules# 查看已经安装的所有的 ModulesGet-InstalledModule# 查看已经安装的指定名称、版本的 ModulesGet-InstalledModule -Name &quot;AzureRM.Automation&quot; -MinimumVersion 1.0 -MaximumVersion 2.0\n\n更新已经安装的 Modules使用 Update-Module 命令来更新 Module，其支持的参数有很多，具体可以查看官方文档，这里我们只列举最常用的参数的使用方法：\n# 以 posh-git 为例，使用 Update-Module 来更新安装的 posh-git 版本Update-Module -Name posh-git# 将模块更新到指定的版本Update-Module -Name SpeculationControl -RequiredVersion 1.0.14\n\n卸载 Module使用 Uninstall-Module 命令可以来卸载 Module，其支持的参数有很多，具体可以查看官方文档，这里我们只列举最常用的参数的使用方法：\n# 卸载指定名称的模块Uninstall-Module -Name SpeculationControl# 强制卸载指定名称的模块Uninstall-Module -Name SpeculationControl -Force# 使用流水线的方式卸载，即先查找到某个模块并卸载Get-InstalledModule -Name SpeculationControl | Uninstall-Module# 卸载指定版本的模块Uninstall-Module -Name &#x27;oh-my-posh&#x27; -RequiredVersion &#x27;7.31.1&#x27;\n\n美化PowerShell 原始的界面是非常丑的，我们可以通过安装一些 modules 来进行美化，网上有很多博客介绍如何美化 PowerShell，但是大部分都没有介绍每个 module 的作用。\noh-my-posh\nA prompt theme engine for any shell.\n\n从介绍中可以看出 oh-my-posh 是为任何 shell 提供的一套主题引擎，这个是美化 PowerShell 的关键，具体更多的文档可以查阅官网。\n安装 oh-my-posh最新版本的 oh-my-posh 已经作为一个独立的应用来安装了（旧版本是作为 PowerShell 的一个 Module 来进行安装的），这里我们使用 winget 命令来安装最新版本的 oh-my-posh ，安装命令如下：\nwinget install JanDeDobbeleer.OhMyPosh -s winget\n\n安装完成之后，需要将 oh-my-posh 添加到环境变量的 path 里面\n$env:Path += &quot;;C:\\Users\\user\\AppData\\Local\\Programs\\oh-my-posh\\bin&quot;\n\n更新 oh-my-posh如果之前安装过 oh-my-posh 但是想要更新版本，其更新命令如下：\nwinget upgrade JanDeDobbeleer.OhMyPosh -s winget\n\n启用 oh-my-posh安装 oh-my-posh 之后，并不会直接启用，跟上文创建别名的方法一样，在 Windows PowerShell profile 文件中启用即可。通过 notepad $PROFILE 命令，打开 Windows PowerShell profile 文件，在文件中添加如下内容：\n# 使用 oh-my-posh 来初始化 powershelloh-my-posh init pwsh | Invoke-Expression# 指定使用的主题oh-my-posh init pwsh --config &quot;$env:POSH_THEMES_PATH\\yyds.omp.json&quot; | Invoke-Expression\n\n部分主题乱码问题由于一些 oh-my-posh 中用到了一些特殊的字符，需要对应的终端更换为支持这种特殊字符的字体，可以在nerdfonts 网站下载自己喜欢的字体，个人推荐 CaskaydiaMono Nerd Font Mono 这个字体。\nposh-gitposh-git 用于在 shell 上提示 git 的一些信息，其安装、更新、卸载过程跟其他的 PowerShell modules 一致。这里只列举安装命令：\nInstall-Module posh-git -Scope CurrentUser\n\n启用 posh-git安装 posh-git 之后，并不会直接启用，跟上文创建别名的方法一样，在 Windows PowerShell profile 文件中启用即可。通过 notepad $PROFILE 命令，打开 Windows PowerShell profile 文件，在文件中添加如下内容：\n# 引入 posh-git 模块Import-Module posh-git\n\nPSReadLinePSReadLine 在 PowerShell 控制台中提供改进的命令行编辑体验。具体说明可参考其官方文档。\n安装 PSReadLine# 需要注意的是：由于最新的 Windows 版本自带了 PSReadLine，但是其版本较低，无法启用跟 oh-my-posh 配合的功能，故我们采用为当前用户强制安装新版本的方式Install-Module -Name PSReadLine -Scope CurrentUser -Force\n\n启用 PSReadLine安装 PSReadLine 之后，并不会直接启用，跟上文创建别名的方法一样，在 Windows PowerShell profile 文件中启用即可。通过 notepad $PROFILE 命令，打开 Windows PowerShell profile 文件，在文件中添加如下内容：\n# 引入 PSReadLine 模块Import-Module PSReadLine# 设置编辑模式为 EmacsSet-PSReadlineOption -EditMode Emacs# 开启预测 IntelliSense，其模式为历史命令，即历史敲过的命令都会进行提示Set-PSReadLineOption -PredictionSource History# 开启预测 IntelliSense 之后，使用快捷键快速选中命令Set-PSReadlineKeyHandler -Key UpArrow -Function HistorySearchBackwardSet-PSReadlineKeyHandler -Key DownArrow -Function HistorySearchForward\n\nGet-ChildItemColorGet-ChildItemColor 是一个用于为 PowerShell 的 Get-ChildItem 命令输出添加颜色的模块，可以让文件和文件夹以不同颜色显示，提高可读性。\n安装 Get-ChildItemColor# 为当前用户安装 Get-ChildItemColor 模块Install-Module -Name Get-ChildItemColor -Scope CurrentUser\n\n启用 Get-ChildItemColor安装 Get-ChildItemColor 之后，需要在 Windows PowerShell profile 文件中启用。通过 notepad $PROFILE 命令，打开 Windows PowerShell profile 文件，在文件中添加如下内容：\n# 引入 Get-ChildItemColor 模块Import-Module Get-ChildItemColor# 设置别名，替换默认的 ls 命令Set-Alias -Name l   -Value Get-ChildItemColor -option AllScopeSet-Alias -Name ll  -Value Get-ChildItemColor -option AllScopeSet-Alias -Name dir -Value Get-ChildItemColor -Option AllScopeSet-Alias -Name ls  -Value Get-ChildItemColorFormatWide -option AllScope\n","categories":["手册"],"tags":["未完待续","PowerShell"]},{"title":"RPC Introduction","url":"/2019/07/11/rpc-introduction/","content":"What is RPC\nRemote Procedure Call (RPC) is a protocol that one program can use to request a service from a program located in another computer on a network without having to understand the network’s details. A procedure call is also sometimes known as a function call or a subroutine call. A procedure call is also sometimes known as a function call or a subroutine call.\n\nRPC 是一种远程过程调用协议，一个程序可以使用该协议从位于网络上另一台计算机中的程序请求服务，而无需了解网络的详细信息。RPC 有时也称为函数调用或子程序调用。RPC 是进程间通信的一种方式。\nWhy is RPC网上很多关于 RPC 的优点，笔者都不太赞同。不能将那些成熟的 RPC 框架解决的问题全部归结为 RPC 的优点。比如 RPC 的概念中并没有提到服务治理等问题，但是常见的 RPC 框架（如 DUBBO）均解决了服务治理的相关问题，这显然不能作为 RPC 的优点。要解释“Why is RPC?”的问题，还是要回归到 RPC 的概念上来。\n\nRPC 可以使远程过程调用变得像本地调用一样简单。\n方便计算能力的横向扩展。\n\n有兴趣可以阅读 dubbo 诞生的背景 以及dubbo 解决了哪些需求。\nRPC vs HTTP其实这两者不是同一个维度的概念。从 RPC 的概念上来讲，HTTP 其实就是 RPC 的一种实现。\nRPC vs RMI这两者也不是同一个维度的概念。\nRMI 是 JAVA 提供的一种远程方法调用，而 RPC 的变成模型是远程过程调用，RPC 并没有规定采用哪种编程语言实现，我们甚至可以使用 JAVA 语言实现一个具体的 RPC 协议，内部采用 RMI 来实现数据的传输，例如 dubbo 中就可以采用 rmi 协议。\nHow to implement RPC我们先思考这么一个问题：要怎么去调用远程的服务呢？\n\n要知道 ip 和端口，以确定远程唯一的一个进程。\n要知道调用远程的进程中的什么服务，以确定方法和参数\n调用远程的服务之后，要返回结果。\n\n根据上述的三点，我们来看一下如何实现一个 RPC 框架。\n原理在一个 RPC 的架构中包含 4 个组件：\n\nClient：即客户端，服务调用方\nClient Stub：客户端存根，用于存方服务端地址信息，将客户端的信息打包成网络消息，再通过网络发送给服务提供者\nServer Stub：服务端存根，接收客户端发送过来的消息，并调用本地服务\nServer：服务提供者\n\n一个 RPC 的调用过程：\n\nClient 调用以本地调用方式调用服务；\nClient Stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体（在 Java 中是序列化的过程）；\nClient Stub 找到服务地址，并将消息体通过网络发送到服务端；\nServer Stub 收到消息后进行解码（在 Java 中是反序列化的过程）；\nServer Stub 根据解码结果调用 Server 处理；\nServer 将结果返回给 Server Stub；\nServer Stub 将返回结果打包成消息体（在 Java 中是序列化的过程）；\nServer Stub 将打包后的消息通过网络并发送至消费方；\nClient Stub 接收到消息，并进行解码（在 Java 中是反序列化的过程）；\nClient 得到最终结果。\n\n一图顶千言\n\n\n实现我们简单的采用 Java 语言来实现一个 RPC 框架。\n命名作为钢铁侠粉丝，这里我们将项目命名为 Edith。\n\nEven dead,I am hero. -Tony Stark\n\n伊人已逝，仍是英雄。永远纪念 _Tony Stark_。\n暴露服务public class RpcFramework &#123;    public static void export(final Object service, int port) throws Exception &#123;        if (service == null) &#123;            throw new IllegalArgumentException(&quot;Service instance is null&quot;);        &#125;        if (port &lt;= 0 || port &gt; 65535) &#123;            throw new IllegalArgumentException(&quot;Invalid port &quot; + port);        &#125;        System.out.println(&quot;Export service &quot; + service.getClass().getName() + &quot; on port &quot; + port);        ServerSocket server = new ServerSocket(port);        for (; ; ) &#123;            try &#123;                final Socket socket = server.accept();                new Thread(() -&gt; &#123;                    try &#123;                        try &#123;                            ObjectInputStream input = new ObjectInputStream(socket.getInputStream());                            try &#123;                                String methodName = input.readUTF();                                Class&lt;?&gt;[] parameterTypes = (Class&lt;?&gt;[]) input.readObject();                                Object[] arguments = (Object[]) input.readObject();                                ObjectOutputStream output = new ObjectOutputStream(socket.getOutputStream());                                try &#123;                                    Method method = service.getClass().getMethod(methodName, parameterTypes);                                    Object result = method.invoke(service, arguments);                                    output.writeObject(result);                                &#125; catch (Throwable t) &#123;                                    output.writeObject(t);                                &#125; finally &#123;                                    output.close();                                &#125;                            &#125; finally &#123;                                input.close();                            &#125;                        &#125; finally &#123;                            socket.close();                        &#125;                    &#125; catch (Exception e) &#123;                        e.printStackTrace();                    &#125;                &#125;).start();            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n引用服务public class RpcFramework &#123;    public static &lt;T&gt; T refer(final Class&lt;T&gt; interfaceClass, final String host, final int port) &#123;        if (interfaceClass == null) &#123;            throw new IllegalArgumentException(&quot;Interface class is null&quot;);        &#125;        if (!interfaceClass.isInterface()) &#123;            throw new IllegalArgumentException(&quot;The &quot; + interfaceClass.getName() + &quot; must be interface class!&quot;);        &#125;        if (host == null || host.length() == 0) &#123;            throw new IllegalArgumentException(&quot;Host is null!&quot;);        &#125;        if (port &lt;= PORT_MIN || port &gt; PORT_MAX) &#123;            throw new IllegalArgumentException(&quot;Invalid port &quot; + port);        &#125;        System.out.println(&quot;Get remote service &quot; + interfaceClass.getName() + &quot; from server &quot; + host + &quot;:&quot; + port);        return (T) Proxy.newProxyInstance(interfaceClass.getClassLoader(), new Class&lt;?&gt;[]&#123;interfaceClass&#125;, (proxy, method, arguments) -&gt; &#123;            Socket socket = new Socket(host, port);            try &#123;                ObjectOutputStream output = new ObjectOutputStream(socket.getOutputStream());                try &#123;                    output.writeUTF(method.getName());                    output.writeObject(method.getParameterTypes());                    output.writeObject(arguments);                    ObjectInputStream input = new ObjectInputStream(socket.getInputStream());                    try &#123;                        Object result = input.readObject();                        if (result instanceof Throwable) &#123;                            throw (Throwable) result;                        &#125;                        return result;                    &#125; finally &#123;                        input.close();                    &#125;                &#125; finally &#123;                    output.close();                &#125;            &#125; finally &#123;                socket.close();            &#125;        &#125;);    &#125;&#125;\n\n定义接口public interface HelloService &#123;    /**     * 返回一个字符串     *     * @param name name     * @return Hello name     */    String hello(String name);&#125;\n\n编写服务提供者先实现 HelloService\npublic class HelloServiceImpl implements HelloService &#123;    @Override    public String hello(String name) &#123;        String result = &quot;Hello &quot; + name;        System.out.println(Thread.currentThread().getName() + &quot; &quot; + result);        return result;    &#125;&#125;\n\n启动并暴漏服务\npublic class Provider &#123;    public static void main(String[] args) throws Exception &#123;        HelloService helloService = new HelloServiceImpl();        RpcFramework.export(helloService, 8888);    &#125;&#125;\n\n编写服务调用者public class Consumer &#123;    public static void main(String[] args) &#123;        HelloService helloService = RpcFramework.refer(HelloService.class, &quot;127.0.0.1&quot;, 8888);        String name = &quot;Peter Parker&quot;;        System.out.println(helloService.hello(name));    &#125;&#125;\n\n执行 Consumer，查看控制台输出：\nHello Peter Parker\n\n总结本文的例子，采用了阻塞的 Socket IO 流来进行 Client 和 Server 之间的端对端通信。方法的远程调用采用了 Java 的动态代理，参数的序列化与反序列化采用 ObjectStream。成熟的 RPC 框架会对上述的实现方式进行替换，比如采用 Netty 的 NIO 来实现非阻塞通信，采用成熟的注册中心来统一管理服务的注册与发现，采用 hession2，fastjson 等序列化方式等等。成熟的 RPC 框架还会考虑调用过程中的诸多问题，比如重试机制、超时配置等等。\n本文参考了 徐靖峰的博客。\n","tags":["RPC"]},{"title":"Spring Cloud Alibaba Introduction","url":"/2019/10/11/spring-cloud-alibaba-introduction/","content":"介绍\nSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用服务的必需组件（涵盖了服务治理、配置管理、限流降级以及阿里开源生态和商业生态的诸多组件），方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里分布式应用解决方案，通过阿里中间件来迅速搭建分布式应用系统。\n\nSpring Cloud 是什么\nSpring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems .\n\nSpring Cloud 为开发者提供了快速构建分布式系统的模型。Spring Cloud 除了抽象了分布式系统里的一些接口，并且提供了一系列开箱即用的组件。\nSpring Cloud 更详细的介绍以及相关的组件，可以参考官网。\nSpring Cloud Alibaba 对 Spring Cloud 的意义\nSpring Cloud Alibaba 在 Spring Cloud 体系中是一个套件，类似于 Netflix OSS，为开发者提供了更多的选择。\n在 Netflix OSS 诸多重要组件先后宣布停止新功能开发的大背景下 Spring Cloud Alibaba 作为一个高速迭代中的新生项目无疑是更合适的选择。\n将国内非常流行的 Dubbo、RocketMQ 等融入 Spring Cloud 体系，使得应用的接入和改造的成本更低。\nSpring Cloud Alibaba 是中文文档最全的 Spring Cloud 组件。\n\n组件开源组件\nNacos Config：配置中心\nNacos Discovery：服务发现（注册中心）\nSentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\nRocketMQ：Apache RocketMQ™ 基于 Java 的高性能、高吞吐量的分布式消息和流计算平台。\nDubbo Spring Cloud：Apache Dubbo™ 是一款高性能 Java RPC 框架。\nSeata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。\n\n商业化组件\nANS：注册中心\nACM：配置中心\nOSS：阿里云对象存储服务\nSchedulerX：阿里中间件团队开发的一款分布式任务调度产品，支持周期性的任务与固定时间点触发任务。\nSMS：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。\n\n组件的版本关系\n\n\nSpring Cloud Alibaba Version\nSentinel Version\nNacos Version\nRocketMQ Version\nDubbo Version\nSeata Version\n\n\n\n2.1.0.RELEASE 2.0.0.RELEASE 1.5.0.RELEASE\n1.6.3\n1.1.1\n4.4.0\n2.7.3\n0.7.1\n\n\n0.9.0.RELEASE 0.2.2.RELEASE 0.1.2.RELEASE\n1.5.2\n1.0.0\n4.4.0\n2.7.1\n0.4.2\n\n\n0.2.1.RELEASE 0.1.1.RELEASE\n1.4.0\n0.6.2\n4.3.1\nx\nx\n\n\n0.2.0.RELEASE 0.1.0.RELEASE\n1.3.0-GA\n0.3.0\nx\nx\nx\n\n\n与 Spring Cloud 以及 Spring Boot 的版本依赖关系\n\n\nSpring Cloud Version\nSpring Cloud Alibaba Version\nSpring Boot Version\n\n\n\nSpring Cloud Greenwich\n2.1.0.RELEASE\n2.1.X.RELEASE\n\n\nSpring Cloud Finchley\n2.0.0.RELEASE\n2.0.X.RELEASE\n\n\nSpring Cloud Edgware\n1.5.0.RELEASE\n1.5.X.RELEASE\n\n\n过老的版本不推荐\nSpring Cloud Alibaba VS DubboDubbo Spring Cloud (归属于 Spring Cloud Alibaba 项目)是基于 Dubbo Spring Boot (归属于 Dubbo 项目)和 Spring Cloud开发，使得 Dubbo 应用以一种更优雅的方式融入 Spring Cloud 体系。\n功能对比由于 Dubbo Spring Cloud 构建在原生的 Spring Cloud 之上，其服务治理方面的能力可认为是 Spring Cloud 的加强版，不仅完全覆盖 Spring Cloud 原生特性，而且提供更为稳定和成熟的实现，特性比对如下表所示：\n\n\n\n功能组件\nSpring Cloud\nDubbo Spring Cloud\nDubbo\n\n\n\n分布式配置（Distributed configuration）\nGit、Zookeeper、Consul、JDBC\nSpring Cloud 分布式配置 + Dubbo 配置中心\nDubbo 配置中心\n\n\n服务注册与发现（Service registration and discovery）\nEureka、Zookeeper、Consul\nSpring Cloud 原生注册中心[1] + Dubbo 原生注册中心\nDubbo 原生注册中心\n\n\n负载均衡（Load balancing）\nRibbon（随机、轮询等算法）\nDubbo 内建实现（随机、轮询等算法 + 权重等特性）[2]\nDubbo 内建实现（随机、轮询等算法 + 权重等特性）\n\n\n服务熔断（Circuit Breakers）\nSpring Cloud Hystrix\nSpring Cloud Hystrix + Alibaba Sentinel[3] 等\nAlibaba Sentinel\n\n\n服务调用（Service-to-service calls）\nOpen Feign、RestTemplate\nSpring Cloud 服务调用 + Dubbo @Reference\nDubbo @Reference\n\n\n链路跟踪（Tracing）\nSpring Cloud Sleuth + Zipkin\nZipkin、opentracing 等\nZipkin、opentracing 等\n\n\n[1]: Spring Cloud 原生注册中心，除 Eureka、Zookeeper、Consul 之外，还包括 Spring Cloud Alibaba 中的 Nacos\n[2]: Dubbo Spring Cloud 相对于单纯的 Dubbo 服务的一个坑：单纯的 Dubbo 是将每一个由 @org.apache.dubbo.config.annotation.Service 注解的服务作为单独的服务暴露的，Dubbo Spring Cloud 如果采用推荐的写法，是将所属的工程作为一个服务来暴露的，若同一个服务版本不一致，会导致消费者找不到服务的情况。\n[3]: Alibaba Sentinel：Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性 - ，目前 Sentinel 已被 Spring Cloud 项目纳为断路器的候选实现\n写法对比从依赖上，Dubbo Spring Boot 的项目需要引入 dubbo-spring-boot-starter 相关依赖，Dubbo Spring Cloud 项目需要引入 spring-cloud-starter-dubbo相关依赖。\nExample：\nDubbo Spring Boot\n&lt;dependency&gt;    &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;    &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;    &lt;artifactId&gt;dubbo&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.dubbo&lt;/groupId&gt;    &lt;artifactId&gt;dubbo-registry-nacos&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt;    &lt;artifactId&gt;nacos-client&lt;/artifactId&gt;&lt;/dependency&gt;\n\nDubbo Spring Cloud\n&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-dubbo&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;&lt;/dependency&gt;\n\n从配置和代码上，Dubbo Spring Cloud 完全兼容 Dubbo Spring Boot 的配置写法，但是更推荐将 Dubbo 挂载本机 Spring Cloud 的服务发现的地址，并且推荐配置消费者所订阅的服务，从而来降低服务寻址时的 CPU 和内存开销。写发如下：\nspring:  cloud:    nacos:      discovery:        server-addr: nacos1.dafy.com:8848dubbo:  registry:    address: spring-cloud://localhost  cloud:    subscribed-services: bs-auth\n","tags":["Dubbo","Spring Cloud","Spring Cloud Alibaba"]},{"title":"事务隔离级别","url":"/2019/11/14/transaction-isolation/","content":"本文简单介绍一下数据库的事务隔离级别，所用数据库采用 MySQL，MySQL 提供了两种事务性的存储引擎 InnoDB 和 NDB Cluster，本文示例采用 InnoDB 存储引擎。\n查看当前数据的事务隔离级别-- 查看当前数据库事务隔离级别mysql&gt; SHOW VARIABLES LIKE &#x27;%transaction_isolation%&#x27;;-- 或者mysql&gt; SELECT @@transaction_isolation;-- 低版本的 MySQL 查看事务隔离级别的属性是不一样的mysql&gt; SHOW VARIABLES LIKE &#x27;%tx_isolation%&#x27;;-- 或者mysql&gt; SELECT @@tx_isolation;\n\n不同的事务隔离级别所面对的问题\n\n\n事务隔离级别\n脏读\n不可重复读\n幻读\n\n\n\n读未提交（read-uncommitted）\n是\n是\n是\n\n\n读已提交（read-committed）\n否\n是\n是\n\n\n可重复读（repeatable-read）\n否\n否\n是\n\n\n串行化（serializable）\n否\n否\n否\n\n\n\n脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。\n\n不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。\n\n幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。\n\n\n小结：不可重复读和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要使用间隙锁或临键锁来锁定范围。\n脏读的场景客户端 A 先开启事务，查询用户余额-- 客户端A设置当前会话级别为`read-uncommitted`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;-- 客户端A开启事务mysql&gt; START TRANSACTION;-- 客户端A查询用户余额mysql&gt; SELECT * FROM wallet WHERE user_id = 1;-- 结果如下：# +----+---------+-----------+# | id | user_id | balance   |# +----+---------+-----------+# |  1 |       1 | 100000000 |# +----+---------+-----------+\n\n客户端 B 开启事务，并修改用户余额-- 客户端B设置当前会话级别为`read-uncommitted`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;-- 客户端B开启事务mysql&gt; START TRANSACTION;-- 客户端B修改用户余额，mysql&gt; UPDATE wallet SET balance = balance + 100 WHERE user_id = 1;\n\n客户端 A 查询用户余额-- 客户端A获取用户余额（此时由于B的事务并未提交，故A事务读到了B事务已经更新后的数据，此时发生脏读）mysql&gt; SELECT * FROM wallet WHERE user_id = 1;-- 结果如下：# +----+---------+-----------+# | id | user_id | balance   |# +----+---------+-----------+# |  1 |       1 | 100000100 |# +----+---------+-----------+\n\n客户端 B 回滚事务-- 客户端B回滚事务mysql&gt; ROLLBACK;\n\n客户端 A 修改用户余额-- 客户端A修改用户余额mysql&gt; UPDATE wallet SET balance = balance - 500 WHERE user_id = 1;-- 客户端A查询用户余额mysql&gt; SELECT * FROM wallet WHERE user_id = 1;-- 结果如下：# +----+---------+----------+# | id | user_id | balance  |# +----+---------+----------+# |  1 |       1 | 99999500 |# +----+---------+----------+-- 对于A客户端来讲，此时的结果是很奇怪的。-- 客户端A提交事务mysql&gt; COMMIT;\n\n不可重复读的场景客户端 A 开启事务，查询用户余额-- 客户端A设置当前会话级别为`read-committed`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;-- 客户端A开启事务mysql&gt; BEGIN;-- 客户端A查询用户余额SELECT * FROM wallet WHERE user_id = 1;-- 结果如下:# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     200 |# +----+---------+---------+\n\n客户端 B 开启事务，并修改用户余额-- 客户端B设置当前会话级别为`read-committed`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;-- 客户端B开启事务mysql&gt; BEGIN;-- 客户端B修改用户余额mysql&gt; UPDATE wallet SET balance = balance + 100 WHERE user_id = 1;-- 客户端B查询用户余额mysql&gt; SELECT * FROM wallet WHERE user_id = 1;-- 结果如下：# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     300 |# +----+---------+---------+\n\n客户端 A 查询用户余额-- 客户端A查询用户余额mysql&gt; SELECT * FROM wallet WHERE user_id = 1;-- 结果如下：# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     200 |# +----+---------+---------+-- 此时客户端B的事务还没有提交，故客户端A不能查询到B事务已经更新的数据，解决了脏读的问题\n\n客户端 B 提交事务-- 客户端B提交事务mysql&gt; COMMIT;\n\n客户端 A 查询用户余额-- 客户端A查询用户余额mysql&gt; SELECT * FROM wallet WHERE user_id = 1;-- 结果如下：# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     300 |# +----+---------+---------+-- 此时客户端B的事务已经提交，结果与上一步不一致，即产生了不可重复读的问题。-- 客户端A提交事务mysql&gt; COMMIT;\n\n幻读的场景客户端 A 开启事务，查询所有用户-- 客户端A设置当前会话级别为`repeatable-read`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;-- 客户端A开启事务mysql&gt; BEGIN;-- 客户端A查询所有用户余额SELECT * FROM wallet;-- 结果如下:# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     100 |# +----+---------+---------+\n\n客户端 B 开启事务，并插入一条记录-- 客户端B设置当前会话级别为`repeatable-read`mysql&gt; SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;-- 客户端B开启事务mysql&gt; BEGIN;-- 客户端B查询所有用户余额SELECT * FROM wallet;-- 结果如下:# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     100 |# +----+---------+---------+-- 客户端B插入一条记录mysql&gt; INSERT INTO wallet (`id`, `user_id`, `balance`) VALUES (2, 2, 200);-- 客户端B查询所有的用户余额mysql&gt; SELECT * FROM wallet;-- 结果如下# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     100 |# |  2 |       2 |     200 |# +----+---------+---------+\n\n客户端 A 查询所有用户余额-- 客户端A查询所有用户余额, 此时发生幻读。SELECT * FROM wallet;-- 结果如下:# +----+---------+---------+# | id | user_id | balance |# +----+---------+---------+# |  1 |       1 |     100 |# +----+---------+---------+\n\n客户端 B 提交事务-- 客户端B提交事务mysql&gt; COMMIT;\n\n客户端 A 插入一条记录-- 客户A插入id为2的记录mysql&gt; INSERT INTO wallet (`id`, `user_id`, `balance`) VALUES (2, 2, 200);-- 结果失败了，ERROR 1062 (23000): Duplicate entry &#x27;2&#x27; for key &#x27;PRIMARY&#x27;-- 客户端A回滚mysql&gt; ROLLBACK;\n","tags":["数据库","MySQL","事务"]},{"title":"zsh 手册","url":"/2021/08/24/zsh-%E6%89%8B%E5%86%8C/","content":"zsh 可能是目前最好用的终端。\n安装Mac OSmacOS 自带 zsh，并且当前最新版本 macOS 默认终端即为 zsh\nUbuntu使用 sudo apt install zsh 命令即可安装 zsh\nCentOS使用 sudo yum install zsh 命令即可安装 zsh\n在安装好 zsh 之后，第一次使用的时候，会有如下的提示：\nThis is the Z Shell configuration function for new users,zsh-newuser-install.You are seeing this message because you have no zsh startup files(the files .zshenv, .zprofile, .zshrc, .zlogin in the directory~).  This function can help you with a few settings that shouldmake your use of the shell easier.You can:(q)  Quit and do nothing.  The function will be run again next time.(0)  Exit, creating the file ~/.zshrc containing just a comment.     That will prevent this function being run again.(1)  Continue to the main menu.(2)  Populate your ~/.zshrc with the configuration recommended     by the system administrator and exit (you will need to edit     the file by hand, if so desired).--- Type one of the keys in parentheses ---\n\n这里我推荐直接使用选项 (2)，通过 ~/.zshrc 文件来配置我们的 zsh。\n查看 zsh 版本使用 zsh --version 命令即可查看 zsh 的版本。\n将 zsh 设置为默认的 shell使用 chsh -s /bin/zsh root 即可将 root 用户的默认 shell 设置为 zsh，如需为其他用户设置默认的 shell，将 root 替换为其他用户名即可。\n查看默认的 shell使用 echo $SHELL 命令即可查看默认的 shell\n查看当前正在使用的 shell使用 echo $0 命令即可查看当前正在使用的 shell\n使用 oh-my-zsh 美化 zsh安装 oh-my-zsh打开 oh-my-zsh 官网，直接使用官网提供的命令，即可安装 oh-my-zsh，命令如下（任选其一即可）：\n# 使用 curl 下载sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;# 或者使用 wgetsh -c &quot;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)&quot;\n\n对于国内的用户，上面命令下载 install.sh 可能存在连接超时的问题，我们可以替换为 gitee 的镜像来进行下载，命令如下：\nwget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh\n\n下载之后，使用 sh install.sh 来安装 oh-my-zsh，如果在 clone oh-my-zsh 过程仍然连接超时的情况下，可以通过替换 install.sh 脚本中的仓库地址来进行加速。\n将脚本中的如下内容\nREPO=$&#123;REPO:-ohmyzsh/ohmyzsh&#125;REMOTE=$&#123;REMOTE:-https://github.com/$&#123;REPO&#125;.git&#125;\n\n替换为\nREPO=$&#123;REPO:-mirrors/oh-my-zsh&#125;REMOTE=$&#123;REMOTE:-https://gitee.com/$&#123;REPO&#125;.git&#125;\n\n配置 oh-my-zsh 主题修改 ~/.zshrc 文件，找到 ZSH_THEME 的选项，修改为自己喜欢的，笔者喜欢使用 ys 主题，其配置如下：\nZSH_THEME=&quot;ys&quot;\n\n如果你比较喜欢每次打开终端都体验不一样的主题的话，可以使用 random 主题。\n安装常用的插件下面列举一些非常实用的插件\n\nzsh-syntax-highlighting 有时候记不住一些命令，等输入完了才知道命令输错了，这个插件直接在输入过程中就会提示你，当前命令是否正确，错误红色，正确绿色\n\nzsh-autosuggestions 该插件会记录你之前输入过的所有命令，并且自动匹配你可能想要输入命令，然后按 → 补全\n\n\n可以使用如下命令来安装插件\n# 安装 zsh-syntax-highlightinggit clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting# 安装 zsh-autosuggestionsgit clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions\n\n修改 ~&#x2F;.zshrc 中插件的配置\nplugins=(git zsh-syntax-highlighting zsh-autosuggestions)\n\n然后使用 source ~/.zshrc 来使配置生效\n","categories":["手册"],"tags":["shell","bash","zsh"]},{"title":"一个 Spring 依赖注入的问题浅析","url":"/2021/08/08/%E4%B8%80%E4%B8%AA-Spring-%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%E7%9A%84%E9%97%AE%E9%A2%98%E6%B5%85%E6%9E%90/","content":"使用 Spring 做项目的先思考一个问题，一个接口有在多个实现类的情况下，在成员变量的声明上如果没有指定注入那个别名的 Bean 的时候 Spring 会如何选择对应的 Bean 来进行注入？\n问题模拟先来简单说明一下示例代码。\n定义一个接口，用于打印当前注入的 Bean 的名称\npublic interface TestService &#123;    void printBeanName();&#125;\n\n针对上面定义的接口编写两个实现类，并分别定义其 beanName 为 testService 和 testService2\n@Service(&quot;testService&quot;)public class TestServiceImpl implements TestService &#123;    @Override    public void printBeanName() &#123;        System.out.println(&quot;testService&quot;);    &#125;&#125;@Service(&quot;testService2&quot;)public class TestServiceImpl2 implements TestService &#123;    @Override    public void printBeanName() &#123;        System.out.println(&quot;testService2&quot;);    &#125;&#125;\n\n编写 Handler，并注入 TestService\n@Servicepublic class TestHandler &#123;    @Autowired    private TestService testService;    public void test() &#123;        testService.printBeanName();    &#125;&#125;\n\n编写单元测试，并观察输出\n@SpringBootTestclass TestHandlerTest &#123;    @Autowired    private TestHandler testHandler;    @Test    void test() &#123;        testHandler.test();    &#125;&#125;\n\n执行该单元测试，发现其打印的 beanName 为 testService。从输出结果可以看出在这种情况下最终注入的是 beanName 为 testService 的 bean，与组合交易子系统的现象一致。\n源码分析与验证根据 Spring 的文档，使用 Autowired 注解在自动装配时会通过 org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor#postProcessProperties 方法来对属性进行赋值操作。我们可以在该方法入口打上断点，并对断点指定条件，如下图：\n\n\n由于方法深度较深，调试的过程这里不再赘述，我们直接分析影响我们最终结果的方法 org.springframework.beans.factory.support.DefaultListableBeanFactory#determineAutowireCandidate，其源码及分析如下：\n/** * @param candidates 为我们要注入的属性对应的所有 Bean 组成的 map * @param descriptor 描述了我们要注入的属性的一些信息，包含了属性对应的类、方法、fieldName 等信息 */protected String determineAutowireCandidate(Map&lt;String, Object&gt; candidates, DependencyDescriptor descriptor) &#123;    // requiredType 为我们要注入的属性的类型，针对本的例子 requiredType 的值为 TestService 这个类    Class&lt;?&gt; requiredType = descriptor.getDependencyType();    // 如果 candidates 中有 Bean 添加了 @Primary 注解，则会返回该 Bean 对应的 beanName    String primaryCandidate = determinePrimaryCandidate(candidates, requiredType);    if (primaryCandidate != null) &#123;        return primaryCandidate;    &#125;    // 如果 candidates 中的 Bean 没有 @Primary 注解，但是添加了 @Priority 注解，会解析 Bean 的优先级，返回优先级最高的 Bean 对应的 beanName    String priorityCandidate = determineHighestPriorityCandidate(candidates, requiredType);    if (priorityCandidate != null) &#123;        return priorityCandidate;    &#125;    // 降级逻辑    for (Map.Entry&lt;String, Object&gt; entry : candidates.entrySet()) &#123;        String candidateName = entry.getKey();        Object beanInstance = entry.getValue();        // 此时的 this.resolvableDependencies 是不包含本例子中的 TestService 对应的任一 bean 的        // descriptor.getDependencyName() 方法的处理中会返回要注入的属性所对应的 fieldName，本例子中的 fieldName 为 testService        // 最终如果要注入属性名跟 candidates 的 Bean 的 beanName 相同，则会返回对应的 beanName        if ((beanInstance != null &amp;&amp; this.resolvableDependencies.containsValue(beanInstance)) ||                matchesBeanName(candidateName, descriptor.getDependencyName())) &#123;            return candidateName;        &#125;    &#125;    return null;&#125;\n\n下面我们来验证一下源码中的我们未验证到的情况\n使用 Primary 注解来标识主要的类将 beanName 为 testService2 的 Bean 加上 Primary 注解并运行单元测试，其打印的 beanName 为 testService2。\n使用 Priority 来标识 Bean 的优先级去掉上面操作所添加的 Primary 注解，来验证使用 Priority 时的情况。\n\n将 beanName 为 testService2 的 bean 加上 @Priority(2) 注解并运行单元测试，其打印的 beanName 为 testService2；\n将 beanName 为 testService 的 bean 加上 @Priority(1) 注解，将 beanName 为 testService2 的 bean 加上 @Priority(2) 注解并运行单元测试，其打印的 beanName 为 testService；\n将 beanName 为 testService 的 bean 加上 @Priority(3) 注解，将 beanName 为 testService2 的 bean 加上 @Priority(2) 注解并运行单元测试，其打印的 beanName 为 testService2。\n\n修改 TestHandler 中的属性名去掉上面操作所添加的 Primary 和 Priority 注解，来验证根据属性名注入时的情况。\n\n将 TestHandler 中的属性名修改为 testService2 并运行单元测试，其打印的 beanName 为 testService2；\n将 TestHandler 中的属性名修改为 testService3 并运行单元测试，程序抛出 NoUniqueBeanDefinitionException 异常。\n\n最佳实践建议在实际开发中，当遇到同一接口有多个实现类的情况时，推荐使用以下方式明确指定要注入的Bean：\n使用 @Qualifier 注解@Servicepublic class TestHandler &#123;    @Autowired    @Qualifier(&quot;testService2&quot;)    private TestService testService;    public void test() &#123;        testService.printBeanName();    &#125;&#125;\n\n使用字段名匹配@Servicepublic class TestHandler &#123;    @Autowired    private TestService testService2; // 字段名与Bean名匹配    public void test() &#123;        testService2.printBeanName();    &#125;&#125;\n\n使用 @Primary 注解@Service(&quot;testService&quot;)@Primarypublic class TestServiceImpl implements TestService &#123;    // ...&#125;\n\n结论根据上面源码的分析与实践，同一类型存在多个 Bean 的情况下，在使用 Autowired 注解时 Spring 会采用以下装配顺序来选择要装配的 Bean：\n\n使用了 Primary 注解的 Bean;\n查找使用了 Priority 注解的 Bean，并选择优先级最高的；\n要注入的属性的属性名称与 Bean 名称相同的；\n\n在我们平时写代码时，为了代码的可读性和明确性，建议使用 Qualifier 注解来明确指明要注入的Bean，避免依赖默认的装配规则。\n","categories":["Spring"],"tags":["Spring","源码"]},{"title":"不要过分相信自己的直觉之 RateLimiter.getRate()","url":"/2022/07/20/%E4%B8%8D%E8%A6%81%E8%BF%87%E5%88%86%E7%9B%B8%E4%BF%A1%E8%87%AA%E5%B7%B1%E7%9A%84%E7%9B%B4%E8%A7%89%E4%B9%8BRateLimiter-getRate/","content":"最近使用 Guava 中 RateLimiter.getRate() 方法时遇到了一个反直觉的现象，这里贴出来给大家分享一下。\n现象我们先看下下面这段代码\npublic static void main(String[] args) &#123;    RateLimiter rateLimiter = RateLimiter.create(10.0D);    double rate = rateLimiter.getRate();    System.out.println(rate);&#125;\n\n直觉上最终会输出 10.0，实际最终也是输出了 10.0。\n可是如果我们将上述代码中的 10.0D 变为 15.0D，结果会输出什么呢？\npublic static void main(String[] args) &#123;    RateLimiter rateLimiter = RateLimiter.create(15.0D);    double rate = rateLimiter.getRate();    System.out.println(rate);&#125;\n\n执行后输出的值竟然是 14.999999999999998。看到这个结果我觉得非常的奇怪，毕竟直觉告诉我应该输出 15.0 才对。\n刨根问底看到这样的现象，我们首先就要从源码上分析一下，看一下 Guava 内部是如何处理的。\n打开 RateLimiter.getRate() 方法，发现其返回的是抽象方法 doGetRate() 的值。\npublic final double getRate() &#123;    synchronized (mutex()) &#123;        return doGetRate();    &#125;&#125;\n\n我们创建 RateLimiter 的实例时默认创建的是类型为 SmoothBursty 的对象，该类的 doGetRate() 方法实现如下：\n@Overridefinal double doGetRate() &#123;    return SECONDS.toMicros(1L) / stableIntervalMicros;&#125;\n\n这里竟然不是直接返回我们创建 RateLimiter 时设置的值，而是通过除法运算得来的。\n继续分析 stableIntervalMicros 是怎么设值的。\n/** * 该方法是创建 RateLimiter 时调用的方法**/@Overridefinal void doSetRate(double permitsPerSecond, long nowMicros) &#123;    resync(nowMicros);    double stableIntervalMicros = SECONDS.toMicros(1L) / permitsPerSecond;    this.stableIntervalMicros = stableIntervalMicros;    doSetRate(permitsPerSecond, stableIntervalMicros);&#125;\n\n至此结论已经非常清晰了：由于在创建 RateLimiter 时成员变量 stableIntervalMicros 便是通过简单的除法运算得来的，当 1000000 微妙（1 秒）不能够被传入的限流值除尽时 stableIntervalMicros 就已经丢失了精度，从而导致在这种情况下调用 doGetRate() 是不能够得到我们创建 RateLimiter 时传入的原始值的。\n发散Guava 为什么不在创建 RateLimiter 时把我们传入的原始值保存在一个成员变量里，调用 doGetRate() 方法时直接返回该成员变量的值呢？\n我个人的理解可以从变量和方法命名上去分析，RateLimiter.create(double permitsPerSecond) 方法的变量名 permitsPerSecond 其含义是每秒产生多少令牌。而 RateLimiter.getRate() 从方法名以及 Guava 的注释上来看该方法的含义更倾向于提供产生令牌的实际速率。\n总结在使用一些三方的库甚至是 Java 本身提供的一些方法时要弄清楚其使用场景，尽量多验证一下各种边界值、特殊值的情况，不能盲目相信自己的直觉。\n","categories":["Guava"],"tags":["源码","Guava","限流"]},{"title":"使用 Guava 中 RateLimiter 遇到的一个问题","url":"/2021/06/26/%E4%BD%BF%E7%94%A8Guava%E4%B8%ADRateLimiter%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98/","content":"线上业务使用了 Guava 中的 RateLimiter 来做单机的限流。最近运维同事反馈，在修改了限流的配置之后，请求频率没有超过限流的配置却触发了限流逻辑，在此对该问题进行一下分析与总结。\n问题模拟根据上述问题的现象，初步推测问题可能跟 Guava 中 RateLimiter 的限流算法实现有关，为了方便排查问题，参考线上业务的限流的逻辑写了一个 demo，其核心代码如下：\n@RestController@RequestMapping(&quot;/hello&quot;)public class HelloController &#123;    /** 用于存储不同的接口，对应的 RateLimiter **/    private static Map&lt;String, RateLimiter&gt; RATE_LIMITER_MAP = Maps.newConcurrentMap();    /** 用于存储不同接口限流配置的参数 **/    private static Map&lt;String, String&gt; RATE_MAP = Maps.newConcurrentMap();    static &#123;        // 初始化一个接口默认的限流配置        RATE_MAP.put(&quot;loan&quot;, &quot;100000&quot;);    &#125;    /**     * 测试限流的接口     * @param key 限流配置的 key     */    @GetMapping(&quot;/testLimit&quot;)    public String testLimit(String key) &#123;        String value = RATE_MAP.get(key);        logger.info(&quot;自定义限流配置=&#123;&#125;&quot;, value);        Double currentRate = Double.parseDouble(value);        RateLimiter rateLimiter = RATE_LIMITER_MAP.get(key);        if (rateLimiter == null || !isSameRate(currentRate, rateLimiter.getRate())) &#123;            logger.info(&quot;创建新的RateLimiter|速率=&#123;&#125;&quot;, currentRate.toString());            rateLimiter = RateLimiter.create(currentRate);            RATE_LIMITER_MAP.putIfAbsent(key, rateLimiter);        &#125;        boolean allowed = rateLimiter.tryAcquire();        logger.info(&quot;是否允许当前请求通过=&#123;&#125;|rate=&#123;&#125;&quot;, allowed, rateLimiter.getRate());        return allowed ? &quot;SUCCESS&quot; : &quot;FAIL&quot;;    &#125;    /**     * 模拟修改限流配置     * @param key 限流配置的key     * @param rate 限流的值     */    @GetMapping(&quot;/setRate&quot;)    public String setRate(String key, String rate) &#123;        RATE_MAP.put(key, rate);        String currentValue = RATE_MAP.get(key);        logger.info(&quot;设置完之后的值=&#123;&#125;&quot;, currentValue);        return &quot;SUCCESS&quot;;    &#125;&#125;\n\n启动工程，我们模拟一下出现问题时的操作。\n\n构造 HTTP 请求调用 /setRate 接口，将 loan 对应的限流的值修改为 5；\n构造 HTTP 请求快速调用 /testLimit 接口 2 次，发现第一次调用接口返回 SUCCESS，第二次接口返回 FAIL，说明第 2 次请求触发了限流；\n构造 HTTP 请求调用 /testLimit 5 次，保证 5 次请求在 1 秒内接收，发现这 5 次请求接口均返回 SUCCESS，说明这 5 次请求均未触发限流；\n构造 HTTP 请求调用 /testLimit 6 次，保证 6 次请求均在 1 秒内接收，发现前 6 次请求接口均返回 SUCCESS，说明这 6 次请求均未触发限流；\n构造 HTTP 请求调用 /testLimit 7 次，保证 7 次请求均在 1 秒内接收，发现前 6 次请求接口均返回 SUCCESS，第 7 次请求接口返回 FAIL，说明前 6 次请求均未触发限流，第 7 次请求触发限流。\n\n至此，我们模拟的现象与线上一致。步骤 3 是我们预期的结果，步骤 2 中在未超过限流配置的情况下触发了限流，步骤 4、5 中的第 6 次请求在超过了限流配置的情况下，仍然允许通过，我们直观上认为这些是不合理的。\n排查与分析Guava 中 RateLimiter 提供了两种令牌桶的算法实现：\n\n平滑突发限流（SmoothBursty）\n平滑预热限流（SmoothWarmingUp）\n\n我们项目中使用了默认的平滑突发限流（SmoothBursty）算法，这里我们只针对该算法进行分析。\ntryAcquire 方法其源码\npublic boolean tryAcquire(int permits, long timeout, TimeUnit unit) &#123;  long timeoutMicros = max(unit.toMicros(timeout), 0);  checkPermits(permits);  long microsToWait;  synchronized (mutex()) &#123;    long nowMicros = stopwatch.readMicros();    if (!canAcquire(nowMicros, timeoutMicros)) &#123;      return false;    &#125; else &#123;      microsToWait = reserveAndGetWaitLength(permits, nowMicros);    &#125;  &#125;  stopwatch.sleepMicrosUninterruptibly(microsToWait);  return true;&#125;\n\n可以观察到只有在 canAcquire 方法返回 false 的情况下，才会返回 false，通过阅读 canAcquire 方法可知该方法跟 SmoothBursty 中的成员变量 nextFreeTicketMicros 有关，该成员变量的释义如下：\n\nThe time when the next request (no matter its size) will be granted. After granting a request, this is pushed further in the future. Large requests push this further than small requests.\n\n该成员变量标识下一次请求获得令牌的最早时间，在创建 SmoothBursty 时初始值为 0，并且每次授权一个请求之后，这个值会向后推移。查找该成员变量引用的地方，发现 SmoothBursty 类中 reserveEarliestAvailable、resync 方法会触发该成员变量的更新，并且观察该方法的调用栈，其中就有 RateLimiter#tryAcquire() 方法。\nreserveEarliestAvailable、resync 方法其源码\n/**  * @param requiredPermits 表示我们该次请求所取得令牌数，我们这里值为 1  * @param nowMicros 距创建 RateLimiter 时经过了多少时长，单位为微秒  */@Overridefinal long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123;  // 刷新令牌数  resync(nowMicros);  long returnValue = nextFreeTicketMicros;  // storedPermits 是创建 RateLimiter 时的一个成员变量，表示当前存储的令牌数，在 resync 方法和本方法中会更新所存储的令牌数  // 当前存储的令牌数跟需要获取的令牌数进行比较，取两者的的最小值，即为当前可以得到令牌数  double storedPermitsToSpend = min(requiredPermits, this.storedPermits);  // 需要预先支付的令牌  double freshPermits = requiredPermits - storedPermitsToSpend;  // 在突然涌入大量请求，而现有的令牌数又不够用的情况下，会预先支付一定的令牌数  // stableIntervalMicros 为创建 RateLimiter 时计算出的稳定时间间隔，其计算公式为 周期 / 令牌数，在我们的例子中，该值即为 200000 微妙（即 200ms）  // waitMicros 表示预先支付令牌的时间  long waitMicros =      storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend)          + (long) (freshPermits * stableIntervalMicros);  // 预先支付令牌的时间+原请求获取令牌的最早时间，即为下一次获取令牌的最早时间  this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros);  // 所存储的令牌数需要减去本次消耗的令牌  this.storedPermits -= storedPermitsToSpend;  // 这里返回旧的获取令牌最早的时间，即本次请求无需为预支付的令牌付出额外的等待时间  return returnValue;&#125;void resync(long nowMicros) &#123;  // if nextFreeTicket is in the past, resync to now  if (nowMicros &gt; nextFreeTicketMicros) &#123;    // 在 SmoothBursty 类中 coolDownIntervalMicros() 方法返回的是成员变量 stableIntervalMicros，在我们的例子中，该值即为 200000 微妙（即 200ms）    double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros();    // maxPermits 在 创建 RateLimiter 时的一个成员变量，表示所能存储的最大令牌数，在我们的例子中，该值为 5    // 更新当前所存储的令牌数，取值为 原存储的令牌数与新产生的令牌数之和 与 最大存储令牌数 两个数值中较小的值，保证可用的令牌数不会大于所允许存储的最大令牌数    storedPermits = min(maxPermits, storedPermits + newPermits);    nextFreeTicketMicros = nowMicros;  &#125;&#125;\n\n在 reserveEarliestAvailable 方法结尾处打断点，来观察一下修改配置之后，第一次调用该方法时对 nextFreeTicketMicros 成员变量的设值情况。如下图:\n\n\n通过上图中的执行情况可知，在限流配置修改为 5TPS 的情况下，第一次请求进来之后，令牌桶内所存储的令牌桶还不足 1，发生了预支付令牌的情况，此时 nextFreeTicketMicros 成员变量会被赋值为约 200000 微妙（即 200ms），如果第二个请求是在第一个请求之后 200ms 内请求进来的，一定会触发限流逻辑，如下图：\n\n\n同样的我们提上面的操作中 1 秒内的连续 6 次请求，第 6 次仍未触发限流，这种现象也是由于预支付令牌产生的。在一段时间内没有请求进来的情况下，令牌桶内累计了 5 个令牌，此时前 5 个令牌会被前 5 个请求消费掉，当第 6 个请求进来的时候，时间仍然在向前推进，只是此时桶内累计的令牌数不足 1 个，会触发预先支付令牌，故这种情况下第 6 个请求，仍然是能够通过的。而当第 7 个请求进来的时候，由于下一次请求获得令牌的最早时间已经大于当前时间了，故取令牌失败，触发限流，如下图：\n\n\n结论通过以上源码的分析，Guava 中 RateLimiter 的平滑突发限流（SmoothBursty）是通过以固定的速率向桶内放置令牌，从而达到平滑输出的效果。由于桶内会进行令牌的积累，可以应对一定程度的流量突发。\n对于我们线上遇到的修改配置之后第二个请求就触发了限流的问题，我们在切换配置时应该使用 RateLimiter 的 setRate 方法直接修改其限流配置，这样可以避免重新创建一个新的 RateLimiter 时会创建一个新的跑表（Stopwatch），同时也不会将 nextFreeTicketMicros 重新置为 0，使得在取令牌时对桶内令牌数的计算不会像重新创建一个那么极端。\n思考大家也可以看一下 Guava 中平滑预热限流（SmoothWarmingUp）在实现上与的平滑突发限流（SmoothBursty）有什么区别？此外常见的其他限流算法如漏桶算法、计数法分别是怎么实现的？\n","categories":["Guava"],"tags":["源码","Guava","限流"]},{"title":"How Install Embed Python On Windows","url":"/2020/03/19/How-Install-Embed-Python-On-Windows/","content":"Windows 系统如何安装 Python 绿色版以下为适配 Windows 系统（以 Windows11 X64 为例）的 Python 3.13.9 绿色版安装步骤，安装路径统一为 C:\\devtools\\python\\Python313，可实现多 Python 版本共存，适合需要灵活管理多个 Python 环境的场景。\n一、下载并解压 Python 3.13.9 绿色版获取绿色版解压包访问 Python 官方下载页面，定位到 Python 3.13.9 版本：\n\n官方入口：打开 Python 下载首页，在 “Looking for a specific release?” 栏目下找到 “Python 3.13.9” 并点击进入版本详情页\n直接下载：若已知链接，可访问 Python 3.13.9 专属下载页，在 “Files” 区域选择 Windows x86-64 zip file（64 位系统绿色版，文件格式为 .zip，无需安装，解压即可使用）\n\n解压到指定路径\n找到下载完成的 .zip 压缩包，右键选择 “解压到…”\n在解压路径选择窗口中，手动输入或浏览定位到 C:\\devtools\\python\\Python313（若路径中 “devtools””python” 文件夹不存在，需提前在对应目录手动新建，确保路径无中文、无空格，避免后续出现命令执行错误）\n等待解压完成，打开 C:\\devtools\\python\\Python313 目录，确认包含 python.exe 等核心文件，即解压成功\n\n二、安装 pip 包管理器（绿色版默认不含 pip）pip 是 Python 官方包管理工具，用于安装、卸载第三方库（如 numpy、pandas 等），绿色版 Python 默认不预装，需手动安装：\n下载 get-pip.py 脚本\n访问 pip 官方安装指南页面：https://pip.pypa.io/en/stable/installation/\n在页面中找到 “Download get-pip.py” 链接，右键点击该链接，选择 “链接另存为”\n在保存窗口中，将文件路径定位到 C:\\devtools\\python\\Python313（即 Python 根目录），确保文件名保留为 get-pip.py，点击 “保存”\n\n执行 pip 安装命令\n按下 Win + R 组合键打开 “运行” 窗口，输入 cmd 后按下回车，打开 Windows 命令提示符（CMD）\n在 CMD 中，通过 cd 命令切换到 Python 根目录，执行命令：\n\ncd /d C:\\devtools\\python\\Python313\n\n\n/d 参数用于跨盘符切换路径，若当前 CMD 已在 C 盘，可省略 /d，直接执行 cd C:\\devtools\\python\\Python313\n\n\n切换路径后，执行 pip 安装命令：\n\npy get-pip.py\n\n\n等待命令执行完成（过程中会自动下载并安装 pip 及依赖组件），若 Python 根目录新增 Lib 和 Scripts 两个文件夹，且无报错提示，即 pip 安装成功\n\n三、解决 “找不到模块” 问题（关键步骤）绿色版 Python 为避免多版本冲突，默认不自动加载模块路径，导致执行 pip 命令时可能报错（如 “ModuleNotFoundError”），需通过修改配置文件解决：\n初始验证（确认问题）在已切换到 Python 根目录的 CMD 窗口中，执行以下两条命令：\n\n验证 Python 版本：python -V（若输出 “Python 3.13.9”，说明 Python 核心程序正常）\n验证 pip 状态：Scripts\\pip -V（若出现 “找不到模块” 或 “命令无法识别” 等报错，需继续执行后续步骤）\n\n修改 python313._pth 配置文件\n打开 C:\\devtools\\python\\Python313 目录，找到名为 python313._pth 的文件（文件名格式为 “python [版本号]._pth”，Python 3.13.9 对应此名称）\n右键选择该文件，点击 “打开方式”→”记事本”（或其他文本编辑器）\n在文件内容中找到 #import site 这一行（# 表示注释，该行未生效），删除开头的注释符 #，修改后为 import site\n按下 Ctrl + S 保存文件，关闭记事本\n\n再次验证（确认问题解决）在 CMD 窗口中重新执行 Scripts\\pip -V，若输出类似以下信息，说明问题已解决，pip 可正常使用：\npip X.X.X from C:\\devtools\\python\\Python313\\Lib\\site-packages\\pip (python 3.13)\n\n\n“X.X.X” 为 pip 实际版本号，无需关注具体数值，只要无报错即可\n\n四、可选操作：添加环境变量（实现全局便捷调用）默认情况下，需在 Python 根目录执行 python 或 pip 命令，若希望在任意目录的 CMD 窗口中直接调用，需将 Python 路径添加到系统环境变量 Path 中：\n打开环境变量配置窗口\n右键点击 “此电脑”→ 选择 “属性”→ 在弹出的 “系统” 窗口中，点击左侧 “高级系统设置”\n在 “系统属性” 窗口的 “高级” 选项卡下，点击右下角 “环境变量”\n在 “环境变量” 窗口中，找到 “系统变量” 区域的 Path 变量，点击 “编辑”\n\n添加 Python 相关路径在 “编辑环境变量” 窗口中，点击 “新建”，分别添加以下两个路径：\n\nC:\\devtools\\python\\Python313（Python 核心程序路径，用于调用 python 命令）\nC:\\devtools\\python\\Python313\\Scripts（pip 工具路径，用于调用 pip 命令）\n\n添加完成后，点击 “确定” 关闭所有窗口（需依次关闭 “编辑环境变量””环境变量””系统属性” 窗口，确保配置生效）\n验证环境变量是否生效\n关闭已打开的所有 CMD 窗口（环境变量修改需重启 CMD 生效）\n重新打开一个新的 CMD 窗口，在任意目录下执行以下命令：\npython -V（输出 Python 3.13.9 版本）\npip -V（输出 pip 版本及路径）\n\n\n若两条命令均无报错且正常输出，说明环境变量配置成功\n\n五、安装完成后的验证操作为确保 Python 及 pip 完全可用，可执行简单的测试命令：\n\n在 CMD 中执行 python，进入 Python 交互环境（显示 “&gt;&gt;&gt;” 提示符）\n输入 print(&quot;Python 3.13.9 绿色版安装成功！&quot;)，按下回车，若输出对应字符串，说明 Python 交互环境正常\n输入 exit() 退出交互环境，执行 pip list，若显示已安装的包列表（如 pip、setuptools 等），说明 pip 可正常使用\n\n至此，Python 3.13.9 绿色版在 Windows 系统中的安装全部完成，可根据需求安装第三方库或运行 Python 脚本。\n"},{"title":"JaCoCo 二次开发解决「类局部修改丢失历史覆盖率」完整方案","url":"/2026/01/18/JaCoCo-%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%E8%A7%A3%E5%86%B3%E3%80%8C%E7%B1%BB%E5%B1%80%E9%83%A8%E4%BF%AE%E6%94%B9%E4%B8%A2%E5%A4%B1%E5%8E%86%E5%8F%B2%E8%A6%86%E7%9B%96%E7%8E%87%E3%80%8D%E5%AE%8C%E6%95%B4%E6%96%B9%E6%A1%88/","content":"本文为基于 JaCoCo 源码二次开发的全流程方案，旨在实现类局部修改后保留未改动方法历史覆盖率，仅失效改动方法覆盖率的核心诉求，兼顾 JaCoCo 原生正确性原则与业务实用性。\n一、核心目标与不可突破原则1.1 核心开发目标\n类局部修改（方法 &#x2F; 代码块修改）时，未改动方法的历史覆盖率完全复用，改动方法覆盖率清零并重新统计；\n完全兼容 JaCoCo 原生能力：插桩方式（动态 &#x2F; 离线）、覆盖率维度、dump 文件格式、构建插件（Maven&#x2F;Gradle）；\n坚守正确性底线：仅当方法字节码逻辑完全未变时才复用覆盖率，杜绝错误数据。\n\n1.2 不可突破原则\n正确性原则：复用数据必须基于方法逻辑一致性，方法体改动则覆盖率强制失效；\n向下兼容原则：改造后 JaCoCo 可解析原生 dump 文件，原生 JaCoCo 可解析改造后文件（降级兼容）；\n无侵入原则：业务侧无感知，使用方式与原生 JaCoCo 一致，新增开关控制功能。\n\n1.3 核心改造思想原生 JaCoCo 以 类级别 ClassID 绑定覆盖率数据，类变更则全量失效；改造后下沉为 方法级别 MethodID 绑定，实现方法级粒度的失效与复用，核心逻辑如下：\n\n覆盖率数据存储结构从 ClassID + 全局探针ID → ClassID + MethodID + 方法内局部探针ID\n\n二、前置准备2.1 源码与环境准备\n源码仓库：克隆 JaCoCo 官方仓库 https://github.com/jacoco/jacoco，基于 0.8.12&#x2F;0.8.13 稳定版 开发（避免主干版本不稳定风险）；\n构建环境\n构建工具：Maven 3.9.11+\nJDK 版本：编译用 JDK 17，测试兼容 JDK 8+\nIDE：IntelliJ IDEA&#x2F;Eclipse（需安装 ASM 插件辅助字节码分析）；\n核心依赖：重点掌握 ASM 9.x 框架（JaCoCo 插桩 &#x2F; 字节码解析的底层依赖）；\n\n\n改造涉及模块（仅需修改 3 个核心模块，其余无改动）\n\n\n\n\n模块名称\n改造比重\n核心作用\n\n\n\norg.jacoco.core\n80%\n插桩、探针管理、ClassID&#x2F;MethodID 生成、覆盖率数据存储\n\n\norg.jacoco.report\n20%\n覆盖率报告渲染、数据聚合逻辑调整\n\n\norg.jacoco.agent\n&lt;5%\n动态插桩入口适配，无核心逻辑修改\n\n\n2.2 原生 JaCoCo 核心机制回顾二次开发前必须吃透的 3 个底层逻辑：\n\nClassID 生成：由 org.jacoco.core.data.CRC64 类实现，对 class 完整字节码做 CRC64 哈希，字节码变动则 ClassID 改变；\n探针机制：JaCoCo 在字节码指令级插入探针（boolean 数组），行 &#x2F; 分支 &#x2F; 方法覆盖率均基于探针状态聚合；\n覆盖率存储：核心载体为 org.jacoco.core.data.ExecutionData，存储 ClassID + 全局探针数组，最终序列化到 .exec 文件。\n\n三、核心改造点（优先级排序）所有改造均为增量改造，保留原生逻辑，通过开关控制新功能，降低开发风险。\n3.1 核心改造一：方法级唯一标识 MethodID 生成与管理\n改造意义：为每个方法生成稳定唯一标识，作为覆盖率复用的核心依据，是整个方案的基石。\n\n3.1.1 MethodID 设计要求\n稳定性：方法逻辑不变 → MethodID 不变（忽略注释、格式、行号表等无关内容）；\n唯一性：方法逻辑变动（哪怕一行代码）→ MethodID 立即改变。\n\n3.1.2 源码实现步骤\n新增工具类：org.jacoco.core.data.MethodCRC64\n参考原生 CRC64 类，专门用于生成 MethodID，核心逻辑如下：\n\npublic class MethodCRC64 &#123;    private final CRC64 crc = new CRC64();    /**     * 生成 MethodID：基于方法核心特征字节码     * @param access 方法访问修饰符     * @param name 方法名     * @param desc 方法签名     * @param methodBytes 方法体核心字节码（排除调试信息）     * @return 8字节 MethodID     */    public long generateId(int access, String name, String desc, byte[] methodBytes) &#123;        crc.reset();        crc.update(access);        crc.update(name.getBytes(StandardCharsets.UTF_8));        crc.update(desc.getBytes(StandardCharsets.UTF_8));        crc.update(methodBytes);        return crc.getValue();    &#125;&#125;\n\n\nMethodID 提取逻辑\n在 org.jacoco.core.internal.flow.ClassProbesVisitor 中，通过 ASM 解析 class 文件时：\n遍历每个方法，使用 ClassReader.SKIP_DEBUG 模式跳过调试信息；\n提取方法的 访问修饰符 + 方法名 + 方法签名 + 方法体字节码，调用 MethodCRC64 生成 MethodID；\n缓存 方法名+签名 → MethodID 的映射关系。\n\n\n\n3.2 核心改造二：重构探针编号与管理机制\n改造意义：将原生类级全局探针改为方法级局部探针，实现探针与方法的精准绑定。\n\n3.2.1 原生探针机制痛点原生探针为类内全局连续编号（如方法 A 探针 0-1，方法 B 探针 2-4），类变更则全局探针数组全部失效，无法区分探针归属。\n3.2.2 改造后探针机制\n探针编号规则\n每个方法内部探针独立编号（从 0 开始），例如方法 A 探针 0-1、方法 B 探针 0-2；\n类级别维护 全局探针ID → (MethodID, 方法内局部探针ID) 映射表，兼容原生全局探针结构。\n\n\n源码改造位置\norg.jacoco.core.internal.flow.MethodProbesVisitor：修改方法内探针编号逻辑为局部编号；\norg.jacoco.core.internal.instr.Instrumenter：适配插桩时的局部探针编号生成；\n新增工具类 org.jacoco.core.data.ProbeMapping：维护全局探针与方法探针的映射关系，并序列化到 dump 文件。\n\n\n\n3.3 核心改造三：扩展覆盖率数据载体与 dump 文件存储\n改造意义：实现方法级覆盖率数据的持久化存储，兼容原生 dump 文件格式。\n\n3.3.1 原生 ExecutionData 痛点原生 ExecutionData 仅存储类级数据，无方法维度信息，无法支撑方法级复用：\nprivate final long classId; // 类IDprivate final String name; // 类名private final boolean[] probes; // 全局探针执行状态\n\n3.3.2 扩展 ExecutionData（增量改造）通过继承扩展实现，不修改原生核心字段，避免破坏兼容性：\npackage org.jacoco.core.data;/** * 扩展类：支持方法级覆盖率数据存储 */public class ExtendedExecutionData extends ExecutionData &#123;    // MethodID -&gt; 方法内局部探针执行状态    private final Map&lt;Long, boolean[]&gt; methodProbes;    // MethodID -&gt; 方法名+签名（用于报告展示）    private final Map&lt;Long, String&gt; methodNames;    public ExtendedExecutionData(long classId, String name, int probeCount) &#123;        super(classId, name, probeCount);        this.methodProbes = new HashMap&lt;&gt;();        this.methodNames = new HashMap&lt;&gt;();    &#125;    // 省略 getter/setter 方法&#125;\n\n3.3.3 序列化 &#x2F; 反序列化逻辑\n序列化：原生 3 个字段正常写入，新增的 methodProbes 和 methodNames 追加写入 dump 文件末尾；\n反序列化：改造后 JaCoCo 可解析原生 &#x2F; 改造后 dump 文件，原生 JaCoCo 解析改造后文件时自动忽略新增字段，实现降级兼容。\n\n3.4 核心改造四：跨版本覆盖率数据复用核心算法\n改造意义：实现历史覆盖率与新版本类数据的智能合并，是方案的核心业务逻辑。\n\n3.4.1 算法核心场景合并旧版本类历史 dump 数据与新版本类本次测试数据，核心逻辑为 MethodID 精准匹配。\n3.4.2 核心算法伪代码/** * 方法级覆盖率复用核心算法 * @param oldData 旧版本类的方法级覆盖率数据 * @param newData 新版本类的方法级覆盖率数据 * @return 合并后数据：未改方法复用历史，改动方法用新数据 */public ExtendedExecutionData mergeCoverage(ExtendedExecutionData oldData, ExtendedExecutionData newData) &#123;    ExtendedExecutionData mergedData = new ExtendedExecutionData(        newData.getClassId(), newData.getName(), newData.getProbes().length    );    // 遍历新版本类的所有方法    for (Map.Entry&lt;Long, boolean[]&gt; entry : newData.getMethodProbes().entrySet()) &#123;        Long newMethodId = entry.getKey();        boolean[] newMethodProbes = entry.getValue();        // 核心判断：MethodID 一致则复用历史数据        if (oldData.getMethodProbes().containsKey(newMethodId)) &#123;            mergedData.getMethodProbes().put(newMethodId, oldData.getMethodProbes().get(newMethodId));            mergedData.getMethodNames().put(newMethodId, oldData.getMethodNames().get(newMethodId));        &#125; else &#123;            // 方法改动/新增：使用本次测试数据            mergedData.getMethodProbes().put(newMethodId, newMethodProbes);            mergedData.getMethodNames().put(newMethodId, newData.getMethodNames().get(newMethodId));        &#125;    &#125;    // 同步更新全局探针数组，兼容原生报告    mergedData.updateGlobalProbes();    return mergedData;&#125;\n\n3.5 核心改造五：报告生成模块改造\n改造意义：实现方法级覆盖率数据的可视化展示，完成最后一公里落地。\n\n3.5.1 核心改造点\n数据聚合逻辑：在报告生成入口调用 mergeCoverage 算法，合并新旧版本数据；\n报告可视化增强（可选）\n在 HTML&#x2F;XML 报告中新增方法变更状态标识：未改动方法标注「复用历史覆盖率」，改动方法标注「新增覆盖率」；\n保留原生覆盖率统计维度（行 &#x2F; 分支 &#x2F; 方法覆盖率），仅调整数据来源为方法级聚合。\n\n\n源码改造位置：org.jacoco.report.internal.html.HTMLFormatter、org.jacoco.report.xml.XMLFormatter\n\n四、非核心改造点（适配性改造）完成核心改造后，需进行少量适配工作，确保功能完整可用：\n\nAgent 模块适配：修改 org.jacoco.agent.rt.internal_*.Agent，调用 ExtendedExecutionData 替代原生 ExecutionData，无核心逻辑改动；\n构建插件适配：在 Maven&#x2F;Gradle 插件中新增开关配置，控制是否开启方法级复用：\n\n&lt;!-- Maven 插件示例配置 --&gt;&lt;plugin&gt;    &lt;groupId&gt;org.jacoco&lt;/groupId&gt;    &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;    &lt;version&gt;0.8.12-custom&lt;/version&gt;    &lt;configuration&gt;        &lt;!-- 新增开关：默认关闭，开启后启用方法级覆盖率复用 --&gt;        &lt;enableMethodLevelCoverage&gt;true&lt;/enableMethodLevelCoverage&gt;    &lt;/configuration&gt;&lt;/plugin&gt;\n\n\nCLI 工具适配：为 jacococli.jar 的 merge&#x2F;report 命令新增 –method-level 参数，支持方法级数据处理。\n\n五、技术难点与避坑指南（Q&amp;A）Q1：ASM 字节码解析时如何保证 MethodID 的准确性？问题描述：在生成 MethodID 时，容易把调试信息、行号表等无关信息算进 MethodID，导致方法逻辑没有变化但 MethodID 却改变了。\n解决方案：生成 MethodID 时，使用 ASM 的 ClassReader.SKIP_DEBUG 模式解析 class 文件，这样可以自动跳过调试信息，只处理核心字节码，确保 MethodID 的稳定性。\nQ2：如何处理 Lambda 表达式和内部类的覆盖率统计？问题描述：Java 的 Lambda 表达式、匿名内部类在 ASM 解析时会生成「合成方法（synthetic method）」，这些方法的 MethodID 也需要生成，否则会导致 Lambda 内的覆盖率失效。\n解决方案：对合成方法一视同仁，正常生成 MethodID，探针插桩逻辑不变。JaCoCo 原生已经兼容了内部类，只需继承该逻辑即可。\nQ3：改造后新增的功能是否会影响 JaCoCo 的性能？问题描述：改造后新增了 MethodID 生成、方法探针映射等功能，是否会显著影响 JaCoCo 的性能？\n解答：实际上影响很小，几乎可以忽略：\n\nMethodID 生成是在「编译期 &#x2F; 插桩期」执行一次，运行时无任何开销；\n方法探针映射是内存中的 Map 操作，时间复杂度 O(1)；\n\n实测结果显示：改造后的 JaCoCo，插桩耗时增加 &lt; 5%，运行时覆盖率采集耗时增加 &lt; 2%，性能影响完全可以忽略。\nQ4：如何确保与第三方工具（如 IDEA、Jenkins、SonarQube）的兼容性？问题描述：改造后可能会导致与第三方工具的兼容性失效，这是绝对要避免的坑。\n解决方案：遵循核心原则：永远不要修改 JaCoCo 原生的核心类和核心字段，所有改造都应用「继承、扩展、新增」的方式实现。保留原生全局探针数组，第三方工具可正常解析，方法级数据作为增强维度。\nQ5：如何实现降级兼容，使改造后的 JaCoCo 能够解析原生 dump 文件？问题描述：改造后需要确保能够向后兼容，既能解析原生 dump 文件，也要让原生 JaCoCo 能解析改造后的文件。\n解决方案：\n\n在序列化时，原生的 3 个字段正常写入，新增的 methodProbes 和 methodNames 追加写入 dump 文件末尾；\n在反序列化时，改造后的 JaCoCo 可解析原生及改造后的 dump 文件；\n原生 JaCoCo 解析改造后的文件时自动忽略新增字段，实现降级兼容。\n\n六、效果验证（核心场景测试）开发完成后，需验证以下 3 个核心场景，确保功能达标：\n\n场景 1：类局部方法修改\n\n初始状态：类 A 含方法 A1&#x2F;A2&#x2F;A3，测试后覆盖率 100%，生成 dump1.exec；\n修改操作：仅修改方法 A2 的分支逻辑，A1&#x2F;A3 保持不变；\n新测试：仅执行方法 A2 的测试用例，生成 dump2.exec；\n预期结果：合并后报告中 A1&#x2F;A3 覆盖率 100%（复用历史），A2 覆盖率为本次测试结果。\n\n\n场景 2：类新增方法\n\n初始状态：类 A 含方法 A1&#x2F;A2，覆盖率 100%，生成 dump1.exec；\n修改操作：新增方法 A3；\n新测试：仅执行 A3 的测试用例，生成 dump2.exec；\n预期结果：A1&#x2F;A2 复用 100% 覆盖率，A3 覆盖率为本次测试结果。\n\n\n场景 3：方法完全重写\n\n初始状态：方法 A1 覆盖率 100%，生成 dump1.exec；\n修改操作：完全重写 A1 的方法体逻辑，MethodID 改变；\n新测试：未执行 A1 的测试用例，生成 dump2.exec；\n预期结果：A1 覆盖率为 0，其余方法复用历史数据。\n\n\n\n七、工作量评估与开发周期\n\n\n工作内容\n代码量\n预估时间\n\n\n\n核心改造（MethodID + 探针 + 数据结构 + 算法）\n1500-2000 行\n10-14 天\n\n\n非核心适配（Agent + 插件 + CLI）\n300-500 行\n3-5 天\n\n\n功能测试与问题修复\n-\n5-7 天\n\n\n总计\n1800-2500 行\n18-26 天\n\n\n备注：以上时间基于「熟悉 JaCoCo 源码与 ASM 框架」的前提，若需先学习相关技术，建议增加 1 周学习时间。\n八、总结与进阶建议8.1 方案核心收益\n完美解决类局部修改导致的全量覆盖率失效问题，平衡「正确性」与「实用性」；\n完全兼容 JaCoCo 原生生态，无业务侵入性，可平滑上线；\n改造逻辑清晰，代码增量可控，便于后续维护与版本升级。\n\n","categories":["解决方案"],"tags":["JaCoCo"]}]